{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install huggingface-hub\n# %pip install numpy\n# %pip install opencv-python\n# %pip install matplotlib\n# %pip install pandas","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/taki0112/vit-tensorflow.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv \"/kaggle/working/vit-tensorflow/vit_tensorflow\" \"/kaggle/working/vit_tensorflow\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install optree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time\nimport math\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# secret_hf =","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !huggingface-cli login --token $secret_hf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download data","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"imagedata.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"label.txt\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir datasetImage\n!unzip -q -o \"dataset/imagedata.zip\" -d \"datasetImage\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"prefix_path_data = \"/kaggle/working/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rawlabel = \"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load label\nwith open(os.path.join(prefix_path_data, \"dataset/label.txt\"), \"r\") as f:\n    rawlabel = f.read()\n    \n# G93aRj07CIZPKaC8.jpg {\"label-8\":14,\"label-7\":3,\"label-2\":4} 16\n# name image, label(json), totel people vote\n# Format to json {name, label, totel}\nlabelDataset = []\narrayRawLabel = rawlabel.split(\"\\n\")\nfor ele in arrayRawLabel:\n    eleArr = ele.split(\" \")\n    try:\n        labelDataset.append({\n            \"name\": eleArr[0],\n            \"label\": json.loads(eleArr[1]),\n            \"total\": int(eleArr[2])\n        })\n    except:\n        print(ele)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label 0 -> 10, 0 is not good image need to delete\ndef LabelsToVector(labels):\n    vectorLabel = [0] * 11\n    try:\n        for label, num in labels.items():\n            if len(label.split(\"-\")) != 2:\n                print(\"Error: \", labels)\n            vectorLabel[int(label.split(\"-\")[1])] = num\n    except:\n        pass\n    return vectorLabel\n\ndef NormalVectorLabel(vectorLabel, total, presentFilter):\n    # Check if label 0 is > presentFilter\n    if total == 0 or vectorLabel[0]/total > presentFilter:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n    \n    # Process localcation label\n    totalLocalVote = 0\n    for i in range(1, 3):\n        totalLocalVote += vectorLabel[i]\n    if totalLocalVote > 0:\n        for i in range(1, 3):\n            vectorLabel[i] = 1 if vectorLabel[i]/totalLocalVote > presentFilter else 0\n    \n    # Process orther label\n    for i in range(3, len(vectorLabel)):\n        vectorLabel[i] = 1 if vectorLabel[i]/total > presentFilter else 0\n        \n    # Process speacil case\n    # Auto set label 1\n    goodLabel = [3, 4]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[1] = 1;\n    \n    # Auto set label 2\n    goodLabel = [7, 8]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[2] = 1;\n            \n    # Check if label 1 or 2 is set\n    if vectorLabel[1] == vectorLabel[2]:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n#     else:\n#         vectorLabel[0] = 0\n    \n    return np.array(vectorLabel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter label\nfor ele in labelDataset:\n    # Only get label with > 50% vote\n    ele[\"label\"] = NormalVectorLabel(LabelsToVector(ele[\"label\"]), ele[\"total\"], 0.5)\n    \n# Filter bad image\nclearLabelDataset = []\nfor ele in labelDataset:\n    if ele[\"label\"][0] == 0:\n        ele[\"label\"] = ele[\"label\"][1:]\n        clearLabelDataset.append(ele)\nlabelDataset = clearLabelDataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add map image name to label\nmapImageNameToLabel = {}\nfor ele in labelDataset:\n    mapImageNameToLabel[ele[\"name\"]] = ele[\"label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map name for fast filter image\nmapNameFastQuery = set()\nfor ele in labelDataset:\n    mapNameFastQuery.add(ele[\"name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load image\nimagesDataset = {}\nfor label in labelDataset:\n    if label[\"name\"] not in mapNameFastQuery:\n        continue\n    img = resize_image_reduce_size(\n        cv2.imread(os.path.join(prefix_path_data, \"datasetImage/file\", label['name'])),\n        512\n    )\n    imagesDataset[label['name']] = img","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process","metadata":{}},{"cell_type":"code","source":"print(len(labelDataset))\nprint(len(imagesDataset))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot analytic banlance dataset\n\ntotalLabelDataset = np.array([0] * 10)\nfor ele in labelDataset:\n    totalLabelDataset += ele[\"label\"]\n\nprint(totalLabelDataset)\n    \n# Draw\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labelDataset[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csvDataJSON = []\nlistGoodImage = []\nlabelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\nfor ele in labelDataset:\n    labelTemp = {}\n    for i in range(len(labelValue)):\n        labelTemp[labelValue[i]] = ele[\"label\"][i]\n    csvDataJSON.append({\n        \"file\": ele[\"name\"],\n        **labelTemp\n    })\n    listGoodImage.append(ele[\"name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create list good \nf = open(\"listimage.txt\", \"w\")\nf.write(\"\\n\".join(listGoodImage))\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note:\n# imagesDataset is an Dict key is name image, value is image data\n# Using: get image data of label name N => imagesDataset[N]\n# Get image data of label i => imagesDataset[labelDataset[i][\"name\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process data to send","metadata":{}},{"cell_type":"code","source":"from functools import cmp_to_key","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf compressImage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir compressImage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelDataset.sort(key=cmp_to_key(lambda x, y: y[\"total\"] - x[\"total\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listCompressConfig = [100, 80, 50, 30, 20, 10, 5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all label type 9\nlistAddionEle = []\nfor ele in labelDataset:\n    if ele[\"label\"][8] >= 1:\n        listAddionEle.append(ele)\n\nprint(len(listAddionEle))\n\n# Add image from labelDataset\nfor ele in labelDataset[0:400 - len(listAddionEle)]:\n    listAddionEle.append(ele)\n    \nprint(len(listAddionEle))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\ncsvDataJSON = []\ntotalLabelDataset = np.array([0] * 10)\ni = 0\nfor ele in listAddionEle:\n    i += 1\n    file_name = os.path.join(\"compressImage\", \"{0}.jpg\".format(i))\n    for j in range(len(listCompressConfig)):\n        cv2.imwrite(\n            file_name, imagesDataset[ele[\"name\"]],\n            [int(cv2.IMWRITE_JPEG_QUALITY), listCompressConfig[j]]\n        )\n        file_size = os.stat(file_name).st_size / 1024\n        if file_size <= 20.0:\n            break\n    file_size = os.stat(file_name).st_size / 1024\n    if file_size > 20.0:\n        print(\"Error outsize {0}\".format(i))\n        \n    # Add analytics\n    totalLabelDataset += ele[\"label\"]\n    \n    # Add csv\n    labelTemp = {}\n    for j in range(len(labelValue)):\n        labelTemp[labelValue[j]] = ele[\"label\"][j]\n    csvDataJSON.append({\n        \"file\": \"{0}.jpg\".format(i),\n        **labelTemp\n    })\n    \n# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)\n    \n# Draw\nprint(totalLabelDataset)\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r compressImage.zip compressImage","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"markdown","source":"### Analytics data","metadata":{}},{"cell_type":"code","source":"minLabel = np.amin(totalLabelDataset)\nprint(minLabel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ele in labelDataset:\n    print(ele)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label2str(label):\n    s = \"\"\n    for i in range(len(label)):\n        s += str(int(label[i]))\n    return s\ndef str2label(s):\n    label = []\n    for i in range(len(s)):\n        label.append(int(s[i]))\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tempCnumDimOnehot = {}\nfor ele in labelDataset:\n    tempCnumDimOnehot[label2str(ele[\"label\"])] = 1\nnumDimOnehot = len(tempCnumDimOnehot)\nprint(numDimOnehot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def index2onehot(index):\n    onehot = [0] * numDimOnehot\n    onehot[index] = 1\n    return onehot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot = {}\nfor ele in labelDataset:\n    if label2str(ele[\"label\"]) not in mapLabel2OneHot:\n        mapLabel2OneHot[label2str(ele[\"label\"])] = index2onehot(len(mapLabel2OneHot))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label = {}\nfor i in mapLabel2OneHot:\n    mapOneHot2Label[label2str(mapLabel2OneHot[i])] = str2label(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for ele in labelDataset:\n#     ele[\"label\"] = mapLabel2OneHot[label2str(ele[\"label\"])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoLabel2Onehot(label):\n    return mapLabel2OneHot[label2str(label)]\ndef autoOnehot2Label(onehot):\n    return mapOneHot2Label[label2str(onehot)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(autoOnehot2Label(autoLabel2Onehot([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot = {\n    '0100000100': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1010100000': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1010000000': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1001000000': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1000110000': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1000010000': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0100001000': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1000100000': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '1010010000': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0100000000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0100000001': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0100000010': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n    '0100010000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n    '1000000010': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n    '1001010000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n    '1000000000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n    '1011010000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n    '1011000000': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n    '1000000001': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n}\nmapOneHot2Label = {\n    '1000000000000000000': [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n    '0100000000000000000': [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n    '0010000000000000000': [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n    '0001000000000000000': [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n    '0000100000000000000': [1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n    '0000010000000000000': [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n    '0000001000000000000': [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n    '0000000100000000000': [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n    '0000000010000000000': [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n    '0000000001000000000': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0000000000100000000': [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n    '0000000000010000000': [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n    '0000000000001000000': [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n    '0000000000000100000': [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n    '0000000000000010000': [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n    '0000000000000001000': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    '0000000000000000100': [1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n    '0000000000000000010': [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n    '0000000000000000001': [1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process image","metadata":{}},{"cell_type":"markdown","source":"#### Constant","metadata":{}},{"cell_type":"code","source":"size_image_model = 224 # 224","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Helper function","metadata":{}},{"cell_type":"code","source":"def crop2nimage(image, nimage = 3):\n    # Size of bigest square image\n    sizeSquare = min(image.shape[0], image.shape[1])\n\n    # Rotate image if image is portrait\n    isRotate = False\n    if image.shape[0] > image.shape[1]:\n        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n        isRotate = True\n\n    # Crop n image\n    cropImages = []\n    widthBetween = (image.shape[1] - sizeSquare) / (nimage - 1)\n    for i in range(nimage):\n        x1 = int(i * widthBetween)\n        x2 = int(x1 + sizeSquare)\n        cropImages.append(image[:, x1:x2])\n\n    # Rotate image back\n    if isRotate:\n        for i in range(len(cropImages)):\n            cropImages[i] = cv2.rotate(cropImages[i], cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n    # Convert color to RGB\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.cvtColor(cropImages[i], cv2.COLOR_BGR2RGB)\n        \n    return cropImages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calibrate_image(image, target_size_kb=20):\n    # Resize image to the target size\n    resized_image = cv2.resize(image, (224, 224))\n\n    return resized_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation by type:\n# 1. Random flip\n# 2. Random rotate\n# 4. Random Saturate\n# 3. Random brightness\n# 5. Random crop\n\n# Random flip\ndef random_flip(image, p=0.5):\n    if np.random.rand() < p:\n        return cv2.flip(image, 1)\n    return image\n\n# Random rotate from range angle\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n    (in degrees). The returned image will be large enough to hold the entire\n    new image, with a black background\n    \"\"\"\n\n    # Get the image size\n    # No that's not an error - NumPy stores image matricies backwards\n    image_size = (image.shape[1], image.shape[0])\n    image_center = tuple(np.array(image_size) / 2)\n\n    # Convert the OpenCV 3x2 rotation matrix to 3x3\n    rot_mat = np.vstack(\n        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n    )\n\n    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n    # Shorthand for below calcs\n    image_w2 = image_size[0] * 0.5\n    image_h2 = image_size[1] * 0.5\n\n    # Obtain the rotated coordinates of the image corners\n    rotated_coords = [\n        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n    ]\n\n    # Find the size of the new image\n    x_coords = [pt[0] for pt in rotated_coords]\n    x_pos = [x for x in x_coords if x > 0]\n    x_neg = [x for x in x_coords if x < 0]\n\n    y_coords = [pt[1] for pt in rotated_coords]\n    y_pos = [y for y in y_coords if y > 0]\n    y_neg = [y for y in y_coords if y < 0]\n\n    right_bound = max(x_pos)\n    left_bound = min(x_neg)\n    top_bound = max(y_pos)\n    bot_bound = min(y_neg)\n\n    new_w = int(abs(right_bound - left_bound))\n    new_h = int(abs(top_bound - bot_bound))\n\n    # We require a translation matrix to keep the image centred\n    trans_mat = np.matrix([\n        [1, 0, int(new_w * 0.5 - image_w2)],\n        [0, 1, int(new_h * 0.5 - image_h2)],\n        [0, 0, 1]\n    ])\n\n    # Compute the tranform for the combined rotation and translation\n    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n    # Apply the transform\n    result = cv2.warpAffine(\n        image,\n        affine_mat,\n        (new_w, new_h),\n        flags=cv2.INTER_LINEAR\n    )\n\n    return result\n\ndef largest_rotated_rect(w, h, angle):\n    \"\"\"\n    Given a rectangle of size wxh that has been rotated by 'angle' (in\n    radians), computes the width and height of the largest possible\n    axis-aligned rectangle within the rotated rectangle.\n\n    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n\n    Converted to Python by Aaron Snoswell\n    \"\"\"\n\n    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n\n    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n\n    delta = math.pi - alpha - gamma\n\n    length = h if (w < h) else w\n\n    d = length * math.cos(alpha)\n    a = d * math.sin(alpha) / math.sin(delta)\n\n    y = a * math.cos(gamma)\n    x = y * math.tan(gamma)\n\n    return (\n        bb_w - 2 * x,\n        bb_h - 2 * y\n    )\n\ndef crop_around_center(image, width, height):\n    \"\"\"\n    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n    around it's centre point\n    \"\"\"\n\n    image_size = (image.shape[1], image.shape[0])\n    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n\n    if(width > image_size[0]):\n        width = image_size[0]\n\n    if(height > image_size[1]):\n        height = image_size[1]\n\n    x1 = int(image_center[0] - width * 0.5)\n    x2 = int(image_center[0] + width * 0.5)\n    y1 = int(image_center[1] - height * 0.5)\n    y2 = int(image_center[1] + height * 0.5)\n\n    return image[y1:y2, x1:x2]\n\ndef random_rotate(image, angle_range=20):\n    angle = np.random.uniform(-angle_range, angle_range)\n    image_height, image_width = image.shape[0:2]\n    image = crop_around_center(\n        rotate_image(image, angle),\n        *largest_rotated_rect(\n            image_width,\n            image_height,\n            math.radians(angle)\n        )\n    )\n    return image\n\n# Random saturate\ndef random_saturate(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 1] = hsv[:, :, 1] * np.random.uniform(low, high)\n    hsv[:, :, 1][hsv[:, :, 1] > 255] = 255\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random brightness\ndef random_brightness(image, low=0.3, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random crop\ndef random_crop_size(image, size=224):\n    x = np.random.randint(0, image.shape[1] - size)\n    y = np.random.randint(0, image.shape[0] - size)\n    return image[y:y+size, x:x+size]\n\n# Random augment\nRandomAugmentClass = tf.keras.preprocessing.image.ImageDataGenerator(\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    rotation_range=30,\n    brightness_range=[0.3,1.8],\n    zoom_range=[0.5,1.0],\n)\n\ndef random_augment(image):\n    image = np.copy(image)\n#     image = random_flip(image)\n#     image = random_rotate(image)\n#     image = random_saturate(image)\n#     image = random_brightness(image)\n#     image = random_crop_size(image, size_image_model)\n#     image = tf.image.random_crop(image, (size_image_model, size_image_model, 3)).numpy()\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = RandomAugmentClass.random_transform(image)\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random noise\ndef random_noise(image, present=0.05):\n    # Randome noice range [0, 255] with present 0.05\n    lran = int(-255 * present)\n    rran = int(255 * present)\n    noise = np.random.randint(lran, rran, image.shape)\n\n    # Add noise to image\n    image = cv2.add(image, noise, dtype=cv2.CV_8UC3)\n\n    return image\n\n# Random blur\ndef random_blur(image, win_size=(3, 3)):\n    image = cv2.GaussianBlur(image, win_size, 0)\n    return image","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torchvision.transforms.Normalize (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ndef torchNormalize(data: np.ndarray, mean: list[float], std: list[float], inplace=False) -> np.ndarray:\n    # Inplace operation check\n    if not inplace:\n        data = np.copy(data).astype(\"float32\")\n\n    # Convert mean and std to NumPy arrays with appropriate shape\n    mean = np.asarray(mean, dtype=data.dtype)\n    std = np.asarray(std, dtype=data.dtype)\n\n    # Perform normalization\n    return (data - data.mean()) / data.std() * std + mean","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hota_preprocess_input(x):\n#     return tf.keras.applications.efficientnet_v2.preprocess_input(np.copy(x))\n#     return tf.keras.applications.resnet_v2.preprocess_input(np.copy(x))\n    return tf.image.per_image_standardization(x).numpy()\n#     return torchNormalize(\n#         x,\n#         mean=[0.485, 0.456, 0.406],\n#         std=[0.229, 0.224, 0.225]\n#     )\n#     return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image","metadata":{}},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Apply to all image in dataset\nfor imageId in imagesDataset:\n    imagesDataset[imageId] = resize_image_reduce_size(imagesDataset[imageId], size_image_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imwrite(\"test.jpg\", imagesDataset[labelDataset[0][\"name\"]], [cv2.IMWRITE_JPEG_QUALITY, 50])\n# print(os.path.getsize('test.jpg')/1024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data augment","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split image name to label\n# tempImageLabelName = [[] for _ in range(numDimOnehot)]\n# for ele in labelDataset:\n#     for i in range(len(mapLabel2OneHot[label2str(ele[\"label\"])])):\n#         if mapLabel2OneHot[label2str(ele[\"label\"])][i] >= 1:\n#             tempImageLabelName[i].append(ele[\"name\"])\n\ntempImageLabelName = [[] for _ in range(10)]\nfor ele in labelDataset:\n# for ele in listAddionEle:\n    for i in range(len(ele[\"label\"])):\n        if ele[\"label\"][i] >= 1:\n            tempImageLabelName[i].append(ele[\"name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total len\ntotalTempImageLabelName = []\nfor i in range(len(tempImageLabelName)):\n    totalTempImageLabelName.append(len(tempImageLabelName[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amax(totalTempImageLabelName), np.amin(totalTempImageLabelName))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([i for i in totalTempImageLabelName if i > 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target number image each label after augment\ntarget_number_image = 1000\n\nimagesDatasetAug = []\nlabelDatasetAug = []\n# Augment image\nfor i in range(0, len(tempImageLabelName)):\n    print(\"Augment label: \", i)\n    print(\"Number image: \", len(tempImageLabelName[i]))\n    if totalTempImageLabelName[i] >= target_number_image or totalTempImageLabelName[i] == 0:\n        continue\n        \n    numDeltaAdd = target_number_image - totalTempImageLabelName[i]\n    for j in range(numDeltaAdd):\n        # Name image\n        imageName = tempImageLabelName[i][np.random.randint(0, len(tempImageLabelName[i]))]\n        # Random select image\n        image = imagesDataset[imageName]\n        image = random_augment(image)\n        imagesDatasetAug.append(image)\n        \n#         labelDatasetAug.append(autoLabel2Onehot(mapImageNameToLabel[imageName]))\n#         for k in range(len(autoLabel2Onehot(mapImageNameToLabel[imageName]))):\n#             if autoLabel2Onehot(mapImageNameToLabel[imageName])[k] >= 1:\n#                 totalTempImageLabelName[k] += 1\n        \n        labelDatasetAug.append(mapImageNameToLabel[imageName])\n        for k in range(len(mapImageNameToLabel[imageName])):\n            if mapImageNameToLabel[imageName][k] >= 1:\n                totalTempImageLabelName[k] += 1\n        \n#         totalTempImageLabelName[i] += 1","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(totalTempImageLabelName)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetAug), len(labelDatasetAug))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(imagesDatasetAug[124].astype(\"uint8\"))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labelDatasetAug[124])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imagesDatasetArray\nimagesDatasetArray = []\nlabelDatasetArray = []\n\nfor ele in labelDataset:\n# for ele in listAddionEle:\n    imagesDatasetArray.append(random_augment(imagesDataset[ele[\"name\"]]))\n    labelDatasetArray.append(ele[\"label\"])\n#     labelDatasetArray.append(autoLabel2Onehot(ele[\"label\"]))\n\nfor i in range(len(imagesDatasetAug)):\n    imagesDatasetArray.append(imagesDatasetAug[i])\n    labelDatasetArray.append(labelDatasetAug[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray), len(labelDatasetArray))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n# suffer\nzipImageDataset = list(zip(imagesDatasetArray, labelDatasetArray))\nrandom.shuffle(zipImageDataset)\nimagesDatasetArray, labelDatasetArray = zip(*zipImageDataset)\nimagesDatasetArray = list(imagesDatasetArray)\nlabelDatasetArray = list(labelDatasetArray)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image and add some noise and rotate","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3 = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(labelDatasetArray)):\n    image = np.copy(imagesDatasetArray[i])\n    \n    # Crop\n    cropImages = crop2nimage(image, 3)\n\n    # Resize\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.resize(cropImages[i], (size_image_model, size_image_model))\n\n    # Add blur to image\n    for i in range(len(cropImages)):\n        cropImages[i] = random_blur(cropImages[i], (3, 3))\n        \n    # Add noise to image\n    for i in range(len(cropImages)):\n        # Randome noice\n        cropImages[i] = random_noise(cropImages[i], 0.1)\n\n    # Debug\n#     for i in range(len(cropImages)):\n#         plt.imshow(cropImages[i])\n#         plt.show()\n#     break\n\n    imagesDatasetArray3.append([cropImages[1]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray3), len(imagesDatasetArray3[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"markdown","source":"### Normal image","metadata":{}},{"cell_type":"markdown","source":"### Import library","metadata":{}},{"cell_type":"markdown","source":"### Split testcase","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3_training = []\nlabelDatasetArray_training = []\nimagesDatasetArray3_testing = []\nlabelDatasetArray_testing = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = [i for i in range(len(imagesDatasetArray3))]\nnp.random.shuffle(idx)\n\nfor i in range(len(idx)):\n    if i < len(idx) * 0.3:\n        imagesDatasetArray3_training.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_training.append(labelDatasetArray[idx[i]])\n    else:\n        imagesDatasetArray3_testing.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_testing.append(labelDatasetArray[idx[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy\nfor i in range(len(imagesDatasetArray3_training)):\n    imagesDatasetArray3_training[i] = [\n        hota_preprocess_input(np.array(imagesDatasetArray3_training[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_training[i]))\n    ]\n    labelDatasetArray_training[i] = np.array(labelDatasetArray_training[i], dtype=np.float32)\n    \nfor i in range(len(imagesDatasetArray3_testing)):\n    imagesDatasetArray3_testing[i] = [\n        hota_preprocess_input(np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_testing[i]))\n    ]\n    labelDatasetArray_testing[i] = np.array(labelDatasetArray_testing[i], dtype=np.float32)\n\n# imagesDatasetArray3_training = np.array(imagesDatasetArray3_training, dtype=np.float32) / 255.0\n# labelDatasetArray_training = np.array(labelDatasetArray_training, dtype=np.float32)\n# imagesDatasetArray3_testing = np.array(imagesDatasetArray3_testing, dtype=np.float32) / 255.0\n# labelDatasetArray_testing = np.array(labelDatasetArray_testing, dtype=np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build dataset with batch","metadata":{}},{"cell_type":"code","source":"def create_batch_from_arr(arrData, batch_size=64):\n    temp_shape = list(arrData.shape)\n    deltaMiss = ((arrData.shape[0] + batch_size - 1) // batch_size) * batch_size - arrData.shape[0]\n    temp_shape[0] += deltaMiss\n    batchArrData = np.zeros(tuple(temp_shape), dtype=np.float32)\n    # Add to last\n    batchArrData[:arrData.shape[0]] = arrData\n    for i in range(arrData.shape[0], batchArrData.shape[0]):\n        batchArrData[i] = arrData[i - arrData.shape[0]]\n        \n    batchArrData = batchArrData.reshape(tuple([-1, batch_size, *list(batchArrData.shape[1:])]))\n    \n    return batchArrData\n\ndef create_dataset(images, labels, batch_size=64):\n    if batch_size == 0:\n        return (np.array(images, dtype=np.float32), np.array(labels, dtype=np.float32))\n    images = np.array(images, dtype=np.float32)\n    # image is 3 image in array\n    tempImageSplit = []\n    for i in range(images.shape[1]):\n        tempImageSplit.append(create_batch_from_arr(images[:, i], batch_size))\n\n    imagesBatch = []\n    for i in range(len(tempImageSplit[0])):\n        nimage = []\n        for j in range(len(tempImageSplit)):\n            nimage.append(tempImageSplit[j][i])\n        imagesBatch.append(nimage)\n        \n    labels = np.array(labels, dtype=np.float32)\n    labels = create_batch_from_arr(labels, batch_size)\n    \n    return (np.array(imagesBatch), labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 0)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(datasetTraining[0][2][0]), np.amax(datasetTraining[0][2][0]))\nprint(np.mean(datasetTraining[0][2][0]), np.std(datasetTraining[0][2][0]))\nprint(datasetTraining[1][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Init model","metadata":{}},{"cell_type":"code","source":"# Using dataset imagesDatasetArray3 and labelDatasetArray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vit_tensorflow.vit import Transformer\nimport tensorflow.keras.layers as nn\nfrom tensorflow import einsum\nfrom einops import rearrange, repeat\nfrom einops.layers.tensorflow import Rearrange\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViT(tf.keras.layers.Layer):\n    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim,\n                 pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n        super(ViT, self).__init__()\n\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n        \n        self.trearragnge = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n        self.patch_embedding = tf.keras.Sequential([\n            nn.Dense(units=dim)\n        ], name='patch_embedding')\n\n        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches + 1, dim]))\n        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, dim]))\n        self.dropout = nn.Dropout(rate=emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        \n        self.num_classes = num_classes\n\n        self.mlp_head = tf.keras.Sequential([\n            nn.LayerNormalization(),\n            nn.Dense(units=num_classes)\n        ], name='mlp_head')\n        \n    def build(self, input_shape):\n        super(ViT, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, img, training=True, **kwargs):\n        x = self.trearragnge(img)\n        x = self.patch_embedding(x)\n        b, n, d = x.shape\n        \n        cls_tokens = repeat(self.cls_token, 'n d -> b n d', b=b)\n        x = tf.concat([cls_tokens, x], axis=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x, training=training)\n\n        x = self.transformer(x, training=training)\n\n        if self.pool == 'mean':\n            x = tf.reduce_mean(x, axis=1)\n        else:\n            x = x[:, 0]\n\n        x = self.mlp_head(x)\n\n        return x\n    \n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.num_classes)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hotaConv2D(*arg, **kwarg):\n    return tf.keras.layers.Conv2D(*arg, **kwarg) # , kernel_initializer=\"he_uniform\"\ndef hotaDense(*arg, **kwarg):\n    return tf.keras.layers.Dense(*arg, **kwarg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = hotaConv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization()(x) # axis=3\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = hotaConv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n#     x = hotaConv2D(filter, (1,1), padding = 'same', strides = (2,2))(x)\n    return x\ndef convolutional_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = hotaConv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = hotaConv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    # Processing Residue with conv(1,1)\n    x_skip = hotaConv2D(filter, (1,1), strides = (2,2))(x_skip)\n#     x_skip = tf.keras.layers.BatchNormalization()(x_skip)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n#     x = hotaConv2D(filter, (1,1), padding = 'same', strides = (2,2))(x)\n    return x\ndef ResNet(shape = (224, 224, 3), block_layers = [3, 4, 6, 3], using_top_layer = True, classes = 10, activation_class=\"softmax\"):\n    # Step 1 (Setup Input Layer)\n    x_input = tf.keras.layers.Input(shape)\n    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n    # Step 2 (Initial Conv layer along with maxPool)\n    x = hotaConv2D(64, kernel_size=7, strides=2, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    # Define size of sub-blocks and initial filter size\n    filter_size = 64\n    # Step 3 Add the Resnet Blocks\n    for i in range(4):\n        if i == 0:\n            # For sub-block 1 Residual/Convolutional block not needed\n            for j in range(block_layers[i]):\n                x = identity_block(x, filter_size)\n        else:\n            # One Residual/Convolutional Block followed by Identity blocks\n            # The filter size will go on increasing by a factor of 2\n            filter_size = filter_size*2\n            x = convolutional_block(x, filter_size)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filter_size)\n    # Step 4 End Dense Network\n#     x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = hotaDense(512, activation = 'relu')(x)\n    if using_top_layer:\n#         if activation_class == \"sigmoid\":\n#             x = [hotaDense(1, activation = activation_class)(x) for i in range(classes)]\n#         else:\n        x = hotaDense(classes, activation = activation_class)(x)\n    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet12\")\n    return model","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hotaBlockImage(index):\n    # Build model flow\n#     inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n#     model = tf.keras.applications.EfficientNetV2S(\n#         include_top=True,\n#         weights=None, # 'imagenet'\n#         input_tensor=inputTensor,\n#         input_shape=None,\n#         pooling=None,\n#         classes=512,\n#         classifier_activation='relu', # softmax\n#         include_preprocessing=False\n#     )\n\n#     # Rename layer\n#     layer_names=[layer.name for layer in model.layers]\n#     for layer_name in layer_names:\n#         model.get_layer(name=layer_name).name = \"{0}_{1}\".format(layer_name, index)\n\n#     return model\n    \n#     model = ViT(\n#         image_size = (size_image_model, size_image_model),\n#         patch_size = 32,\n#         num_classes = 1000,\n#         dim = 1024,\n#         depth = 6,\n#         heads = 16,\n#         mlp_dim = 2048,\n#         dropout = 0.1,\n#         emb_dropout = 0.1\n#     )(inputTensor)\n        \n#     return tf.keras.Model(inputs=inputTensor, outputs=model)\n#     return ResNet(\n#         shape = (128, 128, 3), block_layers = [3, 3, 3, 3], using_top_layer = False, classes = 10, activation_class=\"softmax\"\n#     )\n    pass\ndef hotaNBlockImage(nblock = 3):\n#     inputs = []\n#     hidden_outputs = []\n#     for i in range(nblock):\n#         temp_model = hotaBlockImage(i)\n# #         inputs.append(temp_model.input[0]) # Application\n#         inputs.append(temp_model.input)\n#         hidden_outputs.append(temp_model.output)\n        \n#     combined = tf.keras.layers.Concatenate()(hidden_outputs)\n#     outputflatten = tf.keras.layers.Flatten()(combined)\n    \n#     hidden_outputs_2 = hotaDense(512, activation=\"relu\")(outputflatten)\n# #     outputs = hotaDense(numDimOnehot, activation=\"softmax\")(hidden_outputs_2)\n#     outputs = hotaDense(10, activation=\"sigmoid\")(hidden_outputs_2)\n    \n#     return tf.keras.Model(inputs=inputs, outputs=outputs)\n#     return hotaBlockImage(0)\n\n#     return ResNet(\n#         shape = (size_image_model, size_image_model, 3),\n#         block_layers = [3, 4, 6, 3],\n#         using_top_layer = True,\n#         classes = 10,\n#         activation_class=\"sigmoid\"\n#     )\n#     inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n#     return tf.keras.applications.EfficientNetV2S(\n#         include_top=True,\n#         weights=None, # 'imagenet'\n#         input_tensor=inputTensor,\n#         input_shape=None,\n#         pooling=None,\n#         classes=10, # 19\n#         classifier_activation='sigmoid', # softmax\n#         include_preprocessing=False\n#     )\n\n#     inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n#     return tf.keras.applications.ResNet50V2(\n#         include_top=True,\n#         weights=None,\n#         input_tensor=inputTensor,\n#         input_shape=None,\n#         pooling=None,\n#         classes=10,\n#         classifier_activation='sigmoid'\n#     )\n\n    inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n    return tf.keras.applications.EfficientNetB0(\n        include_top=True,\n        weights=None,\n        input_tensor=inputTensor,\n        input_shape=None,\n        pooling=None,\n        classes=10,\n        classifier_activation='sigmoid'\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatNumpy2List(data):\n    listData = []\n    for i in range(data.shape[0]):\n        listData.append(data[i])\n        \n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatListMap2MapList(data):\n    listData = []\n    for i in range(data.shape[1]):\n        listData.append(data[:, i])\n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU Training","metadata":{}},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = hotaNBlockImage(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.keras.utils.plot_model(hotaModel, show_shapes=True, expand_nested=True, dpi=40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n\"\"\"\nBinaryFocalCrossentropy(\n    apply_class_balancing=True,\n    alpha=0.92,\n    gamma=2.0,\n)\nBinaryCrossentropy(reduction=\"sum\")\n\"\"\"\n# lossFc = [tf.keras.losses.BinaryCrossentropy() for _ in range(10)]\nlossFc = tf.keras.losses.BinaryCrossentropy()\nlistMetrics = [\n    tf.keras.metrics.BinaryAccuracy(threshold=0.5, name=\"accuracy\"), # BinaryAccuracy CategoricalAccuracy\n    tf.keras.metrics.AUC(multi_label=True, num_labels=10, name=\"auc\"),\n    tf.keras.metrics.F1Score(average=\"micro\", threshold=0.5, name=\"f1\"),\n    tf.keras.metrics.TruePositives(name='tp'),\n    tf.keras.metrics.FalsePositives(name='fp'),\n    tf.keras.metrics.TrueNegatives(name='tn'),\n    tf.keras.metrics.FalseNegatives(name='fn'), \n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall'),\n]\nhotaModel.compile(loss=lossFc, optimizer=opt, metrics=listMetrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasetTrainingYSigmoid = [list(datasetTraining[1][i]) for i in range(len(datasetTraining[1]))]\n# datasetTrainingYSigmoid = list(zip(*datasetTrainingYSigmoid))\n# for i in range(len(datasetTrainingYSigmoid)):\n#     datasetTrainingYSigmoid[i] = np.array(datasetTrainingYSigmoid[i], dtype=\"float32\").reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=3)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"saved_checkpoint/checkpoint.weights.h5\",\n    save_weights_only=True,\n    monitor='val_auc', # val_auc val_accuracy\n    mode='max',\n    save_best_only=True\n)\nhistoryTrain = hotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=24,\n    epochs=300,\n    callbacks=[callbackEarlyStop, model_checkpoint_callback],\n    verbose=1,\n    validation_split=0.2,\n    shuffle=True,\n    initial_epoch=0,\n#     class_weight={0: 1, 1: 10}\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(historyTrain.history[\"loss\"])\nplt.plot(historyTrain.history[\"val_loss\"])\nplt.show()\nplt.plot(historyTrain.history[\"accuracy\"])\nplt.plot(historyTrain.history[\"val_accuracy\"])\nplt.show()\nplt.plot(historyTrain.history[\"f1\"])\n# plt.show()\nplt.plot(historyTrain.history[\"val_f1\"])\nplt.show()\nplt.plot(historyTrain.history[\"auc\"])\nplt.plot(historyTrain.history[\"val_auc\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.load_weights(\"saved_checkpoint/checkpoint.weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TPU Training","metadata":{}},{"cell_type":"code","source":"try: # detect TPUs\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.TPUStrategy(resolver)\n    \n    print('Running on TPU ', resolver.master())\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    hotaModel = hotaNBlockImage(3)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n#     opt = tf.keras.optimizers.SGD(learning_rate=1e-1)\n    # CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n    lossFc = tf.keras.losses.CategoricalCrossentropy()\n    hotaModel.compile(loss=lossFc, optimizer=opt, metrics=[\n        # BinaryAccuracy CategoricalAccuracy\n        tf.keras.metrics.CategoricalAccuracy(\"accuracy\"),\n        tf.keras.metrics.AUC(name=\"auc\"),\n        tf.keras.metrics.F1Score(name=\"f1\"),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 4 * 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = int(xTrainignInput[0].shape[0] * 0.8)//batch_size\nvalidation_steps = int(xTrainignInput[0].shape[0] * 0.2)//batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=3)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"saved_checkpoint/checkpoint.keras\",\n    save_weights_only=False,\n    monitor='val_accuracy', # val_auc val_accuracy\n    mode='max',\n    save_best_only=True\n)\nhistoryTrain = hotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=batch_size,\n    epochs=300,\n    callbacks=[\n        callbackEarlyStop,\n        model_checkpoint_callback\n    ],\n    verbose=1,\n    validation_split=0.2,\n    shuffle=True,\n#     initial_epoch=0,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(historyTrain.history[\"accuracy\"])\nplt.plot(historyTrain.history[\"val_accuracy\"])\nplt.show()\nplt.plot(historyTrain.history[\"f1\"])\nplt.plot(historyTrain.history[\"val_f1\"])\nplt.show()\nplt.plot(historyTrain.history[\"auc\"])\nplt.plot(historyTrain.history[\"val_auc\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = tf.keras.models.load_model(\"saved_checkpoint/checkpoint.keras\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=batch_size,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test predit model","metadata":{}},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].astype(\"float32\").reshape((1, size_image_model, size_image_model, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n        elif type_format == 3:\n            image[i] = hota_preprocess_input(image[i])\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 131\nfor i in range(len(imagesDatasetArray3[testcase])):\n    plt.imshow(imagesDatasetArray3[testcase][i])\n    plt.show()\nprint(predict2binary(hotaModel.predict(\n    autoFormatInput2PreditOutput(\n        hota_preprocess_input(imagesDatasetArray3[testcase])\n    ),\n    batch_size=1\n)))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save model","metadata":{}},{"cell_type":"code","source":"!mkdir saved_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"hotaEfficientNetB0_sigmoid_128x128_v6.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only use for TPU\nwith strategy.scope():\n    hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel = hotaModel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Upload to huggingface","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf_write = user_secrets.get_secret(\"HUGGINGFACE_WRITE_TOKEN\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf_write","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=os.path.join(\"/kaggle/working/saved_model\", model_name),\n    path_in_repo=model_name,\n    repo_id=\"hotamago/deep-learning-and-application-group-02\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load and testing model","metadata":{}},{"cell_type":"code","source":"model_name = \"hotaResnet50V2_sigmoid_128x128_v6.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/deep-learning-and-application-group-02\", filename=model_name, revision=\"main\", repo_type=\"model\", local_dir=\"saved_model\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel = tf.keras.models.load_model(os.path.join('saved_model', model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\ntestModel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(\n        from_logits = False,\n    ),\n    optimizer=opt,\n    metrics=[\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.AUC(),\n        tf.keras.metrics.F1Score(),\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, 224, 224, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image\ndef formatSoftmaxOutput(label):\n    for bat in range(len(label)):\n        indexOne = np.argmax(label[bat])\n        for i in range(len(label[bat])):\n            label[bat][i] = 0\n        label[bat][indexOne] = 1\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 874\n# for i in range(len(imagesDatasetArray3[testcase])):\n#     plt.imshow(imagesDatasetArray3[testcase][i])\n#     plt.show()\nplt.imshow(imagesDatasetArray3[testcase][1])\nplt.show()\nprint(autoOnehot2Label(formatSoftmaxOutput(\n    testModel.predict(\n        autoFormatInput2PreditOutput(\n            formatImageInput(np.copy(imagesDatasetArray3[testcase]).astype('float32'), 2)\n        ),\n        batch_size=1\n    )\n)[0]))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test convert for softmax","metadata":{}},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 64)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaMetrics = [\n    tf.keras.metrics.BinaryAccuracy(threshold=0.5, name=\"accuracy\"), # BinaryAccuracy CategoricalAccuracy\n    tf.keras.metrics.AUC(multi_label=True, num_labels=10, name=\"auc\"),\n    tf.keras.metrics.F1Score(average=\"micro\", threshold=0.5, name=\"f1\"),\n    tf.keras.metrics.TruePositives(name='tp'),\n    tf.keras.metrics.FalsePositives(name='fp'),\n    tf.keras.metrics.TrueNegatives(name='tn'),\n    tf.keras.metrics.FalseNegatives(name='fn'), \n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall'),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertFirst2List(image):\n    return [i for i in image]\ndef autoOnehot2LabelBatch(onehots):\n    labels = []\n    for i in range(len(onehots)):\n        labels.append(autoOnehot2Label(onehots[i]))\n    return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataRunSoft = datasetTesting # datasetTesting datasetTraining\nfor j in range(len(hotaMetrics)):\n    hotaMetrics[j].reset_state()\nfor i in range(len(dataRunSoft[0])):\n    testcaseImage = dataRunSoft[0][i]\n    testcaseLabel = autoOnehot2LabelBatch(np.copy(dataRunSoft[1][i]).astype('float32'))\n    \n    predictOut = np.array(autoOnehot2LabelBatch(formatSoftmaxOutput(\n        testModel.predict(\n            convertFirst2List(np.copy(testcaseImage).astype('float32')),\n            batch_size=64\n        )\n    )), dtype=np.float32)\n    \n    # update metrics\n    for j in range(len(hotaMetrics)):\n        hotaMetrics[j].update_state(testcaseLabel, predictOut)\n    \n    # Print\n    print(\"Done {0} / {1} batch\".format(i + 1, len(dataRunSoft[0])))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(len(hotaMetrics)):\n    print(\"{0}: {1}\".format(hotaMetrics[j].name, hotaMetrics[j].result()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine tuning","metadata":{}},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5)\ntestModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=8,\n    epochs=100,\n    callbacks=[callback],\n    verbose=1,\n    validation_split=0.3,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run final testset","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(\n    repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\",\n    filename=\"TestSet.zip\",\n    revision=\"main\",\n    repo_type=\"dataset\",\n    local_dir=\"dataset\",\n    local_dir_use_symlinks=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir testsetImage\n!unzip -q -o \"dataset/TestSet.zip\" -d \"testsetImage\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load label\nwith open(os.path.join(\"testsetImage\",\"Images\",\"test.txt\"), \"r\") as f:\n    rawlabel = f.read()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelStruct = rawlabel.split(\"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelOnlyStruct = labelStruct[12:-2]\nfor i in range(len(labelOnlyStruct)):\n    labelOnlyStruct[i] = labelOnlyStruct[i].split(\",\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shapeList = []\nfor label in labelOnlyStruct:\n    img = cv2.imread(os.path.join(\"testsetImage\", \"Images\", label[0]))\n    shapeList.append(np.array(img.shape, dtype=\"int16\"))\nshapeList = np.array(shapeList)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.min(shapeList[:, 0]), np.min(shapeList[:, 1]))\nprint(np.max(shapeList[:, 0]), np.max(shapeList[:, 1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load image\nimagesTestset = {}\nfor label in labelOnlyStruct:\n    img = resize_image_reduce_size(\n        cv2.imread(os.path.join(\"testsetImage\", \"Images\", label[0])),\n        512\n    )\n    imagesTestset[label[0]] = img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(imagesTestset[\"1.jpg\"])\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Apply to all image in dataset\nfor label in labelOnlyStruct:\n    imagesTestset[label[0]] = resize_image_reduce_size(imagesTestset[label[0]], size_image_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagesTestsetArray3=[]\nfor i in range(len(labelOnlyStruct)):\n    image = np.copy(imagesTestset[labelOnlyStruct[i][0]])\n    \n    # Crop\n    cropImages = crop2nimage(image, 3)\n\n    # Resize\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.resize(cropImages[i], (size_image_model, size_image_model))\n\n    # Add blur to image\n    for i in range(len(cropImages)):\n        cropImages[i] = random_blur(cropImages[i], (3, 3))\n        \n    # Add noise to image\n#     for i in range(len(cropImages)):\n#         # Randome noice\n#         cropImages[i] = random_noise(cropImages[i], 0.1)\n\n    # Debug\n#     for i in range(len(cropImages)):\n#         plt.imshow(cropImages[i])\n#         plt.show()\n#     break\n\n    imagesTestsetArray3.append([cropImages[1]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesTestsetArray3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"hotaResnet50V2_sigmoid_224x224_v5.keras\" # hotaResnet12_sigmoid_128x128_v4 hotaEfficientNetV2S_sigmoid_224x224_v4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/deep-learning-and-application-group-02\", filename=model_name, revision=\"main\", repo_type=\"model\", local_dir=\"saved_model\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel = tf.keras.models.load_model(os.path.join('saved_model', model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, size_image_model, size_image_model, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image\ndef formatSoftmaxOutput(label):\n    for bat in range(len(label)):\n        indexOne = np.argmax(label[bat])\n        for i in range(len(label[bat])):\n            label[bat][i] = 0\n        label[bat][indexOne] = 1\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagesTestsetArray3[0][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = imagesTestsetArray3[10][0]\nplt.imshow(image)\nplt.show()\nimageData = hota_preprocess_input(image.reshape(([1, *image.shape])))\n# autoOnehot2Label(formatSoftmaxOutput(testModel.predict(\n#     imageData\n# ))[0])\nprint(predict2binary(testModel.predict(\n    imageData\n))[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testModel.predict(\n    imageData\n))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build batch for predict\nbatch_test_size = 64\nimagesTestsetArray3Batch = []\nfor i in range(0, len(imagesTestsetArray3), batch_test_size):\n    imagesTestsetArray3Batch_temp = []\n    for j in range(i, min(i+batch_test_size, len(imagesTestsetArray3))):\n        imagesTestsetArray3Batch_temp.append(\n            imagesTestsetArray3[j][0]\n        )\n    imagesTestsetArray3Batch.append(\n        hota_preprocess_input(\n            np.array(imagesTestsetArray3Batch_temp, dtype=\"float32\")\n        )\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputOfTestset = []\nfor i in range(len(imagesTestsetArray3Batch)):\n#     labelBatch = formatSoftmaxOutput(testModel.predict(\n#         imagesTestsetArray3Batch[i]\n#     ))\n    labelBatch = predict2binary(testModel.predict(\n        imagesTestsetArray3Batch[i]\n    ))\n    for j in range(len(labelBatch)):\n        outputOfTestset.append(list(map(int, labelBatch[j])))\n#         outputOfTestset.append(autoOnehot2Label(labelBatch[j]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listAddPoint = [\n    [0, 2, 3, 4, 5, 8],\n    [1, 4, 5, 6, 7, 8, 9],\n]\ndef applyLogicLabel(label):\n    # Caculate point\n    pointTemp = [0] * len(listAddPoint)\n    for i in range(len(label)):\n        if int(label[i]) == 0:\n            continue\n        for j in range(len(listAddPoint)):\n            if i in listAddPoint[j]:\n                pointTemp[j] += 1\n    # Find max\n    pointJ, indexJ = 0, 0\n    for j in range(len(pointTemp)):\n        if pointJ < pointTemp[j]:\n            pointJ = pointTemp[j]\n            indexJ = j\n    # Flter label\n    labelRes = [0]*len(label)\n    for i in range(len(label)):\n        if int(label[i]) == 1 and (i in listAddPoint[indexJ]):\n            labelRes[i] = 1\n    # Add location\n    labelRes[indexJ] = 1\n    \n    return labelRes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(labelStruct[12:-2])):\n    labelData = labelStruct[i + 12].split(\",\")\n    labelData[1:] = list(map(str, applyLogicLabel(outputOfTestset[i])))\n    labelStruct[i + 12] = \",\".join(labelData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\".join(labelStruct))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"Team_2_Submission_4.txt\", \"w\") as f:\n    f.write(\"\\n\".join(labelStruct))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertBinVec2LabelList(binVec):\n    labels = []\n    for i in range(len(binVec)):\n        if binVec[i] > 0.5:\n            labels.append(labelValue[i])\n    return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compareRes12 = \"\"\"\nAnh : A\nHoGuom : HG\nHoTay : HT\nThapRua : TR\nCauTheHuc : CTH\nBuuDien : BD\nVuonHoa : VH\nChuaTranQuoc : CTQ\nDenQuanThanh : DQT\nKhachSan : KS\nCongVienNuoc : CVN\nA,HG,HT,TR,CTH,BD,VH,CTQ,DQT,KS,CVN\n167.jpg,1,0,0,1,0,0,0,0,0,0\n211.jpg,0,1,0,0,0,0,0,0,0,0\n262.jpg,0,1,0,0,0,0,1,0,0,0\n248.jpg,1,0,0,0,0,0,0,0,1,0\n117.jpg,1,0,1,0,0,0,0,0,0,0\n95.jpg,1,0,1,0,0,0,0,0,0,0\n127.jpg,0,1,0,0,0,0,0,0,0,0\n75.jpg,1,0,1,0,0,0,0,0,0,0\n32.jpg,1,0,0,0,0,0,0,0,1,0\n227.jpg,1,0,0,0,0,0,0,0,0,0\n53.jpg,1,0,0,1,0,0,0,0,0,0\n39.jpg,1,0,1,0,0,0,0,0,0,0\n296.jpg,0,1,0,0,0,0,0,0,0,0\n52.jpg,1,0,1,0,1,0,0,0,0,0\n134.jpg,1,0,1,0,0,0,0,0,0,0\n37.jpg,1,0,0,0,0,0,0,0,1,0\n84.jpg,1,0,0,1,0,0,0,0,0,0\n68.jpg,1,0,0,1,0,0,0,0,0,0\n16.jpg,1,0,0,0,0,0,0,0,0,0\n58.jpg,1,0,0,1,0,0,0,0,0,0\n299.jpg,0,1,0,0,0,0,1,0,0,0\n153.jpg,1,0,0,0,0,0,0,0,1,0\n56.jpg,1,0,0,1,0,0,0,0,0,0\n275.jpg,1,0,0,0,0,0,0,0,0,1\n43.jpg,1,0,1,0,0,0,0,0,0,0\n198.jpg,1,0,1,0,0,0,0,0,0,0\n172.jpg,1,0,0,1,0,0,0,0,0,0\n283.jpg,1,0,0,1,0,0,0,0,0,0\n206.jpg,1,0,0,0,0,0,0,0,0,1\n274.jpg,0,1,0,0,0,0,0,0,0,1\n209.jpg,0,1,0,0,0,0,0,0,1,0\n190.jpg,1,0,0,0,0,0,0,0,0,0\n183.jpg,0,1,0,0,0,0,0,0,0,0\n54.jpg,1,0,0,0,0,0,0,0,1,0\n114.jpg,0,1,0,0,0,0,0,0,0,0\n14.jpg,1,0,0,0,0,0,0,0,1,0\n236.jpg,1,0,0,0,0,0,0,0,1,0\n123.jpg,1,0,0,0,0,0,0,0,1,0\n31.jpg,1,0,0,0,0,0,0,0,0,0\n122.jpg,0,1,0,0,0,0,0,0,1,1\n25.jpg,1,0,0,0,0,0,0,0,1,0\n197.jpg,0,1,0,0,0,0,0,0,0,1\n10.jpg,1,0,0,1,0,0,0,0,0,0\n18.jpg,1,0,0,0,0,0,0,0,0,0\n204.jpg,1,0,0,0,0,0,0,0,0,0\n231.jpg,1,0,0,1,0,0,0,0,0,0\n4.jpg,1,0,0,0,0,0,0,0,1,0\n73.jpg,1,0,1,1,0,0,0,0,0,0\n77.jpg,1,0,1,0,0,0,0,0,0,0\n50.jpg,1,0,1,1,0,0,0,0,0,0\n171.jpg,0,1,0,0,0,0,0,0,1,0\n163.jpg,1,0,0,1,0,0,0,0,0,0\n189.jpg,1,0,0,0,0,0,0,0,0,0\n81.jpg,1,0,1,0,0,0,0,0,0,0\n221.jpg,1,0,0,0,0,0,1,0,0,0\n91.jpg,1,0,1,0,0,0,0,0,0,0\n12.jpg,1,0,0,0,0,0,0,0,0,0\n101.jpg,1,0,0,1,0,0,0,0,0,0\n300.jpg,0,1,0,0,0,0,0,0,0,0\n170.jpg,1,0,0,0,0,0,0,0,1,0\n162.jpg,1,0,0,0,0,0,0,0,0,0\n240.jpg,1,0,0,0,0,0,0,0,1,0\n102.jpg,0,1,0,0,0,0,0,0,1,0\n181.jpg,0,1,0,0,0,1,0,0,0,0\n241.jpg,1,0,0,0,0,0,0,0,1,0\n203.jpg,1,0,0,0,0,0,1,0,0,0\n200.jpg,0,1,0,0,0,0,0,0,0,0\n108.jpg,0,1,0,0,0,0,0,0,1,0\n279.jpg,1,0,0,1,0,0,0,0,0,0\n193.jpg,1,0,0,0,0,1,0,0,0,0\n115.jpg,1,0,1,0,0,0,0,0,0,0\n270.jpg,0,1,0,0,0,0,0,0,0,0\n182.jpg,1,0,0,0,0,0,0,0,0,0\n169.jpg,1,0,0,0,0,0,0,0,1,0\n124.jpg,0,1,0,0,0,0,0,0,1,0\n254.jpg,1,0,0,0,0,0,0,0,1,0\n126.jpg,1,0,0,1,0,0,0,0,0,0\n247.jpg,1,0,0,0,0,0,0,0,1,0\n136.jpg,1,0,0,0,0,0,0,0,0,0\n184.jpg,1,0,1,0,0,0,0,0,0,0\n119.jpg,0,1,0,0,0,0,0,0,0,0\n71.jpg,1,0,1,0,0,0,0,0,0,0\n237.jpg,0,1,0,0,0,0,0,0,1,0\n62.jpg,1,0,1,0,0,0,0,0,0,0\n6.jpg,1,0,0,1,0,0,0,0,0,0\n159.jpg,1,0,0,0,0,0,1,0,0,0\n99.jpg,1,0,0,1,0,0,0,0,0,0\n48.jpg,1,0,1,0,0,0,0,0,0,0\n264.jpg,0,1,0,0,0,0,1,0,0,0\n85.jpg,1,0,1,0,0,0,0,0,0,0\n79.jpg,1,0,1,0,0,0,0,0,0,0\n142.jpg,1,0,0,0,0,0,0,0,1,0\n194.jpg,0,1,0,0,0,0,0,0,1,0\n90.jpg,1,0,0,0,0,0,0,0,1,0\n111.jpg,0,1,0,0,0,0,0,0,0,0\n106.jpg,1,0,0,1,0,0,0,0,0,0\n202.jpg,1,0,1,0,0,0,0,0,0,0\n277.jpg,0,1,0,0,0,0,0,0,0,1\n35.jpg,1,0,0,0,0,0,0,0,1,0\n179.jpg,0,1,0,0,0,0,0,0,1,0\n199.jpg,0,1,0,0,0,0,0,0,0,1\n185.jpg,0,0,0,0,0,0,0,0,0,0\n233.jpg,1,0,0,1,0,0,0,0,0,0\n220.jpg,0,1,0,0,0,0,1,0,0,0\n188.jpg,1,0,1,0,0,0,0,0,0,0\n96.jpg,1,0,1,0,0,0,0,0,0,0\n186.jpg,1,0,1,0,0,1,0,0,0,0\n278.jpg,0,1,0,0,0,0,0,0,0,0\n78.jpg,1,0,1,0,0,0,0,0,0,0\n11.jpg,1,0,0,0,0,0,0,0,1,0\n157.jpg,1,0,0,1,0,0,0,0,0,0\n286.jpg,1,0,0,0,0,0,0,0,0,1\n155.jpg,1,0,0,0,0,0,0,0,0,0\n110.jpg,0,1,0,0,0,0,0,0,1,0\n168.jpg,1,0,1,0,0,0,0,0,0,0\n173.jpg,1,0,0,1,0,0,0,0,0,0\n139.jpg,0,1,0,0,0,0,0,0,1,0\n30.jpg,1,0,0,0,0,0,0,0,1,0\n282.jpg,1,0,0,0,0,0,0,0,0,1\n276.jpg,0,1,0,0,0,0,0,0,0,1\n218.jpg,1,0,0,1,0,0,0,0,0,0\n29.jpg,1,0,1,0,0,0,0,0,0,0\n294.jpg,0,1,0,0,0,0,0,0,0,1\n284.jpg,1,0,0,1,0,0,0,0,0,0\n267.jpg,1,0,0,1,0,0,0,0,0,0\n261.jpg,0,1,0,0,0,0,0,0,0,0\n290.jpg,0,1,0,0,0,0,1,0,0,0\n137.jpg,1,0,0,1,0,0,0,0,0,0\n239.jpg,1,0,0,0,0,0,0,0,1,0\n15.jpg,1,0,0,0,0,0,0,0,0,0\n251.jpg,1,0,0,0,0,0,0,0,1,0\n55.jpg,1,0,0,1,0,0,0,0,0,0\n297.jpg,0,1,0,0,0,0,0,0,0,1\n100.jpg,1,0,0,1,0,0,0,0,0,0\n210.jpg,0,1,0,0,0,0,0,0,1,0\n59.jpg,1,0,0,1,0,0,0,0,0,0\n255.jpg,1,0,0,0,0,0,0,0,1,0\n19.jpg,1,0,0,0,0,0,0,0,0,0\n24.jpg,1,0,0,1,0,0,0,0,0,0\n86.jpg,1,0,1,0,0,0,0,0,0,0\n217.jpg,1,0,0,0,0,0,1,0,0,0\n128.jpg,0,1,0,0,0,0,0,0,0,0\n228.jpg,1,0,0,0,0,0,1,0,1,0\n28.jpg,1,0,0,0,0,0,0,0,0,0\n195.jpg,1,0,1,0,0,0,0,0,0,0\n288.jpg,1,0,0,1,0,0,0,0,0,0\n152.jpg,1,0,0,0,0,0,0,0,0,0\n116.jpg,0,1,0,0,0,0,1,0,0,0\n36.jpg,1,0,0,1,0,0,0,0,0,0\n191.jpg,1,0,0,1,0,0,0,0,0,0\n9.jpg,1,0,0,1,0,0,0,0,0,0\n70.jpg,1,0,1,0,0,0,0,0,0,0\n201.jpg,1,0,1,0,0,0,0,0,0,0\n46.jpg,1,0,1,1,0,0,0,0,0,0\n13.jpg,1,0,0,0,0,0,0,0,0,0\n207.jpg,1,0,1,0,0,0,0,0,0,0\n291.jpg,0,1,0,0,0,0,1,0,0,0\n107.jpg,1,0,0,1,0,0,0,0,0,0\n252.jpg,1,0,0,0,0,0,0,0,1,0\n226.jpg,1,0,0,0,0,0,0,0,0,0\n76.jpg,1,0,1,1,0,0,0,0,0,0\n223.jpg,0,1,0,0,0,0,0,0,0,0\n135.jpg,0,1,0,0,0,0,0,0,1,0\n271.jpg,0,1,0,0,0,0,0,0,0,0\n246.jpg,1,0,0,0,0,0,0,0,1,0\n20.jpg,1,0,0,1,0,0,0,0,0,0\n44.jpg,1,0,0,0,0,0,1,0,1,0\n269.jpg,1,0,0,0,0,0,0,0,0,0\n129.jpg,1,0,1,0,0,0,0,0,0,0\n97.jpg,1,0,1,0,0,0,0,0,0,0\n280.jpg,0,1,0,0,0,0,0,0,0,0\n21.jpg,1,0,0,0,0,0,0,0,1,0\n63.jpg,1,0,0,1,0,0,0,0,0,0\n238.jpg,1,0,0,0,0,0,0,0,1,0\n8.jpg,1,0,0,1,0,0,0,0,0,0\n272.jpg,0,1,0,0,0,0,0,0,1,0\n225.jpg,1,0,0,0,0,0,0,0,0,0\n177.jpg,0,1,0,0,0,0,0,0,0,0\n141.jpg,1,0,0,0,0,0,0,0,1,0\n287.jpg,0,1,0,0,0,0,0,0,0,1\n212.jpg,1,0,0,1,0,0,0,0,0,0\n219.jpg,1,0,0,0,0,0,0,0,1,0\n113.jpg,0,1,0,0,0,1,0,0,0,0\n74.jpg,1,0,0,1,0,0,0,0,0,0\n41.jpg,1,0,0,1,0,0,0,0,0,0\n89.jpg,1,0,1,0,0,0,0,0,0,0\n38.jpg,1,0,0,0,0,0,0,0,1,0\n103.jpg,1,0,0,1,0,0,0,0,0,0\n26.jpg,1,0,0,0,0,0,0,0,0,0\n256.jpg,1,0,0,0,0,0,0,0,1,0\n222.jpg,1,0,0,0,0,0,1,0,0,0\n285.jpg,1,0,0,1,0,0,0,0,0,0\n61.jpg,1,0,0,1,0,0,0,0,0,0\n149.jpg,0,1,0,0,0,0,0,0,0,0\n64.jpg,1,0,0,1,0,0,0,0,0,0\n259.jpg,1,0,0,0,0,0,0,0,1,0\n131.jpg,1,0,1,0,0,0,0,0,0,0\n215.jpg,1,0,0,1,0,0,0,0,0,0\n281.jpg,1,0,0,1,0,0,0,0,0,0\n66.jpg,1,0,0,1,0,0,0,0,0,0\n27.jpg,1,0,0,0,0,0,0,0,1,0\n57.jpg,1,0,0,1,0,0,0,0,0,0\n146.jpg,1,0,0,0,0,0,0,0,1,0\n143.jpg,1,0,0,0,0,0,0,0,1,0\n174.jpg,1,0,0,1,0,0,1,0,0,0\n295.jpg,0,1,0,0,0,0,0,0,0,0\n244.jpg,1,0,0,0,0,0,0,0,1,0\n234.jpg,1,0,0,0,0,0,0,0,0,0\n257.jpg,1,0,0,0,0,0,0,0,0,0\n258.jpg,1,0,0,0,0,0,0,0,0,0\n65.jpg,0,1,0,0,0,0,0,0,1,0\n112.jpg,1,0,0,0,0,1,0,0,0,0\n205.jpg,1,0,0,0,0,0,0,0,0,0\n130.jpg,1,0,0,0,0,0,0,0,0,0\n144.jpg,0,1,0,0,0,0,0,0,0,0\n140.jpg,1,0,0,0,0,0,0,0,1,0\n156.jpg,1,0,0,0,0,0,0,0,1,0\n92.jpg,1,0,1,0,0,0,0,0,0,0\n94.jpg,1,0,1,0,0,0,0,0,0,0\n132.jpg,0,1,0,0,0,0,0,0,0,0\n83.jpg,1,0,0,1,0,0,0,0,0,0\n148.jpg,0,1,0,0,0,0,0,0,0,0\n253.jpg,1,0,0,0,0,0,0,0,1,0\n175.jpg,1,0,0,1,0,0,0,0,0,0\n104.jpg,1,0,0,1,0,0,0,0,0,0\n216.jpg,1,0,0,0,0,0,1,0,0,0\n87.jpg,1,0,1,0,0,0,0,0,0,0\n292.jpg,0,1,0,0,0,0,0,0,0,1\n23.jpg,1,0,0,0,0,0,0,0,0,0\n161.jpg,0,1,0,0,0,0,1,0,0,0\n88.jpg,1,0,0,1,0,0,0,0,0,0\n49.jpg,1,0,1,0,0,0,0,0,0,0\n33.jpg,1,0,0,0,0,0,0,0,0,0\n164.jpg,1,0,0,1,0,0,0,0,0,0\n165.jpg,1,0,0,0,0,0,1,0,0,0\n105.jpg,1,0,0,0,0,0,0,0,1,0\n80.jpg,1,0,0,1,0,0,0,0,0,0\n98.jpg,1,0,0,1,0,0,0,0,0,0\n178.jpg,0,1,0,0,0,0,0,0,0,0\n263.jpg,0,1,0,0,0,0,1,0,0,0\n17.jpg,1,0,0,0,0,0,0,0,1,0\n245.jpg,1,0,0,0,0,0,0,0,1,0\n232.jpg,1,0,0,1,0,0,0,0,0,0\n133.jpg,0,1,0,0,0,0,0,0,1,0\n243.jpg,1,0,0,0,0,0,0,0,1,0\n82.jpg,1,0,0,1,0,0,0,0,0,0\n42.jpg,1,0,1,0,0,0,0,0,0,0\n34.jpg,1,0,0,0,0,0,0,0,1,0\n22.jpg,1,0,0,0,0,0,0,0,0,0\n298.jpg,0,1,0,0,0,0,0,0,0,0\n3.jpg,1,0,0,1,0,0,0,0,0,0\n176.jpg,0,1,0,0,0,0,0,0,0,0\n230.jpg,1,0,0,1,0,0,0,0,0,0\n158.jpg,1,0,0,0,0,0,0,0,0,0\n150.jpg,0,1,0,0,0,0,0,0,0,0\n160.jpg,0,1,0,0,0,0,1,0,0,0\n147.jpg,1,0,0,0,0,0,0,0,1,0\n72.jpg,1,0,1,0,0,0,0,0,0,0\n268.jpg,1,0,0,0,0,0,0,0,0,0\n60.jpg,1,0,0,1,0,0,0,0,0,0\n187.jpg,1,0,0,1,0,0,0,0,0,0\n260.jpg,1,0,0,0,0,0,0,0,1,0\n224.jpg,1,0,0,0,0,0,1,0,0,0\n93.jpg,1,0,1,0,0,0,0,0,0,0\n166.jpg,1,0,0,1,0,0,0,0,0,0\n196.jpg,0,1,0,0,0,0,0,0,0,0\n1.jpg,1,0,0,0,0,0,0,0,1,0\n109.jpg,0,1,0,0,0,0,1,0,0,0\n180.jpg,0,1,0,0,0,0,0,0,0,0\n40.jpg,1,0,1,1,0,0,0,0,0,0\n69.jpg,1,0,0,1,0,0,0,0,0,0\n138.jpg,1,0,0,0,0,0,0,0,0,0\n229.jpg,1,0,0,1,0,0,0,0,0,0\n145.jpg,1,0,0,0,0,0,0,0,1,0\n235.jpg,1,0,0,0,0,0,0,0,0,0\n7.jpg,1,0,0,1,0,0,0,0,0,0\n67.jpg,1,0,0,1,0,0,0,0,0,0\n214.jpg,1,0,0,0,0,0,0,0,1,0\n45.jpg,1,0,0,1,0,0,0,0,0,0\n51.jpg,1,0,1,0,0,0,0,0,0,0\n250.jpg,1,0,0,0,0,0,0,0,1,0\n121.jpg,1,0,0,0,0,0,0,0,1,0\n208.jpg,0,1,0,0,0,0,0,0,0,0\n47.jpg,1,0,0,1,0,0,0,0,0,0\n5.jpg,1,0,0,1,0,0,0,0,0,0\n154.jpg,0,1,0,0,0,0,0,0,0,0\n151.jpg,1,0,1,0,0,0,0,0,0,0\n2.jpg,1,0,1,1,0,0,0,0,0,0\n249.jpg,0,1,0,0,0,0,0,0,0,0\n289.jpg,1,0,0,1,0,0,0,0,0,0\n273.jpg,0,1,0,0,0,0,0,0,0,0\n192.jpg,1,0,0,1,0,0,0,0,0,0\n118.jpg,1,0,0,0,0,0,0,0,0,0\n213.jpg,1,0,0,1,0,0,0,0,0,0\n265.jpg,0,1,0,0,0,0,0,0,0,0\n125.jpg,1,0,0,1,0,0,0,0,0,0\n242.jpg,1,0,0,0,0,0,0,0,1,0\n266.jpg,0,1,0,0,0,0,0,0,0,1\n293.jpg,0,1,0,0,0,0,0,0,0,1\n120.jpg,1,0,0,0,0,0,0,0,1,0\nA,HG,HT,TR,CTH,BD,VH,CTQ,DQT,KS,CVN\n\"\"\"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compareRes12Arr = compareRes12[1:-1].split(\"\\n\")\nprint(len(compareRes12Arr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"linetestcase = random.randrange(12, 312)\nprint(linetestcase + 1)\ntestcase = linetestcase-12\nprint(applyLogicLabel(outputOfTestset[testcase]))\nprint(convertBinVec2LabelList(applyLogicLabel(outputOfTestset[testcase])))\nprint(convertBinVec2LabelList(list(map(int, compareRes12Arr[linetestcase].split(\",\")[1:]))))\nplt.imshow(imagesTestsetArray3[testcase][0])\nplt.show()\n# print(autoOnehot2Label(formatSoftmaxOutput(testModel.predict(\n#     hota_preprocess_input(\n#         np.array(imagesTestsetArray3[testcase], dtype=\"float32\")\n#     )\n# ))[0]))\n# print(predict2binary(testModel.predict(\n#     hota_preprocess_input(\n#         np.array(imagesTestsetArray3[testcase], dtype=\"float32\")\n#     )\n# ))[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n175: res12\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}}]}