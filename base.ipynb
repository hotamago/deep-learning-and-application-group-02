{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install huggingface-hub\n# %pip install numpy\n# %pip install opencv-python\n# %pip install matplotlib\n# %pip install pandas","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/taki0112/vit-tensorflow.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv \"/kaggle/working/vit-tensorflow/vit_tensorflow\" \"/kaggle/working/vit_tensorflow\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install optree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time\nimport math\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:19.631663Z","iopub.execute_input":"2024-04-21T12:45:19.632063Z","iopub.status.idle":"2024-04-21T12:45:19.644239Z","shell.execute_reply.started":"2024-04-21T12:45:19.632032Z","shell.execute_reply":"2024-04-21T12:45:19.642554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:19.816366Z","iopub.execute_input":"2024-04-21T12:45:19.816697Z","iopub.status.idle":"2024-04-21T12:45:19.889031Z","shell.execute_reply.started":"2024-04-21T12:45:19.816676Z","shell.execute_reply":"2024-04-21T12:45:19.887377Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# secret_hf =","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:20.335624Z","iopub.execute_input":"2024-04-21T12:45:20.337126Z","iopub.status.idle":"2024-04-21T12:45:20.341830Z","shell.execute_reply.started":"2024-04-21T12:45:20.337073Z","shell.execute_reply":"2024-04-21T12:45:20.340293Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:20.567946Z","iopub.execute_input":"2024-04-21T12:45:20.569502Z","iopub.status.idle":"2024-04-21T12:45:20.574158Z","shell.execute_reply.started":"2024-04-21T12:45:20.569452Z","shell.execute_reply":"2024-04-21T12:45:20.572718Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Download data","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:21.399655Z","iopub.execute_input":"2024-04-21T12:45:21.400116Z","iopub.status.idle":"2024-04-21T12:45:21.710642Z","shell.execute_reply.started":"2024-04-21T12:45:21.400081Z","shell.execute_reply":"2024-04-21T12:45:21.709198Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'dataset': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"imagedata.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"label.txt\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:21.891531Z","iopub.execute_input":"2024-04-21T12:45:21.891913Z","iopub.status.idle":"2024-04-21T12:45:57.819545Z","shell.execute_reply.started":"2024-04-21T12:45:21.891888Z","shell.execute_reply":"2024-04-21T12:45:57.818371Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"imagedata.zip:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af160d4fb7b04fdcb37cc4fbdcb8f527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"label.txt:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edad7db3b5c04a748ae1f260f5240abe"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'dataset/label.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:57.821327Z","iopub.execute_input":"2024-04-21T12:45:57.821660Z","iopub.status.idle":"2024-04-21T12:46:02.972939Z","shell.execute_reply.started":"2024-04-21T12:45:57.821635Z","shell.execute_reply":"2024-04-21T12:46:02.971809Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nunzip is already the newest version (6.0-25ubuntu1.2).\n0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir datasetImage\n!unzip -q -o \"dataset/imagedata.zip\" -d \"datasetImage\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:02.974338Z","iopub.execute_input":"2024-04-21T12:46:02.974722Z","iopub.status.idle":"2024-04-21T12:46:22.963130Z","shell.execute_reply.started":"2024-04-21T12:46:02.974688Z","shell.execute_reply":"2024-04-21T12:46:22.961247Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'datasetImage': File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"prefix_path_data = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:22.966263Z","iopub.execute_input":"2024-04-21T12:46:22.966645Z","iopub.status.idle":"2024-04-21T12:46:22.972563Z","shell.execute_reply.started":"2024-04-21T12:46:22.966616Z","shell.execute_reply":"2024-04-21T12:46:22.971015Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"rawlabel = \"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:22.974113Z","iopub.execute_input":"2024-04-21T12:46:22.974497Z","iopub.status.idle":"2024-04-21T12:46:22.986372Z","shell.execute_reply.started":"2024-04-21T12:46:22.974466Z","shell.execute_reply":"2024-04-21T12:46:22.985277Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# load label\nwith open(os.path.join(prefix_path_data, \"dataset/label.txt\"), \"r\") as f:\n    rawlabel = f.read()\n    \n# G93aRj07CIZPKaC8.jpg {\"label-8\":14,\"label-7\":3,\"label-2\":4} 16\n# name image, label(json), totel people vote\n# Format to json {name, label, totel}\nlabelDataset = []\narrayRawLabel = rawlabel.split(\"\\n\")\nfor ele in arrayRawLabel:\n    eleArr = ele.split(\" \")\n    try:\n        labelDataset.append({\n            \"name\": eleArr[0],\n            \"label\": json.loads(eleArr[1]),\n            \"total\": int(eleArr[2])\n        })\n    except:\n        print(ele)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.600033Z","iopub.execute_input":"2024-04-21T12:48:41.600429Z","iopub.status.idle":"2024-04-21T12:48:41.615305Z","shell.execute_reply.started":"2024-04-21T12:48:41.600404Z","shell.execute_reply":"2024-04-21T12:48:41.613280Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label 0 -> 10, 0 is not good image need to delete\ndef LabelsToVector(labels):\n    vectorLabel = [0] * 11\n    try:\n        for label, num in labels.items():\n            if len(label.split(\"-\")) != 2:\n                print(\"Error: \", labels)\n            vectorLabel[int(label.split(\"-\")[1])] = num\n    except:\n        pass\n    return vectorLabel\n\ndef NormalVectorLabel(vectorLabel, total, presentFilter):\n    # Check if label 0 is > presentFilter\n    if total == 0 or vectorLabel[0]/total > presentFilter:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n    \n    # Process localcation label\n    totalLocalVote = 0\n    for i in range(1, 3):\n        totalLocalVote += vectorLabel[i]\n    if totalLocalVote > 0:\n        for i in range(1, 3):\n            vectorLabel[i] = 1 if vectorLabel[i]/totalLocalVote > presentFilter else 0\n    \n    # Process orther label\n    for i in range(3, len(vectorLabel)):\n        vectorLabel[i] = 1 if vectorLabel[i]/total > presentFilter else 0\n        \n    # Process speacil case\n    # Auto set label 1\n    goodLabel = [3, 4]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[1] = 1;\n    \n    # Auto set label 2\n    goodLabel = [7, 8]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[2] = 1;\n            \n    # Check if label 1 or 2 is set\n    if vectorLabel[1] == vectorLabel[2]:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n#     else:\n#         vectorLabel[0] = 0\n    \n    return np.array(vectorLabel)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.760060Z","iopub.execute_input":"2024-04-21T12:48:41.760516Z","iopub.status.idle":"2024-04-21T12:48:41.772078Z","shell.execute_reply.started":"2024-04-21T12:48:41.760485Z","shell.execute_reply":"2024-04-21T12:48:41.770461Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Filter label\nfor ele in labelDataset:\n    # Only get label with > 50% vote\n    ele[\"label\"] = NormalVectorLabel(LabelsToVector(ele[\"label\"]), ele[\"total\"], 0.5)\n    \n# Filter bad image\nclearLabelDataset = []\nfor ele in labelDataset:\n    if ele[\"label\"][0] == 0:\n        ele[\"label\"] = ele[\"label\"][1:]\n        clearLabelDataset.append(ele)\nlabelDataset = clearLabelDataset","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.907648Z","iopub.execute_input":"2024-04-21T12:48:41.908094Z","iopub.status.idle":"2024-04-21T12:48:41.924086Z","shell.execute_reply.started":"2024-04-21T12:48:41.908068Z","shell.execute_reply":"2024-04-21T12:48:41.922872Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Add map image name to label\nmapImageNameToLabel = {}\nfor ele in labelDataset:\n    mapImageNameToLabel[ele[\"name\"]] = ele[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:43.747635Z","iopub.execute_input":"2024-04-21T12:48:43.748043Z","iopub.status.idle":"2024-04-21T12:48:43.754269Z","shell.execute_reply.started":"2024-04-21T12:48:43.748019Z","shell.execute_reply":"2024-04-21T12:48:43.752812Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Map name for fast filter image\nmapNameFastQuery = set()\nfor ele in labelDataset:\n    mapNameFastQuery.add(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:43.911297Z","iopub.execute_input":"2024-04-21T12:48:43.911723Z","iopub.status.idle":"2024-04-21T12:48:43.920158Z","shell.execute_reply.started":"2024-04-21T12:48:43.911690Z","shell.execute_reply":"2024-04-21T12:48:43.918811Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:44.531263Z","iopub.execute_input":"2024-04-21T12:48:44.531620Z","iopub.status.idle":"2024-04-21T12:48:44.538233Z","shell.execute_reply.started":"2024-04-21T12:48:44.531597Z","shell.execute_reply":"2024-04-21T12:48:44.536585Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load image\nimagesDataset = {}\nfor label in labelDataset:\n    if label[\"name\"] not in mapNameFastQuery:\n        continue\n    img = resize_image_reduce_size(\n        cv2.imread(os.path.join(prefix_path_data, \"datasetImage/file\", label['name'])),\n        224\n    )\n    imagesDataset[label['name']] = img","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-21T12:48:45.131549Z","iopub.execute_input":"2024-04-21T12:48:45.131972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process","metadata":{}},{"cell_type":"code","source":"print(len(labelDataset))\nprint(len(imagesDataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:23.425046Z","iopub.status.idle":"2024-04-21T12:46:23.425440Z","shell.execute_reply.started":"2024-04-21T12:46:23.425240Z","shell.execute_reply":"2024-04-21T12:46:23.425256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot analytic banlance dataset\n\ntotalLabelDataset = np.array([0] * 10)\nfor ele in labelDataset:\n    totalLabelDataset += ele[\"label\"]\n\nprint(totalLabelDataset)\n    \n# Draw\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:23.427285Z","iopub.status.idle":"2024-04-21T12:46:23.427633Z","shell.execute_reply.started":"2024-04-21T12:46:23.427454Z","shell.execute_reply":"2024-04-21T12:46:23.427472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labelDataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:23.491462Z","iopub.execute_input":"2024-04-21T12:46:23.491884Z","iopub.status.idle":"2024-04-21T12:46:23.498513Z","shell.execute_reply.started":"2024-04-21T12:46:23.491855Z","shell.execute_reply":"2024-04-21T12:46:23.496917Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'name': 'G93aRj07CIZPKaC8.jpg', 'label': array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]), 'total': 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"csvDataJSON = []\nlistGoodImage = []\nlabelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\nfor ele in labelDataset:\n    labelTemp = {}\n    for i in range(len(labelValue)):\n        labelTemp[labelValue[i]] = ele[\"label\"][i]\n    csvDataJSON.append({\n        \"file\": ele[\"name\"],\n        **labelTemp\n    })\n    listGoodImage.append(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:23.699962Z","iopub.execute_input":"2024-04-21T12:46:23.701119Z","iopub.status.idle":"2024-04-21T12:46:23.737661Z","shell.execute_reply.started":"2024-04-21T12:46:23.701084Z","shell.execute_reply":"2024-04-21T12:46:23.735885Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m labelTemp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labelValue)):\n\u001b[0;32m----> 7\u001b[0m     labelTemp[labelValue[i]] \u001b[38;5;241m=\u001b[39m \u001b[43mele\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m csvDataJSON\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: ele[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlabelTemp\n\u001b[1;32m     11\u001b[0m })\n\u001b[1;32m     12\u001b[0m listGoodImage\u001b[38;5;241m.\u001b[39mappend(ele[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:23.899809Z","iopub.execute_input":"2024-04-21T12:46:23.900183Z","iopub.status.idle":"2024-04-21T12:46:24.226230Z","shell.execute_reply.started":"2024-04-21T12:46:23.900157Z","shell.execute_reply":"2024-04-21T12:46:24.224725Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create list good \nf = open(\"listimage.txt\", \"w\")\nf.write(\"\\n\".join(listGoodImage))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:24.239454Z","iopub.execute_input":"2024-04-21T12:46:24.239845Z","iopub.status.idle":"2024-04-21T12:46:24.245439Z","shell.execute_reply.started":"2024-04-21T12:46:24.239820Z","shell.execute_reply":"2024-04-21T12:46:24.244321Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Note:\n# imagesDataset is an Dict key is name image, value is image data\n# Using: get image data of label name N => imagesDataset[N]\n# Get image data of label i => imagesDataset[labelDataset[i][\"name\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process data to send","metadata":{}},{"cell_type":"code","source":"from functools import cmp_to_key","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir compressImage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelDataset.sort(key=cmp_to_key(lambda x, y: y[\"total\"] - x[\"total\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listCompressConfig = [100, 80, 50, 30, 20, 10, 5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\ncsvDataJSON = []\ntotalLabelDataset = np.array([0] * 10)\nfor i in range(400):\n    file_name = os.path.join(\"compressImage\", \"{0}.jpg\".format(i))\n    for j in range(len(listCompressConfig)):\n        cv2.imwrite(\n            file_name, imagesDataset[labelDataset[i][\"name\"]],\n            [int(cv2.IMWRITE_JPEG_QUALITY), listCompressConfig[j]]\n        )\n        file_size = os.stat(file_name).st_size / 1024\n        if file_size <= 20.0:\n            break\n    file_size = os.stat(file_name).st_size / 1024\n    if file_size > 20.0:\n        print(\"Error outsize {0}\".format(i))\n        \n    # Add analytics\n    totalLabelDataset += labelDataset[i][\"label\"]\n    \n    # Add csv\n    labelTemp = {}\n    for j in range(len(labelValue)):\n        labelTemp[labelValue[j]] = labelDataset[i][\"label\"][j]\n    csvDataJSON.append({\n        \"file\": \"{0}.jpg\".format(i),\n        **labelTemp\n    })\n    \n# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)\n    \n# Draw\nprint(totalLabelDataset)\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"markdown","source":"### Analytics data","metadata":{}},{"cell_type":"code","source":"minLabel = np.amin(totalLabelDataset)\nprint(minLabel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ele in labelDataset:\n    print(ele)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label2str(label):\n    s = \"\"\n    for i in range(len(label)):\n        s += str(int(label[i]))\n    return s\ndef str2label(s):\n    label = []\n    for i in range(len(s)):\n        label.append(int(s[i]))\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tempCnumDimOnehot = {}\nfor ele in labelDataset:\n    tempCnumDimOnehot[label2str(ele[\"label\"])] = 1\nnumDimOnehot = len(tempCnumDimOnehot)\nprint(numDimOnehot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def index2onehot(index):\n    onehot = [0] * numDimOnehot\n    onehot[index] = 1\n    return onehot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot = {}\nfor ele in labelDataset:\n    if label2str(ele[\"label\"]) not in mapLabel2OneHot:\n        mapLabel2OneHot[label2str(ele[\"label\"])] = index2onehot(len(mapLabel2OneHot))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label = {}\nfor i in mapLabel2OneHot:\n    mapOneHot2Label[label2str(mapLabel2OneHot[i])] = str2label(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for ele in labelDataset:\n#     ele[\"label\"] = mapLabel2OneHot[label2str(ele[\"label\"])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoLabel2Onehot(label):\n    return mapLabel2OneHot[label2str(label)]\ndef autoOnehot2Label(onehot):\n    return mapOneHot2Label[label2str(onehot)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(autoOnehot2Label(autoLabel2Onehot([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process image","metadata":{}},{"cell_type":"markdown","source":"#### Constant","metadata":{}},{"cell_type":"code","source":"size_image_model = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Helper function","metadata":{}},{"cell_type":"code","source":"def crop2nimage(image, nimage = 3):\n    # Size of bigest square image\n    sizeSquare = min(image.shape[0], image.shape[1])\n\n    # Rotate image if image is portrait\n    isRotate = False\n    if image.shape[0] > image.shape[1]:\n        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n        isRotate = True\n\n    # Crop n image\n    cropImages = []\n    widthBetween = (image.shape[1] - sizeSquare) / (nimage - 1)\n    for i in range(nimage):\n        x1 = int(i * widthBetween)\n        x2 = int(x1 + sizeSquare)\n        cropImages.append(image[:, x1:x2])\n\n    # Rotate image back\n    if isRotate:\n        for i in range(len(cropImages)):\n            cropImages[i] = cv2.rotate(cropImages[i], cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n    # Convert color to RGB\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.cvtColor(cropImages[i], cv2.COLOR_BGR2RGB)\n        \n    return cropImages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calibrate_image(image, target_size_kb=20):\n    # Resize image to the target size\n    resized_image = cv2.resize(image, (224, 224))\n\n    return resized_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation by type:\n# 1. Random flip\n# 2. Random rotate\n# 4. Random Saturate\n# 3. Random brightness\n# 5. Random crop\n\n# Random flip\ndef random_flip(image, p=0.5):\n    if np.random.rand() < p:\n        return cv2.flip(image, 1)\n    return image\n\n# Random rotate from range angle\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n    (in degrees). The returned image will be large enough to hold the entire\n    new image, with a black background\n    \"\"\"\n\n    # Get the image size\n    # No that's not an error - NumPy stores image matricies backwards\n    image_size = (image.shape[1], image.shape[0])\n    image_center = tuple(np.array(image_size) / 2)\n\n    # Convert the OpenCV 3x2 rotation matrix to 3x3\n    rot_mat = np.vstack(\n        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n    )\n\n    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n    # Shorthand for below calcs\n    image_w2 = image_size[0] * 0.5\n    image_h2 = image_size[1] * 0.5\n\n    # Obtain the rotated coordinates of the image corners\n    rotated_coords = [\n        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n    ]\n\n    # Find the size of the new image\n    x_coords = [pt[0] for pt in rotated_coords]\n    x_pos = [x for x in x_coords if x > 0]\n    x_neg = [x for x in x_coords if x < 0]\n\n    y_coords = [pt[1] for pt in rotated_coords]\n    y_pos = [y for y in y_coords if y > 0]\n    y_neg = [y for y in y_coords if y < 0]\n\n    right_bound = max(x_pos)\n    left_bound = min(x_neg)\n    top_bound = max(y_pos)\n    bot_bound = min(y_neg)\n\n    new_w = int(abs(right_bound - left_bound))\n    new_h = int(abs(top_bound - bot_bound))\n\n    # We require a translation matrix to keep the image centred\n    trans_mat = np.matrix([\n        [1, 0, int(new_w * 0.5 - image_w2)],\n        [0, 1, int(new_h * 0.5 - image_h2)],\n        [0, 0, 1]\n    ])\n\n    # Compute the tranform for the combined rotation and translation\n    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n    # Apply the transform\n    result = cv2.warpAffine(\n        image,\n        affine_mat,\n        (new_w, new_h),\n        flags=cv2.INTER_LINEAR\n    )\n\n    return result\n\ndef largest_rotated_rect(w, h, angle):\n    \"\"\"\n    Given a rectangle of size wxh that has been rotated by 'angle' (in\n    radians), computes the width and height of the largest possible\n    axis-aligned rectangle within the rotated rectangle.\n\n    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n\n    Converted to Python by Aaron Snoswell\n    \"\"\"\n\n    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n\n    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n\n    delta = math.pi - alpha - gamma\n\n    length = h if (w < h) else w\n\n    d = length * math.cos(alpha)\n    a = d * math.sin(alpha) / math.sin(delta)\n\n    y = a * math.cos(gamma)\n    x = y * math.tan(gamma)\n\n    return (\n        bb_w - 2 * x,\n        bb_h - 2 * y\n    )\n\ndef crop_around_center(image, width, height):\n    \"\"\"\n    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n    around it's centre point\n    \"\"\"\n\n    image_size = (image.shape[1], image.shape[0])\n    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n\n    if(width > image_size[0]):\n        width = image_size[0]\n\n    if(height > image_size[1]):\n        height = image_size[1]\n\n    x1 = int(image_center[0] - width * 0.5)\n    x2 = int(image_center[0] + width * 0.5)\n    y1 = int(image_center[1] - height * 0.5)\n    y2 = int(image_center[1] + height * 0.5)\n\n    return image[y1:y2, x1:x2]\n\ndef random_rotate(image, angle_range=15):\n    angle = np.random.uniform(-angle_range, angle_range)\n    image_height, image_width = image.shape[0:2]\n    image = crop_around_center(\n        rotate_image(image, angle),\n        *largest_rotated_rect(\n            image_width,\n            image_height,\n            math.radians(angle)\n        )\n    )\n    return image\n\n# Random saturate\ndef random_saturate(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 1] = hsv[:, :, 1] * np.random.uniform(low, high)\n    hsv[:, :, 1][hsv[:, :, 1] > 255] = 255\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random brightness\ndef random_brightness(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random crop\ndef random_crop_size(image, size=224):\n    x = np.random.randint(0, image.shape[1] - size)\n    y = np.random.randint(0, image.shape[0] - size)\n    return image[y:y+size, x:x+size]\n\n# Random augment\ndef random_augment(image):\n    image = random_flip(image)\n    image = random_rotate(image)\n    image = random_saturate(image)\n    image = random_brightness(image)\n    # image = random_crop(image)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random noise\ndef random_noise(image, present=0.05):\n    # Randome noice range [0, 255] with present 0.05\n    lran = int(-255 * present)\n    rran = int(255 * present)\n    noise = np.random.randint(lran, rran, image.shape)\n\n    # Add noise to image\n    image = cv2.add(image, noise, dtype=cv2.CV_8UC3)\n\n    return image\n\n# Random blur\ndef random_blur(image, win_size=(3, 3)):\n    image = cv2.GaussianBlur(image, win_size, 0)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image","metadata":{}},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Apply to all image in dataset\nfor imageId in imagesDataset:\n    imagesDataset[imageId] = resize_image_reduce_size(imagesDataset[imageId], size_image_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imwrite(\"test.jpg\", imagesDataset[labelDataset[0][\"name\"]], [cv2.IMWRITE_JPEG_QUALITY, 50])\n# print(os.path.getsize('test.jpg')/1024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data augment","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split image name to label\ntempImageLabelName = [[] for _ in range(numDimOnehot)]\nfor ele in labelDataset:\n    for i in range(len(mapLabel2OneHot[label2str(ele[\"label\"])])):\n        if mapLabel2OneHot[label2str(ele[\"label\"])][i] >= 1:\n            tempImageLabelName[i].append(ele[\"name\"])\n\n# tempImageLabelName = [[] for _ in range(10)]\n# for ele in labelDataset:\n#     for i in range(len(ele[\"label\"])):\n#         if ele[\"label\"][i] >= 1:\n#             tempImageLabelName[i].append(ele[\"name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total len\ntotalTempImageLabelName = []\nfor i in range(len(tempImageLabelName)):\n    totalTempImageLabelName.append(len(tempImageLabelName[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amax(totalTempImageLabelName), np.amin(totalTempImageLabelName))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([i for i in totalTempImageLabelName if i > 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target number image each label after augment\ntarget_number_image = 160\n\nimagesDatasetAug = []\nlabelDatasetAug = []\n# Augment image\nfor i in range(0, len(tempImageLabelName)):\n    print(\"Augment label: \", i)\n    print(\"Number image: \", len(tempImageLabelName[i]))\n    if totalTempImageLabelName[i] >= target_number_image or totalTempImageLabelName[i] == 0:\n        continue\n        \n    numDeltaAdd = target_number_image - totalTempImageLabelName[i]\n    for j in range(numDeltaAdd):\n        # Name image\n        imageName = tempImageLabelName[i][np.random.randint(0, len(tempImageLabelName[i]))]\n        # Random select image\n        image = imagesDataset[imageName]\n        image = random_augment(image)\n        imagesDatasetAug.append(image)\n        \n        labelDatasetAug.append(autoLabel2Onehot(mapImageNameToLabel[imageName]))\n        for k in range(len(autoLabel2Onehot(mapImageNameToLabel[imageName]))):\n            if autoLabel2Onehot(mapImageNameToLabel[imageName])[k] >= 1:\n                totalTempImageLabelName[k] += 1\n        \n#         labelDatasetAug.append(mapImageNameToLabel[imageName])\n#         for k in range(len(mapImageNameToLabel[imageName])):\n#             if mapImageNameToLabel[imageName][k] >= 1:\n#                 totalTempImageLabelName[k] += 1","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(totalTempImageLabelName)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetAug))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(imagesDatasetAug[123])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labelDatasetAug[123])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imagesDatasetArray\nimagesDatasetArray = []\nlabelDatasetArray = []\n\nfor ele in labelDataset:\n    imagesDatasetArray.append(imagesDataset[ele[\"name\"]])\n#     labelDatasetArray.append(ele[\"label\"])\n    labelDatasetArray.append(autoLabel2Onehot(ele[\"label\"]))\n\nfor i in range(len(imagesDatasetAug)):\n    imagesDatasetArray.append(imagesDatasetAug[i])\n    labelDatasetArray.append(labelDatasetAug[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray), len(labelDatasetArray))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image and add some noise and rotate","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3 = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(labelDatasetArray)):\n    image = np.copy(imagesDatasetArray[i])\n    \n    # Crop\n    cropImages = crop2nimage(image, 3)\n\n    # Resize\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.resize(cropImages[i], (size_image_model, size_image_model))\n\n    # Add blur to image\n    for i in range(len(cropImages)):\n        cropImages[i] = random_blur(cropImages[i], (3, 3))\n        \n    # Add noise to image\n    for i in range(len(cropImages)):\n        # Randome noice\n        cropImages[i] = random_noise(cropImages[i], 0.05)\n\n    # Debug\n    # for i in range(len(cropImages)):\n    #     plt.imshow(cropImages[i])\n    #     plt.show()\n    # break\n\n    imagesDatasetArray3.append([cropImages[1]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray3), len(imagesDatasetArray3[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"markdown","source":"### Normal image","metadata":{}},{"cell_type":"markdown","source":"### Import library","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split testcase","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3_training = []\nlabelDatasetArray_training = []\nimagesDatasetArray3_testing = []\nlabelDatasetArray_testing = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = [i for i in range(len(imagesDatasetArray3))]\nnp.random.shuffle(idx)\n\nfor i in range(len(idx)):\n    if i < len(idx) * 0.3:\n        imagesDatasetArray3_training.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_training.append(labelDatasetArray[idx[i]])\n    else:\n        imagesDatasetArray3_testing.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_testing.append(labelDatasetArray[idx[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy\ntypePreprocess = 2 # 0 = [0, 1]  1 = [-1, 1]\nConfigPreprocess = True\nfor i in range(len(imagesDatasetArray3_training)):\n    if ConfigPreprocess:\n        if typePreprocess == 0:\n            imagesDatasetArray3_training[i] = [\n                (np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n        elif typePreprocess == 1:\n            imagesDatasetArray3_training[i] = [\n                (np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) / 255.0 - 0.5) / 0.5 for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n        elif typePreprocess == 2:\n            imagesDatasetArray3_training[i] = [\n                tf.image.per_image_standardization(np.array(imagesDatasetArray3_training[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n    else:\n        imagesDatasetArray3_training[i] = [\n            np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) for j in range(len(imagesDatasetArray3_training[i]))\n        ]\n    labelDatasetArray_training[i] = np.array(labelDatasetArray_training[i], dtype=np.float32)\n    \nfor i in range(len(imagesDatasetArray3_testing)):\n    if ConfigPreprocess:\n        if typePreprocess == 0:\n            imagesDatasetArray3_testing[i] = [\n                (np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n        elif typePreprocess == 1:\n            imagesDatasetArray3_testing[i] = [\n                (np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) / 255.0 - 0.5) / 0.5 for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n        elif typePreprocess == 2:\n            imagesDatasetArray3_testing[i] = [\n                tf.image.per_image_standardization(np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n    else:\n        imagesDatasetArray3_testing[i] = [\n            np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) for j in range(len(imagesDatasetArray3_testing[i]))\n        ]\n    labelDatasetArray_testing[i] = np.array(labelDatasetArray_testing[i], dtype=np.float32)\n\n# imagesDatasetArray3_training = np.array(imagesDatasetArray3_training, dtype=np.float32) / 255.0\n# labelDatasetArray_training = np.array(labelDatasetArray_training, dtype=np.float32)\n# imagesDatasetArray3_testing = np.array(imagesDatasetArray3_testing, dtype=np.float32) / 255.0\n# labelDatasetArray_testing = np.array(labelDatasetArray_testing, dtype=np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build dataset with batch","metadata":{}},{"cell_type":"code","source":"def create_batch_from_arr(arrData, batch_size=64):\n    temp_shape = list(arrData.shape)\n    deltaMiss = ((arrData.shape[0] + batch_size - 1) // batch_size) * batch_size - arrData.shape[0]\n    temp_shape[0] += deltaMiss\n    batchArrData = np.zeros(tuple(temp_shape), dtype=np.float32)\n    # Add to last\n    batchArrData[:arrData.shape[0]] = arrData\n    for i in range(arrData.shape[0], batchArrData.shape[0]):\n        batchArrData[i] = arrData[i - arrData.shape[0]]\n        \n    batchArrData = batchArrData.reshape(tuple([-1, batch_size, *list(batchArrData.shape[1:])]))\n    \n    return batchArrData\n\ndef create_dataset(images, labels, batch_size=64):\n    if batch_size == 0:\n        return (np.array(images), np.array(labels))\n    images = np.array(images, dtype=np.float32)\n    # image is 3 image in array\n    tempImageSplit = []\n    for i in range(images.shape[1]):\n        tempImageSplit.append(create_batch_from_arr(images[:, i], batch_size))\n\n    imagesBatch = []\n    for i in range(len(tempImageSplit[0])):\n        nimage = []\n        for j in range(len(tempImageSplit)):\n            nimage.append(tempImageSplit[j][i])\n        imagesBatch.append(nimage)\n        \n    labels = np.array(labels, dtype=np.float32)\n    labels = create_batch_from_arr(labels, batch_size)\n    \n    return (np.array(imagesBatch), labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 0)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(datasetTraining[0][0][0]), np.amax(datasetTraining[0][0][0]))\nprint(datasetTraining[1][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Init model","metadata":{}},{"cell_type":"code","source":"# Using dataset imagesDatasetArray3 and labelDatasetArray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vit_tensorflow.vit import Transformer\nimport tensorflow.keras.layers as nn\nfrom tensorflow import einsum\nfrom einops import rearrange, repeat\nfrom einops.layers.tensorflow import Rearrange\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViT(tf.keras.layers.Layer):\n    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim,\n                 pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n        super(ViT, self).__init__()\n\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n        \n        self.trearragnge = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n        self.patch_embedding = tf.keras.Sequential([\n            nn.Dense(units=dim)\n        ], name='patch_embedding')\n\n        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches + 1, dim]))\n        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, dim]))\n        self.dropout = nn.Dropout(rate=emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        \n        self.num_classes = num_classes\n\n        self.mlp_head = tf.keras.Sequential([\n            nn.LayerNormalization(),\n            nn.Dense(units=num_classes)\n        ], name='mlp_head')\n        \n    def build(self, input_shape):\n        super(ViT, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, img, training=True, **kwargs):\n        x = self.trearragnge(img)\n        x = self.patch_embedding(x)\n        b, n, d = x.shape\n        \n        cls_tokens = repeat(self.cls_token, 'n d -> b n d', b=b)\n        x = tf.concat([cls_tokens, x], axis=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x, training=training)\n\n        x = self.transformer(x, training=training)\n\n        if self.pool == 'mean':\n            x = tf.reduce_mean(x, axis=1)\n        else:\n            x = x[:, 0]\n\n        x = self.mlp_head(x)\n\n        return x\n    \n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\ndef convolutional_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    # Processing Residue with conv(1,1)\n    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\ndef ResNet(shape = (224, 224, 3), block_layers = [3, 4, 6, 3], using_top_layer = True, classes = 10, activation_class=\"softmax\"):\n    # Step 1 (Setup Input Layer)\n    x_input = tf.keras.layers.Input(shape)\n    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n    # Step 2 (Initial Conv layer along with maxPool)\n    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    # Define size of sub-blocks and initial filter size\n    filter_size = 64\n    # Step 3 Add the Resnet Blocks\n    for i in range(4):\n        if i == 0:\n            # For sub-block 1 Residual/Convolutional block not needed\n            for j in range(block_layers[i]):\n                x = identity_block(x, filter_size)\n        else:\n            # One Residual/Convolutional Block followed by Identity blocks\n            # The filter size will go on increasing by a factor of 2\n            filter_size = filter_size*2\n            x = convolutional_block(x, filter_size)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filter_size)\n    # Step 4 End Dense Network\n    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    if using_top_layer:\n        x = tf.keras.layers.Dense(classes, activation = activation_class)(x)\n    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hotaBlockImage(index):\n    # Build model flow\n#     inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n#     model = tf.keras.applications.EfficientNetV2S(\n#         include_top=True,\n#         weights=None, # 'imagenet'\n#         input_tensor=inputTensor,\n#         input_shape=None,\n#         pooling=None,\n#         classes=512,\n#         classifier_activation='relu', # softmax\n#         include_preprocessing=False\n#     )\n\n#     # Rename layer\n#     layer_names=[layer.name for layer in model.layers]\n#     for layer_name in layer_names:\n#         model.get_layer(name=layer_name).name = \"{0}_{1}\".format(layer_name, index)\n\n#     return model\n    \n#     model = ViT(\n#         image_size = (size_image_model, size_image_model),\n#         patch_size = 32,\n#         num_classes = 1000,\n#         dim = 1024,\n#         depth = 6,\n#         heads = 16,\n#         mlp_dim = 2048,\n#         dropout = 0.1,\n#         emb_dropout = 0.1\n#     )(inputTensor)\n        \n#     return tf.keras.Model(inputs=inputTensor, outputs=model)\n#     return ResNet(\n#         shape = (128, 128, 3), block_layers = [3, 3, 3, 3], using_top_layer = False, classes = 10, activation_class=\"softmax\"\n#     )\n    pass\ndef hotaNBlockImage(nblock = 3):\n#     inputs = []\n#     hidden_outputs = []\n#     for i in range(nblock):\n#         temp_model = hotaBlockImage(i)\n# #         inputs.append(temp_model.input[0]) # Application\n#         inputs.append(temp_model.input)\n#         hidden_outputs.append(temp_model.output)\n        \n#     combined = tf.keras.layers.Concatenate()(hidden_outputs)\n#     outputflatten = tf.keras.layers.Flatten()(combined)\n    \n#     hidden_outputs_2 = tf.keras.layers.Dense(512, activation=\"relu\")(outputflatten)\n# #     outputs = tf.keras.layers.Dense(numDimOnehot, activation=\"softmax\")(hidden_outputs_2)\n#     outputs = tf.keras.layers.Dense(10, activation=\"sigmoid\")(hidden_outputs_2)\n    \n#     return tf.keras.Model(inputs=inputs, outputs=outputs)\n#     return hotaBlockImage(0)\n\n#     return ResNet(\n#         shape = (128, 128, 3), block_layers = [3, 4, 6, 3], using_top_layer = True, classes = 10, activation_class=\"sigmoid\"\n#     )\n    inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n    return tf.keras.applications.EfficientNetV2S(\n        include_top=True,\n        weights=None, # 'imagenet'\n        input_tensor=inputTensor,\n        input_shape=None,\n        pooling=None,\n        classes=19,\n        classifier_activation='softmax', # softmax\n        include_preprocessing=False\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatNumpy2List(data):\n    listData = []\n    for i in range(data.shape[0]):\n        listData.append(data[i])\n        \n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatListMap2MapList(data):\n    listData = []\n    for i in range(data.shape[1]):\n        listData.append(data[:, i])\n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU Training","metadata":{}},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = hotaNBlockImage(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n\"\"\"\nBinaryFocalCrossentropy(\n    apply_class_balancing=True,\n    alpha=0.92,\n    gamma=2.0,\n) \n\"\"\"\nlossFc = tf.keras.losses.CategoricalCrossentropy()\nhotaModel.compile(loss=lossFc, optimizer=opt, metrics=[\n    tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), # BinaryAccuracy CategoricalAccuracy\n    tf.keras.metrics.AUC(name=\"auc\"),\n    tf.keras.metrics.F1Score(name=\"f1\"),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"saved_checkpoint/checkpoint.keras\",\n    save_weights_only=False,\n    monitor='val_accuracy', # val_auc val_accuracy\n    mode='max',\n    save_best_only=True\n)\nhotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=64,\n    epochs=300,\n    callbacks=[callbackEarlyStop, model_checkpoint_callback],\n    verbose=1,\n    validation_split=0.3,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = tf.keras.models.load_model(\"saved_checkpoint/checkpoint.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TPU Training","metadata":{}},{"cell_type":"code","source":"try: # detect TPUs\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.TPUStrategy(resolver)\n    \n    print('Running on TPU ', resolver.master())\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    hotaModel = hotaNBlockImage(3)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n#     opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n    opt = tf.keras.optimizers.SGD(learning_rate=1e-1)\n    # CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n    lossFc = tf.keras.losses.BinaryCrossentropy()\n    hotaModel.compile(loss=lossFc, optimizer=opt, metrics=[\n        # BinaryAccuracy CategoricalAccuracy\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.AUC(name=\"auc\"),\n        tf.keras.metrics.F1Score(name=\"f1\"),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8 * 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = int(xTrainignInput[0].shape[0] * 0.8)//batch_size\nvalidation_steps = int(xTrainignInput[0].shape[0] * 0.2)//batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-5, patience=5)\n# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n#     filepath=\"saved_checkpoint/checkpoint.keras\",\n#     save_weights_only=False,\n#     monitor='val_auc',\n#     mode='max',\n#     save_best_only=True\n# )\nhotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=batch_size,\n    epochs=300,\n    callbacks=[],\n    verbose=1,\n    validation_split=0.2,\n    shuffle=True,\n#     initial_epoch=0,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=batch_size,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test predit model","metadata":{}},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, 224, 224, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 132\nfor i in range(len(imagesDatasetArray3[testcase])):\n    plt.imshow(imagesDatasetArray3[testcase][i])\n    plt.show()\nprint(hotaModel.predict(\n    autoFormatInput2PreditOutput(\n        formatImageInput(np.copy(imagesDatasetArray3[testcase]).astype('float32'), 2)\n    ),\n    batch_size=1\n))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save model","metadata":{}},{"cell_type":"code","source":"!mkdir saved_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"hotaEfficientNetV2S_softmax_v2.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only use for TPU\nwith strategy.scope():\n    hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Upload to huggingface","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf_write = user_secrets.get_secret(\"HUGGINGFACE_WRITE_TOKEN\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf_write","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=os.path.join(\"/kaggle/working/saved_model\", model_name),\n    path_in_repo=model_name,\n    repo_id=\"hotamago/deep-learning-and-application-group-02\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load and testing model","metadata":{}},{"cell_type":"code","source":"model_name = \"hotaResnet12_softmax.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/deep-learning-and-application-group-02\", filename=model_name, revision=\"main\", repo_type=\"model\", local_dir=\"saved_model\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel = tf.keras.models.load_model(os.path.join('saved_model', model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\ntestModel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(\n        from_logits = False,\n    ),\n    optimizer=opt,\n    metrics=[\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.AUC(),\n        tf.keras.metrics.F1Score(),\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, 224, 224, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image\ndef formatSoftmaxOutput(label):\n    for bat in range(len(label)):\n        indexOne = np.argmax(label[bat])\n        for i in range(len(label[bat])):\n            label[bat][i] = 0\n        label[bat][indexOne] = 1\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 874\n# for i in range(len(imagesDatasetArray3[testcase])):\n#     plt.imshow(imagesDatasetArray3[testcase][i])\n#     plt.show()\nplt.imshow(imagesDatasetArray3[testcase][1])\nplt.show()\nprint(autoOnehot2Label(formatSoftmaxOutput(\n    testModel.predict(\n        autoFormatInput2PreditOutput(\n            formatImageInput(np.copy(imagesDatasetArray3[testcase]).astype('float32'), 2)\n        ),\n        batch_size=1\n    )\n)[0]))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test convert for softmax","metadata":{}},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 64)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaMetrics = [\n    tf.keras.metrics.BinaryAccuracy(name=\"Accuracy\"),\n    tf.keras.metrics.AUC(name=\"AUC\"),\n    tf.keras.metrics.F1Score(name=\"F1Score\"),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertFirst2List(image):\n    return [i for i in image]\ndef autoOnehot2LabelBatch(onehots):\n    labels = []\n    for i in range(len(onehots)):\n        labels.append(autoOnehot2Label(onehots[i]))\n    return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataRunSoft = datasetTesting # datasetTesting datasetTraining\nfor j in range(len(hotaMetrics)):\n    hotaMetrics[j].reset_state()\nfor i in range(len(dataRunSoft[0])):\n    testcaseImage = dataRunSoft[0][i]\n    testcaseLabel = autoOnehot2LabelBatch(np.copy(dataRunSoft[1][i]).astype('float32'))\n    \n    predictOut = np.array(autoOnehot2LabelBatch(formatSoftmaxOutput(\n        testModel.predict(\n            convertFirst2List(np.copy(testcaseImage).astype('float32')),\n            batch_size=64\n        )\n    )), dtype=np.float32)\n    \n    # update metrics\n    for j in range(len(hotaMetrics)):\n        hotaMetrics[j].update_state(testcaseLabel, predictOut)\n    \n    # Print\n    print(\"Done {0} / {1} batch\".format(i + 1, len(dataRunSoft[0])))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(len(hotaMetrics)):\n    print(\"{0}: {1}\".format(hotaMetrics[j].name, hotaMetrics[j].result()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine tuning","metadata":{}},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5)\ntestModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=8,\n    epochs=100,\n    callbacks=[callback],\n    verbose=1,\n    validation_split=0.3,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{},"execution_count":null,"outputs":[]}]}