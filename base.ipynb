{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install huggingface-hub\n# %pip install numpy\n# %pip install opencv-python\n# %pip install matplotlib\n# %pip install pandas","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/taki0112/vit-tensorflow.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv \"/kaggle/working/vit-tensorflow/vit_tensorflow\" \"/kaggle/working/vit_tensorflow\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install optree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time\nimport math\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:19.631663Z","iopub.execute_input":"2024-04-21T12:45:19.632063Z","iopub.status.idle":"2024-04-21T12:45:19.644239Z","shell.execute_reply.started":"2024-04-21T12:45:19.632032Z","shell.execute_reply":"2024-04-21T12:45:19.642554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:19.816366Z","iopub.execute_input":"2024-04-21T12:45:19.816697Z","iopub.status.idle":"2024-04-21T12:45:19.889031Z","shell.execute_reply.started":"2024-04-21T12:45:19.816676Z","shell.execute_reply":"2024-04-21T12:45:19.887377Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# secret_hf =","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:20.335624Z","iopub.execute_input":"2024-04-21T12:45:20.337126Z","iopub.status.idle":"2024-04-21T12:45:20.341830Z","shell.execute_reply.started":"2024-04-21T12:45:20.337073Z","shell.execute_reply":"2024-04-21T12:45:20.340293Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:20.567946Z","iopub.execute_input":"2024-04-21T12:45:20.569502Z","iopub.status.idle":"2024-04-21T12:45:20.574158Z","shell.execute_reply.started":"2024-04-21T12:45:20.569452Z","shell.execute_reply":"2024-04-21T12:45:20.572718Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Download data","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:21.399655Z","iopub.execute_input":"2024-04-21T12:45:21.400116Z","iopub.status.idle":"2024-04-21T12:45:21.710642Z","shell.execute_reply.started":"2024-04-21T12:45:21.400081Z","shell.execute_reply":"2024-04-21T12:45:21.709198Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'dataset': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"imagedata.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"label.txt\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:21.891531Z","iopub.execute_input":"2024-04-21T12:45:21.891913Z","iopub.status.idle":"2024-04-21T12:45:57.819545Z","shell.execute_reply.started":"2024-04-21T12:45:21.891888Z","shell.execute_reply":"2024-04-21T12:45:57.818371Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"imagedata.zip:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af160d4fb7b04fdcb37cc4fbdcb8f527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"label.txt:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edad7db3b5c04a748ae1f260f5240abe"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'dataset/label.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:57.821327Z","iopub.execute_input":"2024-04-21T12:45:57.821660Z","iopub.status.idle":"2024-04-21T12:46:02.972939Z","shell.execute_reply.started":"2024-04-21T12:45:57.821635Z","shell.execute_reply":"2024-04-21T12:46:02.971809Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nunzip is already the newest version (6.0-25ubuntu1.2).\n0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir datasetImage\n!unzip -q -o \"dataset/imagedata.zip\" -d \"datasetImage\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:02.974338Z","iopub.execute_input":"2024-04-21T12:46:02.974722Z","iopub.status.idle":"2024-04-21T12:46:22.963130Z","shell.execute_reply.started":"2024-04-21T12:46:02.974688Z","shell.execute_reply":"2024-04-21T12:46:22.961247Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'datasetImage': File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"prefix_path_data = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:22.966263Z","iopub.execute_input":"2024-04-21T12:46:22.966645Z","iopub.status.idle":"2024-04-21T12:46:22.972563Z","shell.execute_reply.started":"2024-04-21T12:46:22.966616Z","shell.execute_reply":"2024-04-21T12:46:22.971015Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"rawlabel = \"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:22.974113Z","iopub.execute_input":"2024-04-21T12:46:22.974497Z","iopub.status.idle":"2024-04-21T12:46:22.986372Z","shell.execute_reply.started":"2024-04-21T12:46:22.974466Z","shell.execute_reply":"2024-04-21T12:46:22.985277Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# load label\nwith open(os.path.join(prefix_path_data, \"dataset/label.txt\"), \"r\") as f:\n    rawlabel = f.read()\n    \n# G93aRj07CIZPKaC8.jpg {\"label-8\":14,\"label-7\":3,\"label-2\":4} 16\n# name image, label(json), totel people vote\n# Format to json {name, label, totel}\nlabelDataset = []\narrayRawLabel = rawlabel.split(\"\\n\")\nfor ele in arrayRawLabel:\n    eleArr = ele.split(\" \")\n    try:\n        labelDataset.append({\n            \"name\": eleArr[0],\n            \"label\": json.loads(eleArr[1]),\n            \"total\": int(eleArr[2])\n        })\n    except:\n        print(ele)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.600033Z","iopub.execute_input":"2024-04-21T12:48:41.600429Z","iopub.status.idle":"2024-04-21T12:48:41.615305Z","shell.execute_reply.started":"2024-04-21T12:48:41.600404Z","shell.execute_reply":"2024-04-21T12:48:41.613280Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label 0 -> 10, 0 is not good image need to delete\ndef LabelsToVector(labels):\n    vectorLabel = [0] * 11\n    try:\n        for label, num in labels.items():\n            if len(label.split(\"-\")) != 2:\n                print(\"Error: \", labels)\n            vectorLabel[int(label.split(\"-\")[1])] = num\n    except:\n        pass\n    return vectorLabel\n\ndef NormalVectorLabel(vectorLabel, total, presentFilter):\n    # Check if label 0 is > presentFilter\n    if total == 0 or vectorLabel[0]/total > presentFilter:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n    \n    # Process localcation label\n    totalLocalVote = 0\n    for i in range(1, 3):\n        totalLocalVote += vectorLabel[i]\n    if totalLocalVote > 0:\n        for i in range(1, 3):\n            vectorLabel[i] = 1 if vectorLabel[i]/totalLocalVote > presentFilter else 0\n    \n    # Process orther label\n    for i in range(3, len(vectorLabel)):\n        vectorLabel[i] = 1 if vectorLabel[i]/total > presentFilter else 0\n        \n    # Process speacil case\n    # Auto set label 1\n    goodLabel = [3, 4]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[1] = 1;\n    \n    # Auto set label 2\n    goodLabel = [7, 8]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[2] = 1;\n            \n    # Check if label 1 or 2 is set\n    if vectorLabel[1] == vectorLabel[2]:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n#     else:\n#         vectorLabel[0] = 0\n    \n    return np.array(vectorLabel)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.760060Z","iopub.execute_input":"2024-04-21T12:48:41.760516Z","iopub.status.idle":"2024-04-21T12:48:41.772078Z","shell.execute_reply.started":"2024-04-21T12:48:41.760485Z","shell.execute_reply":"2024-04-21T12:48:41.770461Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Filter label\nfor ele in labelDataset:\n    # Only get label with > 50% vote\n    ele[\"label\"] = NormalVectorLabel(LabelsToVector(ele[\"label\"]), ele[\"total\"], 0.5)\n    \n# Filter bad image\nclearLabelDataset = []\nfor ele in labelDataset:\n    if ele[\"label\"][0] == 0:\n        ele[\"label\"] = ele[\"label\"][1:]\n        clearLabelDataset.append(ele)\nlabelDataset = clearLabelDataset","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:41.907648Z","iopub.execute_input":"2024-04-21T12:48:41.908094Z","iopub.status.idle":"2024-04-21T12:48:41.924086Z","shell.execute_reply.started":"2024-04-21T12:48:41.908068Z","shell.execute_reply":"2024-04-21T12:48:41.922872Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Add map image name to label\nmapImageNameToLabel = {}\nfor ele in labelDataset:\n    mapImageNameToLabel[ele[\"name\"]] = ele[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:43.747635Z","iopub.execute_input":"2024-04-21T12:48:43.748043Z","iopub.status.idle":"2024-04-21T12:48:43.754269Z","shell.execute_reply.started":"2024-04-21T12:48:43.748019Z","shell.execute_reply":"2024-04-21T12:48:43.752812Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Map name for fast filter image\nmapNameFastQuery = set()\nfor ele in labelDataset:\n    mapNameFastQuery.add(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:43.911297Z","iopub.execute_input":"2024-04-21T12:48:43.911723Z","iopub.status.idle":"2024-04-21T12:48:43.920158Z","shell.execute_reply.started":"2024-04-21T12:48:43.911690Z","shell.execute_reply":"2024-04-21T12:48:43.918811Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:48:44.531263Z","iopub.execute_input":"2024-04-21T12:48:44.531620Z","iopub.status.idle":"2024-04-21T12:48:44.538233Z","shell.execute_reply.started":"2024-04-21T12:48:44.531597Z","shell.execute_reply":"2024-04-21T12:48:44.536585Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load image\nimagesDataset = {}\nfor label in labelDataset:\n    if label[\"name\"] not in mapNameFastQuery:\n        continue\n    img = resize_image_reduce_size(\n        cv2.imread(os.path.join(prefix_path_data, \"datasetImage/file\", label['name'])),\n        224\n    )\n    imagesDataset[label['name']] = img","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-21T12:48:45.131549Z","iopub.execute_input":"2024-04-21T12:48:45.131972Z","iopub.status.idle":"2024-04-21T12:50:02.837659Z","shell.execute_reply.started":"2024-04-21T12:48:45.131945Z","shell.execute_reply":"2024-04-21T12:50:02.836672Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Process","metadata":{}},{"cell_type":"code","source":"print(len(labelDataset))\nprint(len(imagesDataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:02.839565Z","iopub.execute_input":"2024-04-21T12:50:02.839910Z","iopub.status.idle":"2024-04-21T12:50:02.845644Z","shell.execute_reply.started":"2024-04-21T12:50:02.839882Z","shell.execute_reply":"2024-04-21T12:50:02.844534Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"768\n768\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot analytic banlance dataset\n\ntotalLabelDataset = np.array([0] * 10)\nfor ele in labelDataset:\n    totalLabelDataset += ele[\"label\"]\n\nprint(totalLabelDataset)\n    \n# Draw\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:02.847846Z","iopub.execute_input":"2024-04-21T12:50:02.848441Z","iopub.status.idle":"2024-04-21T12:50:03.049470Z","shell.execute_reply.started":"2024-04-21T12:50:02.848399Z","shell.execute_reply":"2024-04-21T12:50:03.047810Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[298 470 142  95  63  48 112  63  44  94]\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<BarContainer object of 10 artists>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"print(labelDataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:03.052959Z","iopub.execute_input":"2024-04-21T12:50:03.053396Z","iopub.status.idle":"2024-04-21T12:50:03.060062Z","shell.execute_reply.started":"2024-04-21T12:50:03.053364Z","shell.execute_reply":"2024-04-21T12:50:03.058432Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"{'name': 'G93aRj07CIZPKaC8.jpg', 'label': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0]), 'total': 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"csvDataJSON = []\nlistGoodImage = []\nlabelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\nfor ele in labelDataset:\n    labelTemp = {}\n    for i in range(len(labelValue)):\n        labelTemp[labelValue[i]] = ele[\"label\"][i]\n    csvDataJSON.append({\n        \"file\": ele[\"name\"],\n        **labelTemp\n    })\n    listGoodImage.append(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:03.061563Z","iopub.execute_input":"2024-04-21T12:50:03.061930Z","iopub.status.idle":"2024-04-21T12:50:03.078173Z","shell.execute_reply.started":"2024-04-21T12:50:03.061902Z","shell.execute_reply":"2024-04-21T12:50:03.076608Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:03.080046Z","iopub.execute_input":"2024-04-21T12:50:03.080515Z","iopub.status.idle":"2024-04-21T12:50:03.114851Z","shell.execute_reply.started":"2024-04-21T12:50:03.080476Z","shell.execute_reply":"2024-04-21T12:50:03.113089Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Create list good \nf = open(\"listimage.txt\", \"w\")\nf.write(\"\\n\".join(listGoodImage))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:03.116339Z","iopub.execute_input":"2024-04-21T12:50:03.116701Z","iopub.status.idle":"2024-04-21T12:50:03.128606Z","shell.execute_reply.started":"2024-04-21T12:50:03.116667Z","shell.execute_reply":"2024-04-21T12:50:03.127375Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Note:\n# imagesDataset is an Dict key is name image, value is image data\n# Using: get image data of label name N => imagesDataset[N]\n# Get image data of label i => imagesDataset[labelDataset[i][\"name\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:03.129827Z","iopub.execute_input":"2024-04-21T12:50:03.130115Z","iopub.status.idle":"2024-04-21T12:50:03.142789Z","shell.execute_reply.started":"2024-04-21T12:50:03.130090Z","shell.execute_reply":"2024-04-21T12:50:03.141169Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Process data to send","metadata":{}},{"cell_type":"code","source":"from functools import cmp_to_key","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:47.911938Z","iopub.execute_input":"2024-04-21T12:50:47.912389Z","iopub.status.idle":"2024-04-21T12:50:47.918216Z","shell.execute_reply.started":"2024-04-21T12:50:47.912356Z","shell.execute_reply":"2024-04-21T12:50:47.916641Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"!rm -rf compressImage","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:54:08.765947Z","iopub.execute_input":"2024-04-21T12:54:08.766346Z","iopub.status.idle":"2024-04-21T12:54:09.081314Z","shell.execute_reply.started":"2024-04-21T12:54:08.766318Z","shell.execute_reply":"2024-04-21T12:54:09.079174Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"!mkdir compressImage","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:54:11.589990Z","iopub.execute_input":"2024-04-21T12:54:11.590433Z","iopub.status.idle":"2024-04-21T12:54:11.907484Z","shell.execute_reply.started":"2024-04-21T12:54:11.590398Z","shell.execute_reply":"2024-04-21T12:54:11.905395Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"labelDataset.sort(key=cmp_to_key(lambda x, y: y[\"total\"] - x[\"total\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:50:48.434262Z","iopub.execute_input":"2024-04-21T12:50:48.434583Z","iopub.status.idle":"2024-04-21T12:50:48.441667Z","shell.execute_reply.started":"2024-04-21T12:50:48.434559Z","shell.execute_reply":"2024-04-21T12:50:48.439986Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"listCompressConfig = [100, 80, 50, 30, 20, 10, 5]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:44.805615Z","iopub.execute_input":"2024-04-21T12:53:44.807127Z","iopub.status.idle":"2024-04-21T12:53:44.813259Z","shell.execute_reply.started":"2024-04-21T12:53:44.807059Z","shell.execute_reply":"2024-04-21T12:53:44.811852Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Get all label type 9\nlistAddionEle = []\nfor ele in labelDataset:\n    if ele[\"label\"][8] >= 1:\n        listAddionEle.append(ele)\n\nprint(len(listAddionEle))\n\n# Add image from labelDataset\nfor ele in labelDataset[0:400 - len(listAddionEle)]:\n    listAddionEle.append(ele)\n    \nprint(len(listAddionEle))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:58:41.517765Z","iopub.execute_input":"2024-04-21T12:58:41.518191Z","iopub.status.idle":"2024-04-21T12:58:41.526859Z","shell.execute_reply.started":"2024-04-21T12:58:41.518166Z","shell.execute_reply":"2024-04-21T12:58:41.525254Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"44\n400\n","output_type":"stream"}]},{"cell_type":"code","source":"labelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\ncsvDataJSON = []\ntotalLabelDataset = np.array([0] * 10)\ni = 0\nfor ele in listAddionEle:\n    i += 1\n    file_name = os.path.join(\"compressImage\", \"{0}.jpg\".format(i))\n    for j in range(len(listCompressConfig)):\n        cv2.imwrite(\n            file_name, imagesDataset[ele[\"name\"]],\n            [int(cv2.IMWRITE_JPEG_QUALITY), listCompressConfig[j]]\n        )\n        file_size = os.stat(file_name).st_size / 1024\n        if file_size <= 20.0:\n            break\n    file_size = os.stat(file_name).st_size / 1024\n    if file_size > 20.0:\n        print(\"Error outsize {0}\".format(i))\n        \n    # Add analytics\n    totalLabelDataset += ele[\"label\"]\n    \n    # Add csv\n    labelTemp = {}\n    for j in range(len(labelValue)):\n        labelTemp[labelValue[j]] = ele[\"label\"][j]\n    csvDataJSON.append({\n        \"file\": \"{0}.jpg\".format(i),\n        **labelTemp\n    })\n    \n# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)\n    \n# Draw\nprint(totalLabelDataset)\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:58:45.934009Z","iopub.execute_input":"2024-04-21T12:58:45.934424Z","iopub.status.idle":"2024-04-21T12:58:48.412852Z","shell.execute_reply.started":"2024-04-21T12:58:45.934394Z","shell.execute_reply":"2024-04-21T12:58:48.411679Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"[207 193  89  64  49  28  59  29  47  26]\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<BarContainer object of 10 artists>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r compressImage.zip compressImage","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:58:55.218184Z","iopub.execute_input":"2024-04-21T12:58:55.218587Z","iopub.status.idle":"2024-04-21T12:58:55.766985Z","shell.execute_reply.started":"2024-04-21T12:58:55.218563Z","shell.execute_reply":"2024-04-21T12:58:55.765378Z"},"scrolled":true,"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"  adding: compressImage/ (stored 0%)\n  adding: compressImage/224.jpg (deflated 1%)\n  adding: compressImage/118.jpg (deflated 1%)\n  adding: compressImage/65.jpg (deflated 1%)\n  adding: compressImage/350.jpg (deflated 1%)\n  adding: compressImage/133.jpg (deflated 1%)\n  adding: compressImage/373.jpg (deflated 1%)\n  adding: compressImage/393.jpg (deflated 1%)\n  adding: compressImage/58.jpg (deflated 1%)\n  adding: compressImage/142.jpg (deflated 1%)\n  adding: compressImage/351.jpg (deflated 2%)\n  adding: compressImage/318.jpg (deflated 1%)\n  adding: compressImage/384.jpg (deflated 1%)\n  adding: compressImage/304.jpg (deflated 1%)\n  adding: compressImage/387.jpg (deflated 2%)\n  adding: compressImage/365.jpg (deflated 1%)\n  adding: compressImage/179.jpg (deflated 1%)\n  adding: compressImage/378.jpg (deflated 1%)\n  adding: compressImage/210.jpg (deflated 1%)\n  adding: compressImage/102.jpg (deflated 1%)\n  adding: compressImage/80.jpg (deflated 1%)\n  adding: compressImage/322.jpg (deflated 1%)\n  adding: compressImage/68.jpg (deflated 2%)\n  adding: compressImage/369.jpg (deflated 1%)\n  adding: compressImage/292.jpg (deflated 2%)\n  adding: compressImage/270.jpg (deflated 1%)\n  adding: compressImage/286.jpg (deflated 1%)\n  adding: compressImage/269.jpg (deflated 1%)\n  adding: compressImage/366.jpg (deflated 1%)\n  adding: compressImage/38.jpg (deflated 1%)\n  adding: compressImage/364.jpg (deflated 1%)\n  adding: compressImage/115.jpg (deflated 2%)\n  adding: compressImage/159.jpg (deflated 1%)\n  adding: compressImage/207.jpg (deflated 1%)\n  adding: compressImage/130.jpg (deflated 2%)\n  adding: compressImage/96.jpg (deflated 1%)\n  adding: compressImage/151.jpg (deflated 2%)\n  adding: compressImage/160.jpg (deflated 2%)\n  adding: compressImage/111.jpg (deflated 1%)\n  adding: compressImage/74.jpg (deflated 2%)\n  adding: compressImage/225.jpg (deflated 1%)\n  adding: compressImage/400.jpg (deflated 1%)\n  adding: compressImage/348.jpg (deflated 1%)\n  adding: compressImage/24.jpg (deflated 1%)\n  adding: compressImage/94.jpg (deflated 1%)\n  adding: compressImage/340.jpg (deflated 2%)\n  adding: compressImage/283.jpg (deflated 1%)\n  adding: compressImage/371.jpg (deflated 2%)\n  adding: compressImage/40.jpg (deflated 1%)\n  adding: compressImage/376.jpg (deflated 1%)\n  adding: compressImage/234.jpg (deflated 1%)\n  adding: compressImage/31.jpg (deflated 1%)\n  adding: compressImage/116.jpg (deflated 1%)\n  adding: compressImage/311.jpg (deflated 1%)\n  adding: compressImage/119.jpg (deflated 1%)\n  adding: compressImage/125.jpg (deflated 2%)\n  adding: compressImage/34.jpg (deflated 1%)\n  adding: compressImage/28.jpg (deflated 1%)\n  adding: compressImage/280.jpg (deflated 1%)\n  adding: compressImage/181.jpg (deflated 2%)\n  adding: compressImage/277.jpg (deflated 1%)\n  adding: compressImage/25.jpg (deflated 1%)\n  adding: compressImage/217.jpg (deflated 2%)\n  adding: compressImage/219.jpg (deflated 1%)\n  adding: compressImage/356.jpg (deflated 1%)\n  adding: compressImage/230.jpg (deflated 1%)\n  adding: compressImage/5.jpg (deflated 1%)\n  adding: compressImage/294.jpg (deflated 1%)\n  adding: compressImage/16.jpg (deflated 1%)\n  adding: compressImage/153.jpg (deflated 2%)\n  adding: compressImage/70.jpg (deflated 1%)\n  adding: compressImage/9.jpg (deflated 1%)\n  adding: compressImage/155.jpg (deflated 1%)\n  adding: compressImage/308.jpg (deflated 1%)\n  adding: compressImage/56.jpg (deflated 4%)\n  adding: compressImage/75.jpg (deflated 2%)\n  adding: compressImage/193.jpg (deflated 1%)\n  adding: compressImage/389.jpg (deflated 1%)\n  adding: compressImage/229.jpg (deflated 1%)\n  adding: compressImage/178.jpg (deflated 1%)\n  adding: compressImage/33.jpg (deflated 1%)\n  adding: compressImage/273.jpg (deflated 1%)\n  adding: compressImage/289.jpg (deflated 1%)\n  adding: compressImage/172.jpg (deflated 1%)\n  adding: compressImage/372.jpg (deflated 1%)\n  adding: compressImage/287.jpg (deflated 1%)\n  adding: compressImage/171.jpg (deflated 1%)\n  adding: compressImage/239.jpg (deflated 1%)\n  adding: compressImage/236.jpg (deflated 1%)\n  adding: compressImage/37.jpg (deflated 1%)\n  adding: compressImage/81.jpg (deflated 1%)\n  adding: compressImage/15.jpg (deflated 2%)\n  adding: compressImage/220.jpg (deflated 1%)\n  adding: compressImage/189.jpg (deflated 1%)\n  adding: compressImage/279.jpg (deflated 1%)\n  adding: compressImage/349.jpg (deflated 1%)\n  adding: compressImage/342.jpg (deflated 2%)\n  adding: compressImage/346.jpg (deflated 1%)\n  adding: compressImage/355.jpg (deflated 1%)\n  adding: compressImage/108.jpg (deflated 2%)\n  adding: compressImage/246.jpg (deflated 1%)\n  adding: compressImage/10.jpg (deflated 1%)\n  adding: compressImage/201.jpg (deflated 1%)\n  adding: compressImage/359.jpg (deflated 2%)\n  adding: compressImage/90.jpg (deflated 2%)\n  adding: compressImage/221.jpg (deflated 1%)\n  adding: compressImage/77.jpg (deflated 1%)\n  adding: compressImage/103.jpg (deflated 5%)\n  adding: compressImage/156.jpg (deflated 1%)\n  adding: compressImage/303.jpg (deflated 1%)\n  adding: compressImage/29.jpg (deflated 1%)\n  adding: compressImage/48.jpg (deflated 1%)\n  adding: compressImage/32.jpg (deflated 1%)\n  adding: compressImage/323.jpg (deflated 2%)\n  adding: compressImage/188.jpg (deflated 1%)\n  adding: compressImage/187.jpg (deflated 1%)\n  adding: compressImage/275.jpg (deflated 1%)\n  adding: compressImage/386.jpg (deflated 1%)\n  adding: compressImage/135.jpg (deflated 1%)\n  adding: compressImage/180.jpg (deflated 1%)\n  adding: compressImage/79.jpg (deflated 4%)\n  adding: compressImage/190.jpg (deflated 1%)\n  adding: compressImage/62.jpg (deflated 1%)\n  adding: compressImage/100.jpg (deflated 5%)\n  adding: compressImage/332.jpg (deflated 1%)\n  adding: compressImage/6.jpg (deflated 1%)\n  adding: compressImage/175.jpg (deflated 1%)\n  adding: compressImage/166.jpg (deflated 1%)\n  adding: compressImage/186.jpg (deflated 2%)\n  adding: compressImage/107.jpg (deflated 1%)\n  adding: compressImage/241.jpg (deflated 1%)\n  adding: compressImage/161.jpg (deflated 2%)\n  adding: compressImage/306.jpg (deflated 1%)\n  adding: compressImage/370.jpg (deflated 1%)\n  adding: compressImage/256.jpg (deflated 1%)\n  adding: compressImage/164.jpg (deflated 1%)\n  adding: compressImage/299.jpg (deflated 1%)\n  adding: compressImage/85.jpg (deflated 1%)\n  adding: compressImage/255.jpg (deflated 1%)\n  adding: compressImage/329.jpg (deflated 1%)\n  adding: compressImage/148.jpg (deflated 1%)\n  adding: compressImage/327.jpg (deflated 2%)\n  adding: compressImage/41.jpg (deflated 1%)\n  adding: compressImage/312.jpg (deflated 1%)\n  adding: compressImage/296.jpg (deflated 1%)\n  adding: compressImage/30.jpg (deflated 1%)\n  adding: compressImage/250.jpg (deflated 1%)\n  adding: compressImage/198.jpg (deflated 1%)\n  adding: compressImage/251.jpg (deflated 2%)\n  adding: compressImage/257.jpg (deflated 2%)\n  adding: compressImage/183.jpg (deflated 1%)\n  adding: compressImage/194.jpg (deflated 6%)\n  adding: compressImage/200.jpg (deflated 1%)\n  adding: compressImage/285.jpg (deflated 2%)\n  adding: compressImage/214.jpg (deflated 1%)\n  adding: compressImage/59.jpg (deflated 2%)\n  adding: compressImage/67.jpg (deflated 4%)\n  adding: compressImage/320.jpg (deflated 1%)\n  adding: compressImage/127.jpg (deflated 1%)\n  adding: compressImage/60.jpg (deflated 2%)\n  adding: compressImage/64.jpg (deflated 3%)\n  adding: compressImage/291.jpg (deflated 1%)\n  adding: compressImage/97.jpg (deflated 2%)\n  adding: compressImage/248.jpg (deflated 1%)\n  adding: compressImage/293.jpg (deflated 1%)\n  adding: compressImage/196.jpg (deflated 1%)\n  adding: compressImage/101.jpg (deflated 1%)\n  adding: compressImage/215.jpg (deflated 1%)\n  adding: compressImage/54.jpg (deflated 1%)\n  adding: compressImage/167.jpg (deflated 3%)\n  adding: compressImage/169.jpg (deflated 1%)\n  adding: compressImage/195.jpg (deflated 1%)\n  adding: compressImage/267.jpg (deflated 1%)\n  adding: compressImage/92.jpg (deflated 1%)\n  adding: compressImage/22.jpg (deflated 1%)\n  adding: compressImage/295.jpg (deflated 1%)\n  adding: compressImage/353.jpg (deflated 1%)\n  adding: compressImage/129.jpg (deflated 1%)\n  adding: compressImage/398.jpg (deflated 2%)\n  adding: compressImage/150.jpg (deflated 1%)\n  adding: compressImage/218.jpg (deflated 1%)\n  adding: compressImage/174.jpg (deflated 1%)\n  adding: compressImage/388.jpg (deflated 1%)\n  adding: compressImage/76.jpg (deflated 3%)\n  adding: compressImage/106.jpg (deflated 1%)\n  adding: compressImage/98.jpg (deflated 1%)\n  adding: compressImage/144.jpg (deflated 2%)\n  adding: compressImage/26.jpg (deflated 1%)\n  adding: compressImage/42.jpg (deflated 2%)\n  adding: compressImage/20.jpg (deflated 1%)\n  adding: compressImage/154.jpg (deflated 2%)\n  adding: compressImage/266.jpg (deflated 1%)\n  adding: compressImage/288.jpg (deflated 2%)\n  adding: compressImage/36.jpg (deflated 1%)\n  adding: compressImage/162.jpg (deflated 1%)\n  adding: compressImage/63.jpg (deflated 1%)\n  adding: compressImage/263.jpg (deflated 1%)\n  adding: compressImage/253.jpg (deflated 1%)\n  adding: compressImage/278.jpg (deflated 1%)\n  adding: compressImage/141.jpg (deflated 1%)\n  adding: compressImage/35.jpg (deflated 1%)\n  adding: compressImage/117.jpg (deflated 1%)\n  adding: compressImage/55.jpg (deflated 2%)\n  adding: compressImage/345.jpg (deflated 1%)\n  adding: compressImage/245.jpg (deflated 1%)\n  adding: compressImage/367.jpg (deflated 1%)\n  adding: compressImage/341.jpg (deflated 2%)\n  adding: compressImage/105.jpg (deflated 1%)\n  adding: compressImage/109.jpg (deflated 1%)\n  adding: compressImage/83.jpg (deflated 1%)\n  adding: compressImage/211.jpg (deflated 1%)\n  adding: compressImage/240.jpg (deflated 1%)\n  adding: compressImage/331.jpg (deflated 1%)\n  adding: compressImage/147.jpg (deflated 1%)\n  adding: compressImage/330.jpg (deflated 1%)\n  adding: compressImage/71.jpg (deflated 1%)\n  adding: compressImage/231.jpg (deflated 1%)\n  adding: compressImage/237.jpg (deflated 1%)\n  adding: compressImage/128.jpg (deflated 1%)\n  adding: compressImage/13.jpg (deflated 1%)\n  adding: compressImage/310.jpg (deflated 1%)\n  adding: compressImage/21.jpg (deflated 1%)\n  adding: compressImage/121.jpg (deflated 1%)\n  adding: compressImage/247.jpg (deflated 1%)\n  adding: compressImage/182.jpg (deflated 2%)\n  adding: compressImage/43.jpg (deflated 2%)\n  adding: compressImage/232.jpg (deflated 1%)\n  adding: compressImage/354.jpg (deflated 2%)\n  adding: compressImage/302.jpg (deflated 1%)\n  adding: compressImage/143.jpg (deflated 1%)\n  adding: compressImage/262.jpg (deflated 1%)\n  adding: compressImage/252.jpg (deflated 1%)\n  adding: compressImage/368.jpg (deflated 2%)\n  adding: compressImage/271.jpg (deflated 2%)\n  adding: compressImage/87.jpg (deflated 1%)\n  adding: compressImage/281.jpg (deflated 1%)\n  adding: compressImage/199.jpg (deflated 1%)\n  adding: compressImage/50.jpg (deflated 1%)\n  adding: compressImage/272.jpg (deflated 1%)\n  adding: compressImage/222.jpg (deflated 1%)\n  adding: compressImage/73.jpg (deflated 3%)\n  adding: compressImage/328.jpg (deflated 2%)\n  adding: compressImage/123.jpg (deflated 1%)\n  adding: compressImage/242.jpg (deflated 1%)\n  adding: compressImage/335.jpg (deflated 2%)\n  adding: compressImage/244.jpg (deflated 1%)\n  adding: compressImage/120.jpg (deflated 2%)\n  adding: compressImage/184.jpg (deflated 2%)\n  adding: compressImage/53.jpg (deflated 2%)\n  adding: compressImage/204.jpg (deflated 2%)\n  adding: compressImage/78.jpg (deflated 1%)\n  adding: compressImage/390.jpg (deflated 1%)\n  adding: compressImage/228.jpg (deflated 2%)\n  adding: compressImage/206.jpg (deflated 2%)\n  adding: compressImage/168.jpg (deflated 1%)\n  adding: compressImage/157.jpg (deflated 1%)\n  adding: compressImage/397.jpg (deflated 1%)\n  adding: compressImage/343.jpg (deflated 1%)\n  adding: compressImage/385.jpg (deflated 1%)\n  adding: compressImage/216.jpg (deflated 1%)\n  adding: compressImage/290.jpg (deflated 1%)\n  adding: compressImage/360.jpg (deflated 1%)\n  adding: compressImage/3.jpg (deflated 1%)\n  adding: compressImage/395.jpg (deflated 1%)\n  adding: compressImage/112.jpg (deflated 1%)\n  adding: compressImage/317.jpg (deflated 1%)\n  adding: compressImage/334.jpg (deflated 1%)\n  adding: compressImage/319.jpg (deflated 1%)\n  adding: compressImage/333.jpg (deflated 2%)\n  adding: compressImage/265.jpg (deflated 1%)\n  adding: compressImage/138.jpg (deflated 1%)\n  adding: compressImage/377.jpg (deflated 2%)\n  adding: compressImage/176.jpg (deflated 1%)\n  adding: compressImage/124.jpg (deflated 1%)\n  adding: compressImage/146.jpg (deflated 1%)\n  adding: compressImage/254.jpg (deflated 1%)\n  adding: compressImage/336.jpg (deflated 2%)\n  adding: compressImage/352.jpg (deflated 1%)\n  adding: compressImage/243.jpg (deflated 1%)\n  adding: compressImage/12.jpg (deflated 1%)\n  adding: compressImage/261.jpg (deflated 1%)\n  adding: compressImage/264.jpg (deflated 1%)\n  adding: compressImage/274.jpg (deflated 1%)\n  adding: compressImage/66.jpg (deflated 2%)\n  adding: compressImage/51.jpg (deflated 2%)\n  adding: compressImage/152.jpg (deflated 1%)\n  adding: compressImage/163.jpg (deflated 1%)\n  adding: compressImage/49.jpg (deflated 1%)\n  adding: compressImage/46.jpg (deflated 3%)\n  adding: compressImage/57.jpg (deflated 1%)\n  adding: compressImage/47.jpg (deflated 3%)\n  adding: compressImage/131.jpg (deflated 1%)\n  adding: compressImage/361.jpg (deflated 2%)\n  adding: compressImage/17.jpg (deflated 1%)\n  adding: compressImage/86.jpg (deflated 1%)\n  adding: compressImage/139.jpg (deflated 2%)\n  adding: compressImage/357.jpg (deflated 1%)\n  adding: compressImage/344.jpg (deflated 1%)\n  adding: compressImage/347.jpg (deflated 1%)\n  adding: compressImage/316.jpg (deflated 1%)\n  adding: compressImage/305.jpg (deflated 1%)\n  adding: compressImage/149.jpg (deflated 1%)\n  adding: compressImage/145.jpg (deflated 1%)\n  adding: compressImage/93.jpg (deflated 1%)\n  adding: compressImage/23.jpg (deflated 1%)\n  adding: compressImage/223.jpg (deflated 1%)\n  adding: compressImage/301.jpg (deflated 1%)\n  adding: compressImage/177.jpg (deflated 1%)\n  adding: compressImage/209.jpg (deflated 1%)\n  adding: compressImage/268.jpg (deflated 2%)\n  adding: compressImage/313.jpg (deflated 1%)\n  adding: compressImage/249.jpg (deflated 1%)\n  adding: compressImage/380.jpg (deflated 1%)\n  adding: compressImage/235.jpg (deflated 1%)\n  adding: compressImage/99.jpg (deflated 2%)\n  adding: compressImage/338.jpg (deflated 1%)\n  adding: compressImage/158.jpg (deflated 1%)\n  adding: compressImage/2.jpg (deflated 1%)\n  adding: compressImage/52.jpg (deflated 1%)\n  adding: compressImage/95.jpg (deflated 1%)\n  adding: compressImage/396.jpg (deflated 2%)\n  adding: compressImage/7.jpg (deflated 1%)\n  adding: compressImage/185.jpg (deflated 1%)\n  adding: compressImage/208.jpg (deflated 1%)\n  adding: compressImage/358.jpg (deflated 3%)\n  adding: compressImage/91.jpg (deflated 1%)\n  adding: compressImage/276.jpg (deflated 1%)\n  adding: compressImage/126.jpg (deflated 2%)\n  adding: compressImage/337.jpg (deflated 1%)\n  adding: compressImage/363.jpg (deflated 1%)\n  adding: compressImage/297.jpg (deflated 1%)\n  adding: compressImage/298.jpg (deflated 1%)\n  adding: compressImage/258.jpg (deflated 1%)\n  adding: compressImage/19.jpg (deflated 1%)\n  adding: compressImage/399.jpg (deflated 2%)\n  adding: compressImage/321.jpg (deflated 1%)\n  adding: compressImage/339.jpg (deflated 2%)\n  adding: compressImage/383.jpg (deflated 2%)\n  adding: compressImage/72.jpg (deflated 3%)\n  adding: compressImage/284.jpg (deflated 1%)\n  adding: compressImage/61.jpg (deflated 1%)\n  adding: compressImage/381.jpg (deflated 1%)\n  adding: compressImage/213.jpg (deflated 1%)\n  adding: compressImage/362.jpg (deflated 1%)\n  adding: compressImage/374.jpg (deflated 1%)\n  adding: compressImage/44.jpg (deflated 2%)\n  adding: compressImage/122.jpg (deflated 1%)\n  adding: compressImage/375.jpg (deflated 2%)\n  adding: compressImage/14.jpg (deflated 2%)\n  adding: compressImage/110.jpg (deflated 2%)\n  adding: compressImage/233.jpg (deflated 1%)\n  adding: compressImage/69.jpg (deflated 2%)\n  adding: compressImage/132.jpg (deflated 1%)\n  adding: compressImage/114.jpg (deflated 1%)\n  adding: compressImage/192.jpg (deflated 1%)\n  adding: compressImage/325.jpg (deflated 1%)\n  adding: compressImage/165.jpg (deflated 1%)\n  adding: compressImage/259.jpg (deflated 1%)\n  adding: compressImage/314.jpg (deflated 1%)\n  adding: compressImage/326.jpg (deflated 1%)\n  adding: compressImage/394.jpg (deflated 1%)\n  adding: compressImage/4.jpg (deflated 2%)\n  adding: compressImage/203.jpg (deflated 1%)\n  adding: compressImage/113.jpg (deflated 1%)\n  adding: compressImage/134.jpg (deflated 2%)\n  adding: compressImage/39.jpg (deflated 1%)\n  adding: compressImage/205.jpg (deflated 1%)\n  adding: compressImage/226.jpg (deflated 2%)\n  adding: compressImage/392.jpg (deflated 1%)\n  adding: compressImage/137.jpg (deflated 1%)\n  adding: compressImage/282.jpg (deflated 1%)\n  adding: compressImage/1.jpg (deflated 1%)\n  adding: compressImage/104.jpg (deflated 1%)\n  adding: compressImage/170.jpg (deflated 2%)\n  adding: compressImage/315.jpg (deflated 1%)\n  adding: compressImage/8.jpg (deflated 2%)\n  adding: compressImage/324.jpg (deflated 1%)\n  adding: compressImage/238.jpg (deflated 2%)\n  adding: compressImage/140.jpg (deflated 1%)\n  adding: compressImage/18.jpg (deflated 1%)\n  adding: compressImage/88.jpg (deflated 2%)\n  adding: compressImage/82.jpg (deflated 3%)\n  adding: compressImage/382.jpg (deflated 1%)\n  adding: compressImage/309.jpg (deflated 2%)\n  adding: compressImage/45.jpg (deflated 1%)\n  adding: compressImage/212.jpg (deflated 1%)\n  adding: compressImage/11.jpg (deflated 1%)\n  adding: compressImage/202.jpg (deflated 1%)\n  adding: compressImage/89.jpg (deflated 1%)\n  adding: compressImage/391.jpg (deflated 1%)\n  adding: compressImage/260.jpg (deflated 1%)\n  adding: compressImage/300.jpg (deflated 1%)\n  adding: compressImage/307.jpg (deflated 1%)\n  adding: compressImage/379.jpg (deflated 1%)\n  adding: compressImage/227.jpg (deflated 2%)\n  adding: compressImage/191.jpg (deflated 2%)\n  adding: compressImage/173.jpg (deflated 1%)\n  adding: compressImage/136.jpg (deflated 1%)\n  adding: compressImage/197.jpg (deflated 1%)\n  adding: compressImage/84.jpg (deflated 1%)\n  adding: compressImage/27.jpg (deflated 1%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"markdown","source":"### Analytics data","metadata":{}},{"cell_type":"code","source":"minLabel = np.amin(totalLabelDataset)\nprint(minLabel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ele in labelDataset:\n    print(ele)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label2str(label):\n    s = \"\"\n    for i in range(len(label)):\n        s += str(int(label[i]))\n    return s\ndef str2label(s):\n    label = []\n    for i in range(len(s)):\n        label.append(int(s[i]))\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tempCnumDimOnehot = {}\nfor ele in labelDataset:\n    tempCnumDimOnehot[label2str(ele[\"label\"])] = 1\nnumDimOnehot = len(tempCnumDimOnehot)\nprint(numDimOnehot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def index2onehot(index):\n    onehot = [0] * numDimOnehot\n    onehot[index] = 1\n    return onehot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot = {}\nfor ele in labelDataset:\n    if label2str(ele[\"label\"]) not in mapLabel2OneHot:\n        mapLabel2OneHot[label2str(ele[\"label\"])] = index2onehot(len(mapLabel2OneHot))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapLabel2OneHot","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label = {}\nfor i in mapLabel2OneHot:\n    mapOneHot2Label[label2str(mapLabel2OneHot[i])] = str2label(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapOneHot2Label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for ele in labelDataset:\n#     ele[\"label\"] = mapLabel2OneHot[label2str(ele[\"label\"])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoLabel2Onehot(label):\n    return mapLabel2OneHot[label2str(label)]\ndef autoOnehot2Label(onehot):\n    return mapOneHot2Label[label2str(onehot)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(autoOnehot2Label(autoLabel2Onehot([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process image","metadata":{}},{"cell_type":"markdown","source":"#### Constant","metadata":{}},{"cell_type":"code","source":"size_image_model = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Helper function","metadata":{}},{"cell_type":"code","source":"def crop2nimage(image, nimage = 3):\n    # Size of bigest square image\n    sizeSquare = min(image.shape[0], image.shape[1])\n\n    # Rotate image if image is portrait\n    isRotate = False\n    if image.shape[0] > image.shape[1]:\n        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n        isRotate = True\n\n    # Crop n image\n    cropImages = []\n    widthBetween = (image.shape[1] - sizeSquare) / (nimage - 1)\n    for i in range(nimage):\n        x1 = int(i * widthBetween)\n        x2 = int(x1 + sizeSquare)\n        cropImages.append(image[:, x1:x2])\n\n    # Rotate image back\n    if isRotate:\n        for i in range(len(cropImages)):\n            cropImages[i] = cv2.rotate(cropImages[i], cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n    # Convert color to RGB\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.cvtColor(cropImages[i], cv2.COLOR_BGR2RGB)\n        \n    return cropImages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calibrate_image(image, target_size_kb=20):\n    # Resize image to the target size\n    resized_image = cv2.resize(image, (224, 224))\n\n    return resized_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation by type:\n# 1. Random flip\n# 2. Random rotate\n# 4. Random Saturate\n# 3. Random brightness\n# 5. Random crop\n\n# Random flip\ndef random_flip(image, p=0.5):\n    if np.random.rand() < p:\n        return cv2.flip(image, 1)\n    return image\n\n# Random rotate from range angle\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n    (in degrees). The returned image will be large enough to hold the entire\n    new image, with a black background\n    \"\"\"\n\n    # Get the image size\n    # No that's not an error - NumPy stores image matricies backwards\n    image_size = (image.shape[1], image.shape[0])\n    image_center = tuple(np.array(image_size) / 2)\n\n    # Convert the OpenCV 3x2 rotation matrix to 3x3\n    rot_mat = np.vstack(\n        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n    )\n\n    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n    # Shorthand for below calcs\n    image_w2 = image_size[0] * 0.5\n    image_h2 = image_size[1] * 0.5\n\n    # Obtain the rotated coordinates of the image corners\n    rotated_coords = [\n        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n    ]\n\n    # Find the size of the new image\n    x_coords = [pt[0] for pt in rotated_coords]\n    x_pos = [x for x in x_coords if x > 0]\n    x_neg = [x for x in x_coords if x < 0]\n\n    y_coords = [pt[1] for pt in rotated_coords]\n    y_pos = [y for y in y_coords if y > 0]\n    y_neg = [y for y in y_coords if y < 0]\n\n    right_bound = max(x_pos)\n    left_bound = min(x_neg)\n    top_bound = max(y_pos)\n    bot_bound = min(y_neg)\n\n    new_w = int(abs(right_bound - left_bound))\n    new_h = int(abs(top_bound - bot_bound))\n\n    # We require a translation matrix to keep the image centred\n    trans_mat = np.matrix([\n        [1, 0, int(new_w * 0.5 - image_w2)],\n        [0, 1, int(new_h * 0.5 - image_h2)],\n        [0, 0, 1]\n    ])\n\n    # Compute the tranform for the combined rotation and translation\n    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n    # Apply the transform\n    result = cv2.warpAffine(\n        image,\n        affine_mat,\n        (new_w, new_h),\n        flags=cv2.INTER_LINEAR\n    )\n\n    return result\n\ndef largest_rotated_rect(w, h, angle):\n    \"\"\"\n    Given a rectangle of size wxh that has been rotated by 'angle' (in\n    radians), computes the width and height of the largest possible\n    axis-aligned rectangle within the rotated rectangle.\n\n    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n\n    Converted to Python by Aaron Snoswell\n    \"\"\"\n\n    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n\n    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n\n    delta = math.pi - alpha - gamma\n\n    length = h if (w < h) else w\n\n    d = length * math.cos(alpha)\n    a = d * math.sin(alpha) / math.sin(delta)\n\n    y = a * math.cos(gamma)\n    x = y * math.tan(gamma)\n\n    return (\n        bb_w - 2 * x,\n        bb_h - 2 * y\n    )\n\ndef crop_around_center(image, width, height):\n    \"\"\"\n    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n    around it's centre point\n    \"\"\"\n\n    image_size = (image.shape[1], image.shape[0])\n    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n\n    if(width > image_size[0]):\n        width = image_size[0]\n\n    if(height > image_size[1]):\n        height = image_size[1]\n\n    x1 = int(image_center[0] - width * 0.5)\n    x2 = int(image_center[0] + width * 0.5)\n    y1 = int(image_center[1] - height * 0.5)\n    y2 = int(image_center[1] + height * 0.5)\n\n    return image[y1:y2, x1:x2]\n\ndef random_rotate(image, angle_range=15):\n    angle = np.random.uniform(-angle_range, angle_range)\n    image_height, image_width = image.shape[0:2]\n    image = crop_around_center(\n        rotate_image(image, angle),\n        *largest_rotated_rect(\n            image_width,\n            image_height,\n            math.radians(angle)\n        )\n    )\n    return image\n\n# Random saturate\ndef random_saturate(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 1] = hsv[:, :, 1] * np.random.uniform(low, high)\n    hsv[:, :, 1][hsv[:, :, 1] > 255] = 255\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random brightness\ndef random_brightness(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random crop\ndef random_crop_size(image, size=224):\n    x = np.random.randint(0, image.shape[1] - size)\n    y = np.random.randint(0, image.shape[0] - size)\n    return image[y:y+size, x:x+size]\n\n# Random augment\ndef random_augment(image):\n    image = random_flip(image)\n    image = random_rotate(image)\n    image = random_saturate(image)\n    image = random_brightness(image)\n    # image = random_crop(image)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random noise\ndef random_noise(image, present=0.05):\n    # Randome noice range [0, 255] with present 0.05\n    lran = int(-255 * present)\n    rran = int(255 * present)\n    noise = np.random.randint(lran, rran, image.shape)\n\n    # Add noise to image\n    image = cv2.add(image, noise, dtype=cv2.CV_8UC3)\n\n    return image\n\n# Random blur\ndef random_blur(image, win_size=(3, 3)):\n    image = cv2.GaussianBlur(image, win_size, 0)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image","metadata":{}},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Apply to all image in dataset\nfor imageId in imagesDataset:\n    imagesDataset[imageId] = resize_image_reduce_size(imagesDataset[imageId], size_image_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imwrite(\"test.jpg\", imagesDataset[labelDataset[0][\"name\"]], [cv2.IMWRITE_JPEG_QUALITY, 50])\n# print(os.path.getsize('test.jpg')/1024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data augment","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split image name to label\ntempImageLabelName = [[] for _ in range(numDimOnehot)]\nfor ele in labelDataset:\n    for i in range(len(mapLabel2OneHot[label2str(ele[\"label\"])])):\n        if mapLabel2OneHot[label2str(ele[\"label\"])][i] >= 1:\n            tempImageLabelName[i].append(ele[\"name\"])\n\n# tempImageLabelName = [[] for _ in range(10)]\n# for ele in labelDataset:\n#     for i in range(len(ele[\"label\"])):\n#         if ele[\"label\"][i] >= 1:\n#             tempImageLabelName[i].append(ele[\"name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total len\ntotalTempImageLabelName = []\nfor i in range(len(tempImageLabelName)):\n    totalTempImageLabelName.append(len(tempImageLabelName[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amax(totalTempImageLabelName), np.amin(totalTempImageLabelName))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([i for i in totalTempImageLabelName if i > 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target number image each label after augment\ntarget_number_image = 160\n\nimagesDatasetAug = []\nlabelDatasetAug = []\n# Augment image\nfor i in range(0, len(tempImageLabelName)):\n    print(\"Augment label: \", i)\n    print(\"Number image: \", len(tempImageLabelName[i]))\n    if totalTempImageLabelName[i] >= target_number_image or totalTempImageLabelName[i] == 0:\n        continue\n        \n    numDeltaAdd = target_number_image - totalTempImageLabelName[i]\n    for j in range(numDeltaAdd):\n        # Name image\n        imageName = tempImageLabelName[i][np.random.randint(0, len(tempImageLabelName[i]))]\n        # Random select image\n        image = imagesDataset[imageName]\n        image = random_augment(image)\n        imagesDatasetAug.append(image)\n        \n        labelDatasetAug.append(autoLabel2Onehot(mapImageNameToLabel[imageName]))\n        for k in range(len(autoLabel2Onehot(mapImageNameToLabel[imageName]))):\n            if autoLabel2Onehot(mapImageNameToLabel[imageName])[k] >= 1:\n                totalTempImageLabelName[k] += 1\n        \n#         labelDatasetAug.append(mapImageNameToLabel[imageName])\n#         for k in range(len(mapImageNameToLabel[imageName])):\n#             if mapImageNameToLabel[imageName][k] >= 1:\n#                 totalTempImageLabelName[k] += 1","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(totalTempImageLabelName)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetAug))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(imagesDatasetAug[123])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labelDatasetAug[123])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imagesDatasetArray\nimagesDatasetArray = []\nlabelDatasetArray = []\n\nfor ele in labelDataset:\n    imagesDatasetArray.append(imagesDataset[ele[\"name\"]])\n#     labelDatasetArray.append(ele[\"label\"])\n    labelDatasetArray.append(autoLabel2Onehot(ele[\"label\"]))\n\nfor i in range(len(imagesDatasetAug)):\n    imagesDatasetArray.append(imagesDatasetAug[i])\n    labelDatasetArray.append(labelDatasetAug[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray), len(labelDatasetArray))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image and add some noise and rotate","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3 = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(labelDatasetArray)):\n    image = np.copy(imagesDatasetArray[i])\n    \n    # Crop\n    cropImages = crop2nimage(image, 3)\n\n    # Resize\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.resize(cropImages[i], (size_image_model, size_image_model))\n\n    # Add blur to image\n    for i in range(len(cropImages)):\n        cropImages[i] = random_blur(cropImages[i], (3, 3))\n        \n    # Add noise to image\n    for i in range(len(cropImages)):\n        # Randome noice\n        cropImages[i] = random_noise(cropImages[i], 0.05)\n\n    # Debug\n    # for i in range(len(cropImages)):\n    #     plt.imshow(cropImages[i])\n    #     plt.show()\n    # break\n\n    imagesDatasetArray3.append([cropImages[1]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray3), len(imagesDatasetArray3[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"markdown","source":"### Normal image","metadata":{}},{"cell_type":"markdown","source":"### Import library","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split testcase","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3_training = []\nlabelDatasetArray_training = []\nimagesDatasetArray3_testing = []\nlabelDatasetArray_testing = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = [i for i in range(len(imagesDatasetArray3))]\nnp.random.shuffle(idx)\n\nfor i in range(len(idx)):\n    if i < len(idx) * 0.3:\n        imagesDatasetArray3_training.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_training.append(labelDatasetArray[idx[i]])\n    else:\n        imagesDatasetArray3_testing.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_testing.append(labelDatasetArray[idx[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy\ntypePreprocess = 2 # 0 = [0, 1]  1 = [-1, 1]\nConfigPreprocess = True\nfor i in range(len(imagesDatasetArray3_training)):\n    if ConfigPreprocess:\n        if typePreprocess == 0:\n            imagesDatasetArray3_training[i] = [\n                (np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n        elif typePreprocess == 1:\n            imagesDatasetArray3_training[i] = [\n                (np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) / 255.0 - 0.5) / 0.5 for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n        elif typePreprocess == 2:\n            imagesDatasetArray3_training[i] = [\n                tf.image.per_image_standardization(np.array(imagesDatasetArray3_training[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_training[i]))\n            ]\n    else:\n        imagesDatasetArray3_training[i] = [\n            np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) for j in range(len(imagesDatasetArray3_training[i]))\n        ]\n    labelDatasetArray_training[i] = np.array(labelDatasetArray_training[i], dtype=np.float32)\n    \nfor i in range(len(imagesDatasetArray3_testing)):\n    if ConfigPreprocess:\n        if typePreprocess == 0:\n            imagesDatasetArray3_testing[i] = [\n                (np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n        elif typePreprocess == 1:\n            imagesDatasetArray3_testing[i] = [\n                (np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) / 255.0 - 0.5) / 0.5 for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n        elif typePreprocess == 2:\n            imagesDatasetArray3_testing[i] = [\n                tf.image.per_image_standardization(np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32)) for j in range(len(imagesDatasetArray3_testing[i]))\n            ]\n    else:\n        imagesDatasetArray3_testing[i] = [\n            np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) for j in range(len(imagesDatasetArray3_testing[i]))\n        ]\n    labelDatasetArray_testing[i] = np.array(labelDatasetArray_testing[i], dtype=np.float32)\n\n# imagesDatasetArray3_training = np.array(imagesDatasetArray3_training, dtype=np.float32) / 255.0\n# labelDatasetArray_training = np.array(labelDatasetArray_training, dtype=np.float32)\n# imagesDatasetArray3_testing = np.array(imagesDatasetArray3_testing, dtype=np.float32) / 255.0\n# labelDatasetArray_testing = np.array(labelDatasetArray_testing, dtype=np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build dataset with batch","metadata":{}},{"cell_type":"code","source":"def create_batch_from_arr(arrData, batch_size=64):\n    temp_shape = list(arrData.shape)\n    deltaMiss = ((arrData.shape[0] + batch_size - 1) // batch_size) * batch_size - arrData.shape[0]\n    temp_shape[0] += deltaMiss\n    batchArrData = np.zeros(tuple(temp_shape), dtype=np.float32)\n    # Add to last\n    batchArrData[:arrData.shape[0]] = arrData\n    for i in range(arrData.shape[0], batchArrData.shape[0]):\n        batchArrData[i] = arrData[i - arrData.shape[0]]\n        \n    batchArrData = batchArrData.reshape(tuple([-1, batch_size, *list(batchArrData.shape[1:])]))\n    \n    return batchArrData\n\ndef create_dataset(images, labels, batch_size=64):\n    if batch_size == 0:\n        return (np.array(images), np.array(labels))\n    images = np.array(images, dtype=np.float32)\n    # image is 3 image in array\n    tempImageSplit = []\n    for i in range(images.shape[1]):\n        tempImageSplit.append(create_batch_from_arr(images[:, i], batch_size))\n\n    imagesBatch = []\n    for i in range(len(tempImageSplit[0])):\n        nimage = []\n        for j in range(len(tempImageSplit)):\n            nimage.append(tempImageSplit[j][i])\n        imagesBatch.append(nimage)\n        \n    labels = np.array(labels, dtype=np.float32)\n    labels = create_batch_from_arr(labels, batch_size)\n    \n    return (np.array(imagesBatch), labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 0)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(datasetTraining[0][0][0]), np.amax(datasetTraining[0][0][0]))\nprint(datasetTraining[1][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Init model","metadata":{}},{"cell_type":"code","source":"# Using dataset imagesDatasetArray3 and labelDatasetArray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vit_tensorflow.vit import Transformer\nimport tensorflow.keras.layers as nn\nfrom tensorflow import einsum\nfrom einops import rearrange, repeat\nfrom einops.layers.tensorflow import Rearrange\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViT(tf.keras.layers.Layer):\n    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim,\n                 pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n        super(ViT, self).__init__()\n\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n        \n        self.trearragnge = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n        self.patch_embedding = tf.keras.Sequential([\n            nn.Dense(units=dim)\n        ], name='patch_embedding')\n\n        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches + 1, dim]))\n        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, dim]))\n        self.dropout = nn.Dropout(rate=emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        \n        self.num_classes = num_classes\n\n        self.mlp_head = tf.keras.Sequential([\n            nn.LayerNormalization(),\n            nn.Dense(units=num_classes)\n        ], name='mlp_head')\n        \n    def build(self, input_shape):\n        super(ViT, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, img, training=True, **kwargs):\n        x = self.trearragnge(img)\n        x = self.patch_embedding(x)\n        b, n, d = x.shape\n        \n        cls_tokens = repeat(self.cls_token, 'n d -> b n d', b=b)\n        x = tf.concat([cls_tokens, x], axis=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x, training=training)\n\n        x = self.transformer(x, training=training)\n\n        if self.pool == 'mean':\n            x = tf.reduce_mean(x, axis=1)\n        else:\n            x = x[:, 0]\n\n        x = self.mlp_head(x)\n\n        return x\n    \n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\ndef convolutional_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    # Processing Residue with conv(1,1)\n    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\ndef ResNet(shape = (224, 224, 3), block_layers = [3, 4, 6, 3], using_top_layer = True, classes = 10, activation_class=\"softmax\"):\n    # Step 1 (Setup Input Layer)\n    x_input = tf.keras.layers.Input(shape)\n    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n    # Step 2 (Initial Conv layer along with maxPool)\n    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    # Define size of sub-blocks and initial filter size\n    filter_size = 64\n    # Step 3 Add the Resnet Blocks\n    for i in range(4):\n        if i == 0:\n            # For sub-block 1 Residual/Convolutional block not needed\n            for j in range(block_layers[i]):\n                x = identity_block(x, filter_size)\n        else:\n            # One Residual/Convolutional Block followed by Identity blocks\n            # The filter size will go on increasing by a factor of 2\n            filter_size = filter_size*2\n            x = convolutional_block(x, filter_size)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filter_size)\n    # Step 4 End Dense Network\n    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    if using_top_layer:\n        x = tf.keras.layers.Dense(classes, activation = activation_class)(x)\n    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hotaBlockImage(index):\n    # Build model flow\n#     inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n#     model = tf.keras.applications.EfficientNetV2S(\n#         include_top=True,\n#         weights=None, # 'imagenet'\n#         input_tensor=inputTensor,\n#         input_shape=None,\n#         pooling=None,\n#         classes=512,\n#         classifier_activation='relu', # softmax\n#         include_preprocessing=False\n#     )\n\n#     # Rename layer\n#     layer_names=[layer.name for layer in model.layers]\n#     for layer_name in layer_names:\n#         model.get_layer(name=layer_name).name = \"{0}_{1}\".format(layer_name, index)\n\n#     return model\n    \n#     model = ViT(\n#         image_size = (size_image_model, size_image_model),\n#         patch_size = 32,\n#         num_classes = 1000,\n#         dim = 1024,\n#         depth = 6,\n#         heads = 16,\n#         mlp_dim = 2048,\n#         dropout = 0.1,\n#         emb_dropout = 0.1\n#     )(inputTensor)\n        \n#     return tf.keras.Model(inputs=inputTensor, outputs=model)\n#     return ResNet(\n#         shape = (128, 128, 3), block_layers = [3, 3, 3, 3], using_top_layer = False, classes = 10, activation_class=\"softmax\"\n#     )\n    pass\ndef hotaNBlockImage(nblock = 3):\n#     inputs = []\n#     hidden_outputs = []\n#     for i in range(nblock):\n#         temp_model = hotaBlockImage(i)\n# #         inputs.append(temp_model.input[0]) # Application\n#         inputs.append(temp_model.input)\n#         hidden_outputs.append(temp_model.output)\n        \n#     combined = tf.keras.layers.Concatenate()(hidden_outputs)\n#     outputflatten = tf.keras.layers.Flatten()(combined)\n    \n#     hidden_outputs_2 = tf.keras.layers.Dense(512, activation=\"relu\")(outputflatten)\n# #     outputs = tf.keras.layers.Dense(numDimOnehot, activation=\"softmax\")(hidden_outputs_2)\n#     outputs = tf.keras.layers.Dense(10, activation=\"sigmoid\")(hidden_outputs_2)\n    \n#     return tf.keras.Model(inputs=inputs, outputs=outputs)\n#     return hotaBlockImage(0)\n\n#     return ResNet(\n#         shape = (128, 128, 3), block_layers = [3, 4, 6, 3], using_top_layer = True, classes = 10, activation_class=\"sigmoid\"\n#     )\n    inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n    return tf.keras.applications.EfficientNetV2S(\n        include_top=True,\n        weights=None, # 'imagenet'\n        input_tensor=inputTensor,\n        input_shape=None,\n        pooling=None,\n        classes=19,\n        classifier_activation='softmax', # softmax\n        include_preprocessing=False\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatNumpy2List(data):\n    listData = []\n    for i in range(data.shape[0]):\n        listData.append(data[i])\n        \n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatListMap2MapList(data):\n    listData = []\n    for i in range(data.shape[1]):\n        listData.append(data[:, i])\n    return listData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU Training","metadata":{}},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = hotaNBlockImage(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n\"\"\"\nBinaryFocalCrossentropy(\n    apply_class_balancing=True,\n    alpha=0.92,\n    gamma=2.0,\n) \n\"\"\"\nlossFc = tf.keras.losses.CategoricalCrossentropy()\nhotaModel.compile(loss=lossFc, optimizer=opt, metrics=[\n    tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), # BinaryAccuracy CategoricalAccuracy\n    tf.keras.metrics.AUC(name=\"auc\"),\n    tf.keras.metrics.F1Score(name=\"f1\"),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"saved_checkpoint/checkpoint.keras\",\n    save_weights_only=False,\n    monitor='val_accuracy', # val_auc val_accuracy\n    mode='max',\n    save_best_only=True\n)\nhotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=64,\n    epochs=300,\n    callbacks=[callbackEarlyStop, model_checkpoint_callback],\n    verbose=1,\n    validation_split=0.3,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel = tf.keras.models.load_model(\"saved_checkpoint/checkpoint.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TPU Training","metadata":{}},{"cell_type":"code","source":"try: # detect TPUs\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.TPUStrategy(resolver)\n    \n    print('Running on TPU ', resolver.master())\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    hotaModel = hotaNBlockImage(3)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n#     opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n    opt = tf.keras.optimizers.SGD(learning_rate=1e-1)\n    # CategoricalCrossentropy BinaryCrossentropy BinaryFocalCrossentropy\n    lossFc = tf.keras.losses.BinaryCrossentropy()\n    hotaModel.compile(loss=lossFc, optimizer=opt, metrics=[\n        # BinaryAccuracy CategoricalAccuracy\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.AUC(name=\"auc\"),\n        tf.keras.metrics.F1Score(name=\"f1\"),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8 * 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = int(xTrainignInput[0].shape[0] * 0.8)//batch_size\nvalidation_steps = int(xTrainignInput[0].shape[0] * 0.2)//batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-5, patience=5)\n# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n#     filepath=\"saved_checkpoint/checkpoint.keras\",\n#     save_weights_only=False,\n#     monitor='val_auc',\n#     mode='max',\n#     save_best_only=True\n# )\nhotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=batch_size,\n    epochs=300,\n    callbacks=[],\n    verbose=1,\n    validation_split=0.2,\n    shuffle=True,\n#     initial_epoch=0,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=batch_size,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test predit model","metadata":{}},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, 224, 224, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 132\nfor i in range(len(imagesDatasetArray3[testcase])):\n    plt.imshow(imagesDatasetArray3[testcase][i])\n    plt.show()\nprint(hotaModel.predict(\n    autoFormatInput2PreditOutput(\n        formatImageInput(np.copy(imagesDatasetArray3[testcase]).astype('float32'), 2)\n    ),\n    batch_size=1\n))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save model","metadata":{}},{"cell_type":"code","source":"!mkdir saved_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"hotaEfficientNetV2S_softmax_v2.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only use for TPU\nwith strategy.scope():\n    hotaModel.save(os.path.join(\"saved_model\", model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Upload to huggingface","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf_write = user_secrets.get_secret(\"HUGGINGFACE_WRITE_TOKEN\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf_write","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=os.path.join(\"/kaggle/working/saved_model\", model_name),\n    path_in_repo=model_name,\n    repo_id=\"hotamago/deep-learning-and-application-group-02\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load and testing model","metadata":{}},{"cell_type":"code","source":"model_name = \"hotaResnet12_softmax.keras\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/deep-learning-and-application-group-02\", filename=model_name, revision=\"main\", repo_type=\"model\", local_dir=\"saved_model\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel = tf.keras.models.load_model(os.path.join('saved_model', model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\ntestModel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(\n        from_logits = False,\n    ),\n    optimizer=opt,\n    metrics=[\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.AUC(),\n        tf.keras.metrics.F1Score(),\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])\nxTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=64,\n    verbose=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatInput2PreditOutput(data):\n    return [data[i].reshape((1, 224, 224, 3)) for i in range(len(data))]\n\ndef predict2binary(result):\n    for i in range(len(result)):\n        for j in range(len(result[i])):\n            result[i][j] = 1 if result[i][j] >= 0.5 else 0\n    return result\n\ndef formatImageInput(image, type_format = 0):\n    for i in range(len(image)):\n        image[i] = np.array(image[i], dtype=np.float32)\n        if type_format == 1:\n            image[i] = image[i] / np.float32(255.0)\n        elif type_format == 2:\n            image[i] = image[i] / np.float32(255.0)\n            image[i] = image[i] - np.float32(0.5)\n            image[i] = image[i] / np.float32(0.5)\n    return image\ndef formatSoftmaxOutput(label):\n    for bat in range(len(label)):\n        indexOne = np.argmax(label[bat])\n        for i in range(len(label[bat])):\n            label[bat][i] = 0\n        label[bat][indexOne] = 1\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testcase = 874\n# for i in range(len(imagesDatasetArray3[testcase])):\n#     plt.imshow(imagesDatasetArray3[testcase][i])\n#     plt.show()\nplt.imshow(imagesDatasetArray3[testcase][1])\nplt.show()\nprint(autoOnehot2Label(formatSoftmaxOutput(\n    testModel.predict(\n        autoFormatInput2PreditOutput(\n            formatImageInput(np.copy(imagesDatasetArray3[testcase]).astype('float32'), 2)\n        ),\n        batch_size=1\n    )\n)[0]))\nprint(labelDatasetArray[testcase])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test convert for softmax","metadata":{}},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 64)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaMetrics = [\n    tf.keras.metrics.BinaryAccuracy(name=\"Accuracy\"),\n    tf.keras.metrics.AUC(name=\"AUC\"),\n    tf.keras.metrics.F1Score(name=\"F1Score\"),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertFirst2List(image):\n    return [i for i in image]\ndef autoOnehot2LabelBatch(onehots):\n    labels = []\n    for i in range(len(onehots)):\n        labels.append(autoOnehot2Label(onehots[i]))\n    return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataRunSoft = datasetTesting # datasetTesting datasetTraining\nfor j in range(len(hotaMetrics)):\n    hotaMetrics[j].reset_state()\nfor i in range(len(dataRunSoft[0])):\n    testcaseImage = dataRunSoft[0][i]\n    testcaseLabel = autoOnehot2LabelBatch(np.copy(dataRunSoft[1][i]).astype('float32'))\n    \n    predictOut = np.array(autoOnehot2LabelBatch(formatSoftmaxOutput(\n        testModel.predict(\n            convertFirst2List(np.copy(testcaseImage).astype('float32')),\n            batch_size=64\n        )\n    )), dtype=np.float32)\n    \n    # update metrics\n    for j in range(len(hotaMetrics)):\n        hotaMetrics[j].update_state(testcaseLabel, predictOut)\n    \n    # Print\n    print(\"Done {0} / {1} batch\".format(i + 1, len(dataRunSoft[0])))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(len(hotaMetrics)):\n    print(\"{0}: {1}\".format(hotaMetrics[j].name, hotaMetrics[j].result()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine tuning","metadata":{}},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5)\ntestModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=8,\n    epochs=100,\n    callbacks=[callback],\n    verbose=1,\n    validation_split=0.3,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{},"execution_count":null,"outputs":[]}]}