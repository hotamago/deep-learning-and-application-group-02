{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install huggingface-hub\n%pip install numpy\n%pip install opencv-python\n%pip install matplotlib\n%pip install pandas","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"execution":{"iopub.status.busy":"2024-04-18T10:47:32.584321Z","iopub.execute_input":"2024-04-18T10:47:32.585067Z","iopub.status.idle":"2024-04-18T10:48:35.358843Z","shell.execute_reply.started":"2024-04-18T10:47:32.585036Z","shell.execute_reply":"2024-04-18T10:48:35.357747Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time\nimport math\nimport numpy as np\nimport numpy","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:35.361307Z","iopub.execute_input":"2024-04-18T10:48:35.361997Z","iopub.status.idle":"2024-04-18T10:48:35.367047Z","shell.execute_reply.started":"2024-04-18T10:48:35.361960Z","shell.execute_reply":"2024-04-18T10:48:35.366134Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:35.368413Z","iopub.execute_input":"2024-04-18T10:48:35.369029Z","iopub.status.idle":"2024-04-18T10:48:35.567288Z","shell.execute_reply.started":"2024-04-18T10:48:35.368996Z","shell.execute_reply":"2024-04-18T10:48:35.566536Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# secret_hf =","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:35.569274Z","iopub.execute_input":"2024-04-18T10:48:35.569567Z","iopub.status.idle":"2024-04-18T10:48:35.573640Z","shell.execute_reply.started":"2024-04-18T10:48:35.569541Z","shell.execute_reply":"2024-04-18T10:48:35.572672Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:35.574820Z","iopub.execute_input":"2024-04-18T10:48:35.575092Z","iopub.status.idle":"2024-04-18T10:48:35.583815Z","shell.execute_reply.started":"2024-04-18T10:48:35.575052Z","shell.execute_reply":"2024-04-18T10:48:35.583111Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Download data","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:35.584997Z","iopub.execute_input":"2024-04-18T10:48:35.585347Z","iopub.status.idle":"2024-04-18T10:48:36.539653Z","shell.execute_reply.started":"2024-04-18T10:48:35.585316Z","shell.execute_reply":"2024-04-18T10:48:36.538618Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"imagedata.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/Hoc-sau-va-ung-dung-nhom-2\", filename=\"label.txt\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:48:36.541089Z","iopub.execute_input":"2024-04-18T10:48:36.541383Z","iopub.status.idle":"2024-04-18T10:49:53.619176Z","shell.execute_reply.started":"2024-04-18T10:48:36.541347Z","shell.execute_reply":"2024-04-18T10:49:53.618265Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"imagedata.zip:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77093765a90b460ab9f754361ce59d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"label.txt:   0%|          | 0.00/53.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3778a29d43e4255898a66b9bd51f79a"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'dataset/label.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:49:53.620519Z","iopub.execute_input":"2024-04-18T10:49:53.620842Z","iopub.status.idle":"2024-04-18T10:49:56.815042Z","shell.execute_reply.started":"2024-04-18T10:49:53.620816Z","shell.execute_reply":"2024-04-18T10:49:56.814116Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nunzip is already the newest version (6.0-25ubuntu1.2).\n0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir datasetImage\n!unzip -q -o \"dataset/imagedata.zip\" -d \"datasetImage\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:49:56.816427Z","iopub.execute_input":"2024-04-18T10:49:56.816729Z","iopub.status.idle":"2024-04-18T10:50:13.576088Z","shell.execute_reply.started":"2024-04-18T10:49:56.816701Z","shell.execute_reply":"2024-04-18T10:50:13.574855Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"prefix_path_data = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.580081Z","iopub.execute_input":"2024-04-18T10:50:13.580405Z","iopub.status.idle":"2024-04-18T10:50:13.585253Z","shell.execute_reply.started":"2024-04-18T10:50:13.580376Z","shell.execute_reply":"2024-04-18T10:50:13.584142Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"rawlabel = \"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.586544Z","iopub.execute_input":"2024-04-18T10:50:13.586862Z","iopub.status.idle":"2024-04-18T10:50:13.597615Z","shell.execute_reply.started":"2024-04-18T10:50:13.586833Z","shell.execute_reply":"2024-04-18T10:50:13.596651Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# load label\nwith open(os.path.join(prefix_path_data, \"dataset/label.txt\"), \"r\") as f:\n    rawlabel = f.read()\n    \n# G93aRj07CIZPKaC8.jpg {\"label-8\":14,\"label-7\":3,\"label-2\":4} 16\n# name image, label(json), totel people vote\n# Format to json {name, label, totel}\nlabelDataset = []\narrayRawLabel = rawlabel.split(\"\\n\")\nfor ele in arrayRawLabel:\n    eleArr = ele.split(\" \")\n    try:\n        labelDataset.append({\n            \"name\": eleArr[0],\n            \"label\": json.loads(eleArr[1]),\n            \"total\": int(eleArr[2])\n        })\n    except:\n        print(ele)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.598838Z","iopub.execute_input":"2024-04-18T10:50:13.599160Z","iopub.status.idle":"2024-04-18T10:50:13.617547Z","shell.execute_reply.started":"2024-04-18T10:50:13.599135Z","shell.execute_reply":"2024-04-18T10:50:13.616677Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label 0 -> 10, 0 is not good image need to delete\ndef LabelsToVector(labels):\n    vectorLabel = [0] * 11\n    for label, num in labels.items():\n        if len(label.split(\"-\")) != 2:\n            print(\"Error: \", labels)\n        vectorLabel[int(label.split(\"-\")[1])] = num\n    return vectorLabel\n\ndef NormalVectorLabel(vectorLabel, total, presentFilter):\n    # Check if label 0 is > presentFilter\n    if vectorLabel[0]/total > presentFilter:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n    \n    # Process localcation label\n    totalLocalVote = 0\n    for i in range(1, 3):\n        totalLocalVote += vectorLabel[i]\n    if totalLocalVote > 0:\n        for i in range(1, 3):\n            vectorLabel[i] = 1 if vectorLabel[i]/totalLocalVote > presentFilter else 0\n    \n    # Process orther label\n    for i in range(3, len(vectorLabel)):\n        vectorLabel[i] = 1 if vectorLabel[i]/total > presentFilter else 0\n        \n    # Process speacil case\n    # Auto set label 1\n    goodLabel = [3, 4]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[1] = 1;\n    \n    # Auto set label 2\n    goodLabel = [7, 8]\n    for i in range(len(goodLabel)):\n        if vectorLabel[goodLabel[i]] == 1:\n            vectorLabel[2] = 1;\n            \n    # Check if label 1 or 2 is set\n    if vectorLabel[1] == vectorLabel[2]:\n        vectorLabel[0] = 1\n        for i in range(1, len(vectorLabel)):\n            vectorLabel[i] = 0\n        return np.array(vectorLabel)\n#     else:\n#         vectorLabel[0] = 0\n    \n    return np.array(vectorLabel)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.618526Z","iopub.execute_input":"2024-04-18T10:50:13.619460Z","iopub.status.idle":"2024-04-18T10:50:13.630862Z","shell.execute_reply.started":"2024-04-18T10:50:13.619435Z","shell.execute_reply":"2024-04-18T10:50:13.630101Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Filter label\nfor ele in labelDataset:\n    # Only get label with > 50% vote\n    ele[\"label\"] = NormalVectorLabel(LabelsToVector(ele[\"label\"]), ele[\"total\"], 0.5)\n    \n# Filter bad image\nclearLabelDataset = []\nfor ele in labelDataset:\n    if ele[\"label\"][0] == 0:\n        ele[\"label\"] = ele[\"label\"][1:]\n        clearLabelDataset.append(ele)\nlabelDataset = clearLabelDataset","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.632100Z","iopub.execute_input":"2024-04-18T10:50:13.632363Z","iopub.status.idle":"2024-04-18T10:50:13.658475Z","shell.execute_reply.started":"2024-04-18T10:50:13.632341Z","shell.execute_reply":"2024-04-18T10:50:13.657588Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Add map image name to label\nmapImageNameToLabel = {}\nfor ele in labelDataset:\n    mapImageNameToLabel[ele[\"name\"]] = ele[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.659616Z","iopub.execute_input":"2024-04-18T10:50:13.659963Z","iopub.status.idle":"2024-04-18T10:50:13.671711Z","shell.execute_reply.started":"2024-04-18T10:50:13.659919Z","shell.execute_reply":"2024-04-18T10:50:13.670863Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Map name for fast filter image\nmapNameFastQuery = set()\nfor ele in labelDataset:\n    mapNameFastQuery.add(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.673117Z","iopub.execute_input":"2024-04-18T10:50:13.673827Z","iopub.status.idle":"2024-04-18T10:50:13.681071Z","shell.execute_reply.started":"2024-04-18T10:50:13.673768Z","shell.execute_reply":"2024-04-18T10:50:13.680221Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# resize image with max(width, height) = size_image_model\ndef resize_image_reduce_size(image, size_image_model):\n    min_size = min(image.shape[0], image.shape[1])\n    radio_h = image.shape[0] / min_size\n    radio_w = image.shape[1] / min_size\n    return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:50:13.682141Z","iopub.execute_input":"2024-04-18T10:50:13.682394Z","iopub.status.idle":"2024-04-18T10:50:13.691539Z","shell.execute_reply.started":"2024-04-18T10:50:13.682362Z","shell.execute_reply":"2024-04-18T10:50:13.690635Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Load image\nimagesDataset = {}\nfor label in labelDataset:\n    if label[\"name\"] not in mapNameFastQuery:\n        continue\n    img = resize_image_reduce_size(\n        cv2.imread(os.path.join(prefix_path_data, \"datasetImage/file\", label['name'])),\n        224\n    )\n    imagesDataset[label['name']] = img","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-18T10:50:13.692927Z","iopub.execute_input":"2024-04-18T10:50:13.693332Z","iopub.status.idle":"2024-04-18T10:51:41.091055Z","shell.execute_reply.started":"2024-04-18T10:50:13.693302Z","shell.execute_reply":"2024-04-18T10:51:41.090195Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Process","metadata":{}},{"cell_type":"code","source":"print(len(labelDataset))\nprint(len(imagesDataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:41.092269Z","iopub.execute_input":"2024-04-18T10:51:41.092569Z","iopub.status.idle":"2024-04-18T10:51:41.097687Z","shell.execute_reply.started":"2024-04-18T10:51:41.092544Z","shell.execute_reply":"2024-04-18T10:51:41.096673Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"770\n770\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot analytic banlance dataset\n\ntotalLabelDataset = np.array([0] * 10)\nfor ele in labelDataset:\n    totalLabelDataset += ele[\"label\"]\n\nprint(totalLabelDataset)\n    \n# Draw\nplt.bar([i for i in range(1, 11)], totalLabelDataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:41.098860Z","iopub.execute_input":"2024-04-18T10:51:41.099145Z","iopub.status.idle":"2024-04-18T10:51:41.386673Z","shell.execute_reply.started":"2024-04-18T10:51:41.099101Z","shell.execute_reply":"2024-04-18T10:51:41.385748Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[301 469 143  96  63  50 112  62  45  94]\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<BarContainer object of 10 artists>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"print(labelDataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:41.388108Z","iopub.execute_input":"2024-04-18T10:51:41.388798Z","iopub.status.idle":"2024-04-18T10:51:41.393894Z","shell.execute_reply.started":"2024-04-18T10:51:41.388762Z","shell.execute_reply":"2024-04-18T10:51:41.392905Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'name': 'G93aRj07CIZPKaC8.jpg', 'label': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0]), 'total': 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"csvDataJSON = []\nlistGoodImage = []\nlabelValue = [\"Hồ Gươm\", \"Hồ Tây\", \"Tháp rùa\", \"Cầu Thê Húc\", \"Bưu Điện\", \"Vườn Hoa\", \"Chùa Trấn Quốc\", \"Đền Quán Thánh\", \"Khách Sạn\", \"Công Viên Nước\"]\nfor ele in labelDataset:\n    labelTemp = {}\n    for i in range(len(labelValue)):\n        labelTemp[labelValue[i]] = ele[\"label\"][i]\n    csvDataJSON.append({\n        \"file\": ele[\"name\"],\n        **labelTemp\n    })\n    listGoodImage.append(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:41.395212Z","iopub.execute_input":"2024-04-18T10:51:41.395502Z","iopub.status.idle":"2024-04-18T10:51:41.409720Z","shell.execute_reply.started":"2024-04-18T10:51:41.395477Z","shell.execute_reply":"2024-04-18T10:51:41.408634Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create csv file\nimport pandas as pd\npd.DataFrame(csvDataJSON).to_csv(\"labelData.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:41.411023Z","iopub.execute_input":"2024-04-18T10:51:41.411797Z","iopub.status.idle":"2024-04-18T10:51:42.427596Z","shell.execute_reply.started":"2024-04-18T10:51:41.411760Z","shell.execute_reply":"2024-04-18T10:51:42.426588Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Create list good \nf = open(\"listimage.txt\", \"w\")\nf.write(\"\\n\".join(listGoodImage))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.428837Z","iopub.execute_input":"2024-04-18T10:51:42.429105Z","iopub.status.idle":"2024-04-18T10:51:42.434442Z","shell.execute_reply.started":"2024-04-18T10:51:42.429083Z","shell.execute_reply":"2024-04-18T10:51:42.433514Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Note:\n# imagesDataset is an Dict key is name image, value is image data\n# Using: get image data of label name N => imagesDataset[N]\n# Get image data of label i => imagesDataset[labelDataset[i][\"name\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.435560Z","iopub.execute_input":"2024-04-18T10:51:42.435905Z","iopub.status.idle":"2024-04-18T10:51:42.444121Z","shell.execute_reply.started":"2024-04-18T10:51:42.435880Z","shell.execute_reply":"2024-04-18T10:51:42.443303Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"markdown","source":"### Analytics data","metadata":{}},{"cell_type":"code","source":"minLabel = np.amin(totalLabelDataset)\nprint(minLabel)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.445252Z","iopub.execute_input":"2024-04-18T10:51:42.445844Z","iopub.status.idle":"2024-04-18T10:51:42.455954Z","shell.execute_reply.started":"2024-04-18T10:51:42.445814Z","shell.execute_reply":"2024-04-18T10:51:42.454941Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"45\n","output_type":"stream"}]},{"cell_type":"code","source":"for label in labelDataset:\n    print(label)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.457019Z","iopub.execute_input":"2024-04-18T10:51:42.457337Z","iopub.status.idle":"2024-04-18T10:51:42.466268Z","shell.execute_reply.started":"2024-04-18T10:51:42.457307Z","shell.execute_reply":"2024-04-18T10:51:42.465398Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"{'name': 'G93aRj07CIZPKaC8.jpg', 'label': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0]), 'total': 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process image","metadata":{}},{"cell_type":"markdown","source":"#### Constant","metadata":{}},{"cell_type":"code","source":"size_image_model = 224","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.473197Z","iopub.execute_input":"2024-04-18T10:51:42.473592Z","iopub.status.idle":"2024-04-18T10:51:42.477641Z","shell.execute_reply.started":"2024-04-18T10:51:42.473569Z","shell.execute_reply":"2024-04-18T10:51:42.476750Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Helper function","metadata":{}},{"cell_type":"code","source":"def crop2nimage(image, nimage = 3):\n    # Size of bigest square image\n    sizeSquare = min(image.shape[0], image.shape[1])\n\n    # Rotate image if image is portrait\n    if image.shape[0] > image.shape[1]:\n        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n\n    # Crop n image\n    cropImages = []\n    widthBetween = (image.shape[1] - sizeSquare) / (nimage - 1)\n    for i in range(nimage):\n        x1 = int(i * widthBetween)\n        x2 = int(x1 + sizeSquare)\n        cropImages.append(image[:, x1:x2])\n\n    # Rotate image back\n    if image.shape[0] > image.shape[1]:\n        for i in range(len(cropImages)):\n            cropImages[i] = cv2.rotate(cropImages[i], cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n    # Convert color to RGB\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.cvtColor(cropImages[i], cv2.COLOR_BGR2RGB)\n        \n    return cropImages","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.478609Z","iopub.execute_input":"2024-04-18T10:51:42.478868Z","iopub.status.idle":"2024-04-18T10:51:42.487982Z","shell.execute_reply.started":"2024-04-18T10:51:42.478846Z","shell.execute_reply":"2024-04-18T10:51:42.487140Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def calibrate_image(image, target_size_kb=20):\n    # Resize image to the target size\n    resized_image = cv2.resize(image, (224, 224))\n\n    return resized_image","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.489097Z","iopub.execute_input":"2024-04-18T10:51:42.489340Z","iopub.status.idle":"2024-04-18T10:51:42.498016Z","shell.execute_reply.started":"2024-04-18T10:51:42.489319Z","shell.execute_reply":"2024-04-18T10:51:42.497205Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Data augmentation by type:\n# 1. Random flip\n# 2. Random rotate\n# 4. Random Saturate\n# 3. Random brightness\n# 5. Random crop\n\n# Random flip\ndef random_flip(image, p=0.5):\n    if np.random.rand() < p:\n        return cv2.flip(image, 1)\n    return image\n\n# Random rotate from range angle\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n    (in degrees). The returned image will be large enough to hold the entire\n    new image, with a black background\n    \"\"\"\n\n    # Get the image size\n    # No that's not an error - NumPy stores image matricies backwards\n    image_size = (image.shape[1], image.shape[0])\n    image_center = tuple(np.array(image_size) / 2)\n\n    # Convert the OpenCV 3x2 rotation matrix to 3x3\n    rot_mat = np.vstack(\n        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n    )\n\n    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n    # Shorthand for below calcs\n    image_w2 = image_size[0] * 0.5\n    image_h2 = image_size[1] * 0.5\n\n    # Obtain the rotated coordinates of the image corners\n    rotated_coords = [\n        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n    ]\n\n    # Find the size of the new image\n    x_coords = [pt[0] for pt in rotated_coords]\n    x_pos = [x for x in x_coords if x > 0]\n    x_neg = [x for x in x_coords if x < 0]\n\n    y_coords = [pt[1] for pt in rotated_coords]\n    y_pos = [y for y in y_coords if y > 0]\n    y_neg = [y for y in y_coords if y < 0]\n\n    right_bound = max(x_pos)\n    left_bound = min(x_neg)\n    top_bound = max(y_pos)\n    bot_bound = min(y_neg)\n\n    new_w = int(abs(right_bound - left_bound))\n    new_h = int(abs(top_bound - bot_bound))\n\n    # We require a translation matrix to keep the image centred\n    trans_mat = np.matrix([\n        [1, 0, int(new_w * 0.5 - image_w2)],\n        [0, 1, int(new_h * 0.5 - image_h2)],\n        [0, 0, 1]\n    ])\n\n    # Compute the tranform for the combined rotation and translation\n    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n    # Apply the transform\n    result = cv2.warpAffine(\n        image,\n        affine_mat,\n        (new_w, new_h),\n        flags=cv2.INTER_LINEAR\n    )\n\n    return result\n\ndef largest_rotated_rect(w, h, angle):\n    \"\"\"\n    Given a rectangle of size wxh that has been rotated by 'angle' (in\n    radians), computes the width and height of the largest possible\n    axis-aligned rectangle within the rotated rectangle.\n\n    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n\n    Converted to Python by Aaron Snoswell\n    \"\"\"\n\n    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n\n    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n\n    delta = math.pi - alpha - gamma\n\n    length = h if (w < h) else w\n\n    d = length * math.cos(alpha)\n    a = d * math.sin(alpha) / math.sin(delta)\n\n    y = a * math.cos(gamma)\n    x = y * math.tan(gamma)\n\n    return (\n        bb_w - 2 * x,\n        bb_h - 2 * y\n    )\n\ndef crop_around_center(image, width, height):\n    \"\"\"\n    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n    around it's centre point\n    \"\"\"\n\n    image_size = (image.shape[1], image.shape[0])\n    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n\n    if(width > image_size[0]):\n        width = image_size[0]\n\n    if(height > image_size[1]):\n        height = image_size[1]\n\n    x1 = int(image_center[0] - width * 0.5)\n    x2 = int(image_center[0] + width * 0.5)\n    y1 = int(image_center[1] - height * 0.5)\n    y2 = int(image_center[1] + height * 0.5)\n\n    return image[y1:y2, x1:x2]\n\ndef random_rotate(image, angle_range=15):\n    angle = np.random.uniform(-angle_range, angle_range)\n    image_height, image_width = image.shape[0:2]\n    image = crop_around_center(\n        rotate_image(image, angle),\n        *largest_rotated_rect(\n            image_width,\n            image_height,\n            math.radians(angle)\n        )\n    )\n    return image\n\n# Random saturate\ndef random_saturate(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 1] = hsv[:, :, 1] * np.random.uniform(low, high)\n    hsv[:, :, 1][hsv[:, :, 1] > 255] = 255\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random brightness\ndef random_brightness(image, low=0.5, high=1.5):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 2] = hsv[:, :, 2] * np.random.uniform(low, high)\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n    hsv = np.array(hsv, dtype=np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n# Random crop\ndef random_crop_size(image, size=224):\n    x = np.random.randint(0, image.shape[1] - size)\n    y = np.random.randint(0, image.shape[0] - size)\n    return image[y:y+size, x:x+size]\n\n# Random augment\ndef random_augment(image):\n    image = random_flip(image)\n    image = random_rotate(image)\n    image = random_saturate(image)\n    image = random_brightness(image)\n    # image = random_crop(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.499095Z","iopub.execute_input":"2024-04-18T10:51:42.499408Z","iopub.status.idle":"2024-04-18T10:51:42.531808Z","shell.execute_reply.started":"2024-04-18T10:51:42.499385Z","shell.execute_reply":"2024-04-18T10:51:42.530766Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Random noise\ndef random_noise(image, present=0.05):\n    # Randome noice range [0, 255] with present 0.05\n    lran = int(-255 * present)\n    rran = int(255 * present)\n    noise = np.random.randint(lran, rran, image.shape)\n\n    # Add noise to image\n    image = cv2.add(image, noise, dtype=cv2.CV_8UC3)\n\n    return image\n\n# Random blur\ndef random_blur(image, win_size=(3, 3)):\n    image = cv2.GaussianBlur(image, win_size, 0)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.532809Z","iopub.execute_input":"2024-04-18T10:51:42.533064Z","iopub.status.idle":"2024-04-18T10:51:42.545286Z","shell.execute_reply.started":"2024-04-18T10:51:42.533043Z","shell.execute_reply":"2024-04-18T10:51:42.544475Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"#### Resize image","metadata":{}},{"cell_type":"code","source":"# # resize image with max(width, height) = size_image_model\n# def resize_image_reduce_size(image, size_image_model):\n#     min_size = min(image.shape[0], image.shape[1])\n#     radio_h = image.shape[0] / min_size\n#     radio_w = image.shape[1] / min_size\n#     return cv2.resize(image, (int(radio_w * size_image_model), int(radio_h * size_image_model)))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.546306Z","iopub.execute_input":"2024-04-18T10:51:42.546575Z","iopub.status.idle":"2024-04-18T10:51:42.558329Z","shell.execute_reply.started":"2024-04-18T10:51:42.546553Z","shell.execute_reply":"2024-04-18T10:51:42.557564Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# # Apply to all image in dataset\n# for imageId in imagesDataset:\n#     imagesDataset[imageId] = resize_image_reduce_size(imagesDataset[imageId], size_image_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.559194Z","iopub.execute_input":"2024-04-18T10:51:42.559587Z","iopub.status.idle":"2024-04-18T10:51:42.568260Z","shell.execute_reply.started":"2024-04-18T10:51:42.559552Z","shell.execute_reply":"2024-04-18T10:51:42.567501Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# cv2.imwrite(\"test.jpg\", imagesDataset[labelDataset[0][\"name\"]], [cv2.IMWRITE_JPEG_QUALITY, 50])\n# print(os.path.getsize('test.jpg')/1024)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.569319Z","iopub.execute_input":"2024-04-18T10:51:42.569905Z","iopub.status.idle":"2024-04-18T10:51:42.578117Z","shell.execute_reply.started":"2024-04-18T10:51:42.569874Z","shell.execute_reply":"2024-04-18T10:51:42.577415Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"#### Data augment","metadata":{}},{"cell_type":"code","source":"# Target number image each label after augment\ntarget_number_image = 200","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.579187Z","iopub.execute_input":"2024-04-18T10:51:42.579489Z","iopub.status.idle":"2024-04-18T10:51:42.587501Z","shell.execute_reply.started":"2024-04-18T10:51:42.579455Z","shell.execute_reply":"2024-04-18T10:51:42.586577Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Split image name to label\ntempImageLabelName = [[] for _ in range(10)]\nfor ele in labelDataset:\n    for i in range(len(ele[\"label\"])):\n        if ele[\"label\"][i] >= 1:\n            tempImageLabelName[i].append(ele[\"name\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.588655Z","iopub.execute_input":"2024-04-18T10:51:42.589078Z","iopub.status.idle":"2024-04-18T10:51:42.601966Z","shell.execute_reply.started":"2024-04-18T10:51:42.589048Z","shell.execute_reply":"2024-04-18T10:51:42.601135Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"imagesDatasetAug = []\nlabelDatasetAug = []\n# Augment image\nfor i in range(0, 10):\n    print(\"Augment label: \", i)\n    print(\"Number image: \", len(tempImageLabelName[i]))\n    if len(tempImageLabelName[i]) >= target_number_image:\n        continue\n\n    for j in range(target_number_image - len(tempImageLabelName[i])):\n        # Name image\n        imageName = tempImageLabelName[i][np.random.randint(0, len(tempImageLabelName[i]))]\n        # Random select image\n        image = imagesDataset[imageName]\n        image = random_augment(image)\n        imagesDatasetAug.append(image)\n        labelDatasetAug.append(mapImageNameToLabel[imageName])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:42.603246Z","iopub.execute_input":"2024-04-18T10:51:42.603578Z","iopub.status.idle":"2024-04-18T10:51:45.889470Z","shell.execute_reply.started":"2024-04-18T10:51:42.603549Z","shell.execute_reply":"2024-04-18T10:51:45.888516Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Augment label:  0\nNumber image:  301\nAugment label:  1\nNumber image:  469\nAugment label:  2\nNumber image:  143\nAugment label:  3\nNumber image:  96\nAugment label:  4\nNumber image:  63\nAugment label:  5\nNumber image:  50\nAugment label:  6\nNumber image:  112\nAugment label:  7\nNumber image:  62\nAugment label:  8\nNumber image:  45\nAugment label:  9\nNumber image:  94\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.imshow(imagesDatasetAug[334])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:45.890552Z","iopub.execute_input":"2024-04-18T10:51:45.890895Z","iopub.status.idle":"2024-04-18T10:51:46.249686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imagesDatasetArray\nimagesDatasetArray = []\nlabelDatasetArray = []\n\nfor ele in labelDataset:\n    imagesDatasetArray.append(imagesDataset[ele[\"name\"]])\n    labelDatasetArray.append(ele[\"label\"])\n\nfor i in range(len(imagesDatasetAug)):\n    imagesDatasetArray.append(imagesDatasetAug[i])\n    labelDatasetArray.append(labelDatasetAug[i])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:46.250896Z","iopub.execute_input":"2024-04-18T10:51:46.251194Z","iopub.status.idle":"2024-04-18T10:51:46.258090Z","shell.execute_reply.started":"2024-04-18T10:51:46.251167Z","shell.execute_reply":"2024-04-18T10:51:46.256930Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray), len(labelDatasetArray))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:46.259239Z","iopub.execute_input":"2024-04-18T10:51:46.259548Z","iopub.status.idle":"2024-04-18T10:51:46.273908Z","shell.execute_reply.started":"2024-04-18T10:51:46.259523Z","shell.execute_reply":"2024-04-18T10:51:46.273127Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"1705 1705\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Resize image and add some noise and rotate","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3 = []","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:46.275000Z","iopub.execute_input":"2024-04-18T10:51:46.275305Z","iopub.status.idle":"2024-04-18T10:51:46.284121Z","shell.execute_reply.started":"2024-04-18T10:51:46.275281Z","shell.execute_reply":"2024-04-18T10:51:46.283380Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"for i in range(len(labelDatasetArray)):\n    image = np.copy(imagesDatasetArray[i])\n    \n    # Crop\n    cropImages = crop2nimage(image, 3)\n\n    # Resize\n    for i in range(len(cropImages)):\n        cropImages[i] = cv2.resize(cropImages[i], (size_image_model, size_image_model))\n\n    # Add blur to image\n    for i in range(len(cropImages)):\n        cropImages[i] = random_blur(cropImages[i], (3, 3))\n\n    # Add noise to image\n    for i in range(len(cropImages)):\n        # Randome noice\n        cropImages[i] = random_noise(cropImages[i], 0.05)\n\n    # Debug\n    # for i in range(len(cropImages)):\n    #     plt.imshow(cropImages[i])\n    #     plt.show()\n    # break\n\n    imagesDatasetArray3.append(cropImages)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:46.285209Z","iopub.execute_input":"2024-04-18T10:51:46.285479Z","iopub.status.idle":"2024-04-18T10:51:56.689573Z","shell.execute_reply.started":"2024-04-18T10:51:46.285446Z","shell.execute_reply":"2024-04-18T10:51:56.688563Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(len(imagesDatasetArray3), len(imagesDatasetArray3[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:56.690751Z","iopub.execute_input":"2024-04-18T10:51:56.691017Z","iopub.status.idle":"2024-04-18T10:51:56.696502Z","shell.execute_reply.started":"2024-04-18T10:51:56.690994Z","shell.execute_reply":"2024-04-18T10:51:56.695622Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"1705 3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"markdown","source":"### Normal image","metadata":{}},{"cell_type":"markdown","source":"### Split testcase","metadata":{}},{"cell_type":"code","source":"imagesDatasetArray3_training = []\nlabelDatasetArray_training = []\nimagesDatasetArray3_testing = []\nlabelDatasetArray_testing = []","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:56.697568Z","iopub.execute_input":"2024-04-18T10:51:56.697854Z","iopub.status.idle":"2024-04-18T10:51:56.708037Z","shell.execute_reply.started":"2024-04-18T10:51:56.697831Z","shell.execute_reply":"2024-04-18T10:51:56.707328Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"idx = [i for i in range(len(imagesDatasetArray3))]\nnp.random.shuffle(idx)\n\nfor i in range(len(idx)):\n    if i < len(idx) * 0.5:\n        imagesDatasetArray3_training.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_training.append(labelDatasetArray[idx[i]])\n    else:\n        imagesDatasetArray3_testing.append(imagesDatasetArray3[idx[i]])\n        labelDatasetArray_testing.append(labelDatasetArray[idx[i]])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:56.709210Z","iopub.execute_input":"2024-04-18T10:51:56.709615Z","iopub.status.idle":"2024-04-18T10:51:56.720876Z","shell.execute_reply.started":"2024-04-18T10:51:56.709584Z","shell.execute_reply":"2024-04-18T10:51:56.720072Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy\nfor i in range(len(imagesDatasetArray3_training)):\n    imagesDatasetArray3_training[i] = [\n        (np.array(imagesDatasetArray3_training[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_training[i]))\n    ]\n    labelDatasetArray_training[i] = np.array(labelDatasetArray_training[i], dtype=np.float32)\n    \nfor i in range(len(imagesDatasetArray3_testing)):\n    imagesDatasetArray3_testing[i] = [\n        (np.array(imagesDatasetArray3_testing[i][j], dtype=np.float32) / 255.0) for j in range(len(imagesDatasetArray3_testing[i]))\n    ]\n    labelDatasetArray_testing[i] = np.array(labelDatasetArray_testing[i], dtype=np.float32)\n\n# imagesDatasetArray3_training = np.array(imagesDatasetArray3_training, dtype=np.float32) / 255.0\n# labelDatasetArray_training = np.array(labelDatasetArray_training, dtype=np.float32)\n# imagesDatasetArray3_testing = np.array(imagesDatasetArray3_testing, dtype=np.float32) / 255.0\n# labelDatasetArray_testing = np.array(labelDatasetArray_testing, dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:56.721828Z","iopub.execute_input":"2024-04-18T10:51:56.722091Z","iopub.status.idle":"2024-04-18T10:51:59.021180Z","shell.execute_reply.started":"2024-04-18T10:51:56.722069Z","shell.execute_reply":"2024-04-18T10:51:59.020135Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Import library","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:51:59.022535Z","iopub.execute_input":"2024-04-18T10:51:59.023425Z","iopub.status.idle":"2024-04-18T10:52:10.804211Z","shell.execute_reply.started":"2024-04-18T10:51:59.023389Z","shell.execute_reply":"2024-04-18T10:52:10.803240Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"2024-04-18 10:52:00.640612: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 10:52:00.640711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 10:52:00.764674: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Num GPUs Available:  1\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:10.805759Z","iopub.execute_input":"2024-04-18T10:52:10.806473Z","iopub.status.idle":"2024-04-18T10:52:10.811065Z","shell.execute_reply.started":"2024-04-18T10:52:10.806435Z","shell.execute_reply":"2024-04-18T10:52:10.810193Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### Build dataset with batch","metadata":{}},{"cell_type":"code","source":"def create_batch_from_arr(arrData, batch_size=64):\n    temp_shape = list(arrData.shape)\n    deltaMiss = ((arrData.shape[0] + batch_size - 1) // batch_size) * batch_size - arrData.shape[0]\n    temp_shape[0] += deltaMiss\n    batchArrData = np.zeros(tuple(temp_shape), dtype=np.float32)\n    # Add to last\n    batchArrData[:arrData.shape[0]] = arrData\n    for i in range(arrData.shape[0] + 1, batchArrData.shape[0]):\n        batchArrData[i] = arrData[i - arrData.shape[0] - 1]\n        \n    batchArrData = batchArrData.reshape(tuple([-1, batch_size, *list(batchArrData.shape[1:])]))\n    \n    return batchArrData\n\ndef create_dataset(images, labels, batch_size=64):\n    if batch_size == 0:\n        return (np.array(images), np.array(labels))\n    images = np.array(images, dtype=np.float32)\n    # image is 3 image in array\n    tempImageSplit = []\n    for i in range(images.shape[1]):\n        tempImageSplit.append(create_batch_from_arr(images[:, i], batch_size))\n\n    imagesBatch = []\n    for i in range(len(tempImageSplit[0])):\n        nimage = []\n        for j in range(len(tempImageSplit)):\n            nimage.append(tempImageSplit[j][i])\n        imagesBatch.append(nimage)\n        \n    labels = np.array(labels, dtype=np.float32)\n    labels = create_batch_from_arr(labels, batch_size)\n    \n    return (np.array(imagesBatch), labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:10.812144Z","iopub.execute_input":"2024-04-18T10:52:10.812403Z","iopub.status.idle":"2024-04-18T10:52:10.842439Z","shell.execute_reply.started":"2024-04-18T10:52:10.812381Z","shell.execute_reply":"2024-04-18T10:52:10.841508Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"datasetTraining = create_dataset(imagesDatasetArray3_training, labelDatasetArray_training, 0)\ndatasetTesting = create_dataset(imagesDatasetArray3_testing, labelDatasetArray_testing, 0)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:10.843602Z","iopub.execute_input":"2024-04-18T10:52:10.844002Z","iopub.status.idle":"2024-04-18T10:52:11.743121Z","shell.execute_reply.started":"2024-04-18T10:52:10.843967Z","shell.execute_reply":"2024-04-18T10:52:11.742323Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Init model","metadata":{}},{"cell_type":"code","source":"# Using dataset imagesDatasetArray3 and labelDatasetArray","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:11.744415Z","iopub.execute_input":"2024-04-18T10:52:11.744995Z","iopub.status.idle":"2024-04-18T10:52:11.749162Z","shell.execute_reply.started":"2024-04-18T10:52:11.744961Z","shell.execute_reply":"2024-04-18T10:52:11.748215Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def hotaBlockImage(index):\n    inputTensor = tf.keras.Input(shape=(size_image_model,size_image_model,3))\n    model = tf.keras.applications.densenet.DenseNet121(\n        include_top=True,\n        weights='imagenet',\n        input_tensor=inputTensor,\n        input_shape=None,\n        pooling=None,\n        classes=1000,\n        classifier_activation='softmax'\n    )\n    layer_names=[layer.name for layer in model.layers]\n    for layer_name in layer_names:\n        model.get_layer(name=layer_name).name = \"{0}_{1}\".format(layer_name, index)\n    return model\ndef hotaNBlockImage(nblock = 3):\n    inputs = []\n    hidden_outputs = []\n    for i in range(nblock):\n        temp_model = hotaBlockImage(i)\n        inputs.append(temp_model.input[0])\n        hidden_outputs.append(temp_model.output)\n        \n    combined = tf.keras.layers.Concatenate()(hidden_outputs)\n    outputflatten = tf.keras.layers.Flatten()(combined)\n    \n    hidden_outputs_2 = tf.keras.layers.Dense(256, activation=\"relu\")(outputflatten)\n    outputs = tf.keras.layers.Dense(10, activation=\"sigmoid\")(hidden_outputs_2)\n    \n    return tf.keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:11.750276Z","iopub.execute_input":"2024-04-18T10:52:11.750588Z","iopub.status.idle":"2024-04-18T10:52:11.761967Z","shell.execute_reply.started":"2024-04-18T10:52:11.750562Z","shell.execute_reply":"2024-04-18T10:52:11.761184Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"hotaModel = hotaNBlockImage(3)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:11.763191Z","iopub.execute_input":"2024-04-18T10:52:11.763614Z","iopub.status.idle":"2024-04-18T10:52:22.126797Z","shell.execute_reply.started":"2024-04-18T10:52:11.763583Z","shell.execute_reply":"2024-04-18T10:52:22.125761Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n\u001b[1m33188688/33188688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"hotaModel.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-18T10:52:22.128250Z","iopub.execute_input":"2024-04-18T10:52:22.128997Z","iopub.status.idle":"2024-04-18T10:52:23.844248Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,707,394\u001b[0m (94.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,707,394</span> (94.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m250,944\u001b[0m (980.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,944</span> (980.25 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"datasetTraining[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.845517Z","iopub.execute_input":"2024-04-18T10:52:23.846140Z","iopub.status.idle":"2024-04-18T10:52:23.852602Z"},"trusted":true},"execution_count":null,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(3, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"def autoFormatNumpy2List(data):\n    listData = []\n    for i in range(data.shape[0]):\n        listData.append(data[i])\n        \n    return listData","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.853964Z","iopub.execute_input":"2024-04-18T10:52:23.854290Z","iopub.status.idle":"2024-04-18T10:52:23.862611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-3, patience=3)\nhotaModel.compile(loss=tf.keras.losses.BinaryCrossentropy(\n    from_logits = False,\n), optimizer=opt, metrics=[\n    tf.keras.metrics.BinaryAccuracy()\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.863652Z","iopub.execute_input":"2024-04-18T10:52:23.863939Z","iopub.status.idle":"2024-04-18T10:52:23.893926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoFormatListMap2MapList(data):\n    listData = []\n    for i in range(data.shape[1]):\n        listData.append(data[:, i])\n    return listData","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.895122Z","iopub.execute_input":"2024-04-18T10:52:23.895398Z","iopub.status.idle":"2024-04-18T10:52:23.900123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xTrainignInput = autoFormatListMap2MapList(datasetTraining[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.901154Z","iopub.execute_input":"2024-04-18T10:52:23.901447Z","iopub.status.idle":"2024-04-18T10:52:23.912174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotaModel.fit(\n    x=xTrainignInput,\n    y=datasetTraining[1],\n    batch_size=8,\n    epochs=100,\n    callbacks=[callback],\n    verbose=1,\n    validation_split=0.1,\n    shuffle=True,\n    initial_epoch=0,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T10:52:23.913422Z","iopub.execute_input":"2024-04-18T10:52:23.913995Z","iopub.status.idle":"2024-04-18T12:20:01.276473Z","shell.execute_reply.started":"2024-04-18T10:52:23.913962Z","shell.execute_reply":"2024-04-18T12:20:01.274190Z"},"scrolled":true,"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 8s/step - binary_accuracy: 0.7771 - loss: 0.6526 - val_binary_accuracy: 0.8244 - val_loss: 0.5228\nEpoch 2/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 8s/step - binary_accuracy: 0.8061 - loss: 0.4719 - val_binary_accuracy: 0.8267 - val_loss: 0.4470\nEpoch 3/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 8s/step - binary_accuracy: 0.8177 - loss: 0.4344 - val_binary_accuracy: 0.8279 - val_loss: 0.4391\nEpoch 4/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 8s/step - binary_accuracy: 0.8090 - loss: 0.4379 - val_binary_accuracy: 0.8035 - val_loss: 0.4547\nEpoch 5/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 8s/step - binary_accuracy: 0.8193 - loss: 0.4350 - val_binary_accuracy: 0.8360 - val_loss: 0.4333\nEpoch 6/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 8s/step - binary_accuracy: 0.8168 - loss: 0.4334 - val_binary_accuracy: 0.8174 - val_loss: 0.4394\nEpoch 7/100\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 8s/step - binary_accuracy: 0.8093 - loss: 0.4374 - val_binary_accuracy: 0.8384 - val_loss: 0.4314\nEpoch 8/100\n\u001b[1m 6/96\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:18\u001b[0m 8s/step - binary_accuracy: 0.8058 - loss: 0.4295","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhotaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxTrainignInput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasetTraining\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:809\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:117\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 117\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    121\u001b[0m     outputs,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    123\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:809\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:105\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:56\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[0;32m---> 56\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:816\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py:42\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     38\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     39\u001b[0m         call_fn,\n\u001b[1;32m     40\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:157\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:188\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 188\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/function.py:153\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mfill_in(tensor_dict)\n\u001b[0;32m--> 153\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:572\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:736\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# 3. Check input spec for 1st positional arg.\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# TODO: consider extending this to all args and kwargs.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_input_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# 4. Call build\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:1284\u001b[0m, in \u001b[0;36mLayer._assert_input_compatibility\u001b[0;34m(self, arg_0)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_input_compatibility\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg_0):\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[43minput_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_input_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/input_spec.py:165\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:498\u001b[0m, in \u001b[0;36m_EagerTensorBase.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=access-member-before-definition\u001b[39;00m\n\u001b[1;32m    494\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    495\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# `_tensor_shape` is declared and defined in the definition of\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;66;03m# `EagerTensor`, in C.\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_shape \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:830\u001b[0m, in \u001b[0;36mTensorShape.__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new TensorShape with the given dimensions.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m  TypeError: If dims cannot be converted to a list of dimensions.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dims, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):  \u001b[38;5;66;03m# Most common case.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mas_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:830\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new TensorShape with the given dimensions.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m  TypeError: If dims cannot be converted to a list of dimensions.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dims, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):  \u001b[38;5;66;03m# Most common case.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mas_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dims)\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:744\u001b[0m, in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    742\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:204\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Represents the value of one dimension in a TensorShape.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m@compatibility(TF2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new Dimension with the given value.\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mint\u001b[39m):  \u001b[38;5;66;03m# Most common case.\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"xTestingInput = autoFormatListMap2MapList(datasetTesting[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:20:09.208681Z","iopub.execute_input":"2024-04-18T12:20:09.209344Z","iopub.status.idle":"2024-04-18T12:20:09.213867Z","shell.execute_reply.started":"2024-04-18T12:20:09.209309Z","shell.execute_reply":"2024-04-18T12:20:09.212803Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"hotaModel.evaluate(\n    x=xTestingInput,\n    y=datasetTesting[1],\n    batch_size=8,\n    verbose=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:20:23.116862Z","iopub.execute_input":"2024-04-18T12:20:23.117653Z","iopub.status.idle":"2024-04-18T12:22:37.017854Z","shell.execute_reply.started":"2024-04-18T12:20:23.117620Z","shell.execute_reply":"2024-04-18T12:22:37.016810Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - binary_accuracy: 0.8133 - loss: 0.4319\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"[0.4353775084018707, 0.8069249987602234]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}